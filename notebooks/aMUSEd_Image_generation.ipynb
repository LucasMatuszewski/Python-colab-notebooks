{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOnM79vb91ouTjTp2DWaOu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasMatuszewski/Python-colab-notebooks/blob/main/notebooks/aMUSEd_Image_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# aMUSEd Image generation - 512px and 256px models\n",
        "Based on: [aMUSEd: An Open MUSE Reproduction](https://huggingface.co/amused/amused-512) (which is based on Google MUSE)"
      ],
      "metadata": {
        "id": "Sw_DfmfYj8b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "var codeCells = document.querySelectorAll(\"div.view-lines\");\n",
        "console.log(codeCells)\n",
        "for (var i = 0; i < codeCells.length; i++) {\n",
        "    var lines = codeCells[i].querySelectorAll('.view-line').length;\n",
        "    console.log(lines)\n",
        "    var numbers = Array(lines).fill(0).map((_, i) => i + 1).join(\"\\n\");\n",
        "    var lineNumbersDiv = document.createElement('div');\n",
        "    lineNumbersDiv.textContent = numbers;\n",
        "    codeCells[i].parentElement.insertBefore(lineNumbersDiv, codeCells[i]);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "y4Fejmu2eJkd",
        "outputId": "e3b3cf3d-4ce5-4a8b-ddcc-b721885aa812"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "var codeCells = document.querySelectorAll(\"div.view-lines\");\n",
              "console.log(codeCells)\n",
              "for (var i = 0; i < codeCells.length; i++) {\n",
              "    var lines = codeCells[i].querySelectorAll('.view-line').length;\n",
              "    console.log(lines)\n",
              "    var numbers = Array(lines).fill(0).map((_, i) => i + 1).join(\"\\n\"); \n",
              "    var lineNumbersDiv = document.createElement('div');\n",
              "    lineNumbersDiv.textContent = numbers;\n",
              "    codeCells[i].parentElement.insertBefore(lineNumbersDiv, codeCells[i]);\n",
              "}\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import dependencies and install diffusers"
      ],
      "metadata": {
        "id": "QPJk_iIOnWTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers\n",
        "!pip install transformers\n",
        "import torch\n",
        "from diffusers import AmusedPipeline, AmusedImg2ImgPipeline, AmusedInpaintPipeline\n",
        "# Available pipelines:\n",
        "# AmusedPipeline - base text 2 image\n",
        "# AmusedImg2ImgPipeline - image + text 2 image\n",
        "# AmusedInpaintPipeline - image + mask + text 2 image"
      ],
      "metadata": {
        "id": "8k1wYNIym3rJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09342dcb-9f70-4948-b2e7-7c7226dec5cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /home/lucas/.local/lib/python3.10/site-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/lucas/.local/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/lucas/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lucas/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lucas/.local/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/lucas/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "/home/lucas/.local/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "/home/lucas/.local/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load aMUSEd 512px or 256px model (with optional acceleration for faster restults)"
      ],
      "metadata": {
        "id": "mAze8QsMy6s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab's @param doesn't work in Jupyter, to get similar UX use Jupyter Widgets:\n",
        "# https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html\n",
        "model_name = \"amused/amused-512\"  # @param [\"amused/amused-512\", \"amused/amused-256\"] {type:\"string\"}\n",
        "mode = \"img\"  # @param [\"txt\", \"img\", \"img_mask\"] {type:\"string\"}\n",
        "should_accelerate = True # @param {type: \"boolean\"}\n",
        "size = 512 if model_name == \"amused/amused-512\" else 256\n",
        "# width = size # @param {type: \"string\"}\n",
        "# height = size # @param {type: \"string\"}\n",
        "\n",
        "if mode != \"txt\":\n",
        "    from diffusers.utils import load_image\n",
        "\n",
        "# Load the model first\n",
        "try:\n",
        "    print(\"Loading the model...\")\n",
        "    Pipeline = AmusedInpaintPipeline if mode == \"img_mask\" \\\n",
        "               else AmusedImg2ImgPipeline if mode == \"img\" \\\n",
        "               else AmusedPipeline\n",
        "    pipe = Pipeline.from_pretrained(\n",
        "        model_name, variant=\"fp16\", torch_dtype=torch.float16\n",
        "    )\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Couldn't Load the model: {e}\")\n",
        "\n",
        "# Is GPU available?\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"\\nRunning on CPU !! Go to 'Runtime' manu and 'Change runtime type' to 'GPU'\")\n",
        "    raise RuntimeError(\"GPU not found. Please switch to a GPU runtime.\")\n",
        "\n",
        "generator = torch.Generator('cuda').manual_seed(0)\n",
        "\n",
        "# Accelerate model and generator\n",
        "if should_accelerate:\n",
        "    try:\n",
        "        !pip install accelerate\n",
        "        from accelerate import Accelerator\n",
        "        accelerate_available = True\n",
        "    except ImportError as e:\n",
        "        print(f\"Couldn't import Accelerator: {e}\")\n",
        "        accelerate_available = False\n",
        "    if accelerate_available:\n",
        "        accelerator = Accelerator(fp16=True)  # Or with other desired settings\n",
        "        pipe, generator = accelerator.prepare(pipe, generator)\n",
        "\n",
        "# Send the model to the GPU\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "id": "fcEYdnK32-yp",
        "outputId": "8b590a3b-461a-4d44-9398-cce6732fd55a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: accelerate in /home/lucas/.local/lib/python3.10/site-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/lucas/.local/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from accelerate) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in /home/lucas/.local/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/lucas/.local/lib/python3.10/site-packages (from accelerate) (2.2.1)\n",
            "Requirement already satisfied: huggingface-hub in /home/lucas/.local/lib/python3.10/site-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/lucas/.local/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch>=1.10.0->accelerate) (1.9)\n",
            "Requirement already satisfied: networkx in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/lucas/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/lucas/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.2.140)\n",
            "Requirement already satisfied: requests in /home/lucas/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/lucas/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/lucas/.local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lucas/.local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (2020.6.20)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Accelerator.__init__() got an unexpected keyword argument 'fp16'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_35847/491322825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0maccelerate_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccelerate_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0maccelerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Or with other desired settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Accelerator.__init__() got an unexpected keyword argument 'fp16'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image with Mask and prompt"
      ],
      "metadata": {
        "id": "Rr1F_DtJnGES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLbXfJ52j6F2",
        "outputId": "c6a5ab94-f6a7-4f9c-de3d-767b1063bbab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating image...\n",
            "An error occurred: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 30.50 MiB is free. Including non-PyTorch memory, this process has 3.20 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 9.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ],
      "source": [
        "# define image loading function:\n",
        "def image_loader(image_url, color=True):\n",
        "    return load_image(image_url) \\\n",
        "        .resize((size, size)) \\\n",
        "        .convert(\"RGB\" if color else \"L\") # L = grayscale (Luminance)\n",
        "\n",
        "# define a function for later usage:\n",
        "def generate_image(prompt, input_image_url=None, mask_url=None, strength=0.7):\n",
        "    try:\n",
        "        input_image = image_loader(input_image_url) if input_image_url else None\n",
        "        mask = image_loader(mask_url, color=False) if mask_url else None\n",
        "\n",
        "        # To return multiple images:\n",
        "        # number_of_images = 1 # @param {type:\"slider\", min:1, max:20, step:1}\n",
        "        # for seed in range(number_of_images):\n",
        "        #     print(f\"Generating image {seed}...\")\n",
        "        #     image = pipe(prompt, input_image, mask, generator=torch.Generator('cuda').manual_seed(seed)).images[0]\n",
        "        #     # image.save(f'inpainting_256_{seed}.png')\n",
        "        #     print(f\"Image {seed} generated!\")\n",
        "        print(\"Generating image...\")\n",
        "        image = pipe(prompt, input_image, mask, generator).images[0]\n",
        "        print(\"Image generated!\")\n",
        "        return image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "prompt = \"a man with glasses\"  # @param {type: \"string\"}\n",
        "input_image_url = \"https://raw.githubusercontent.com/huggingface/amused/main/assets/inpainting_256_orig.png\" # @param {type: \"string\"}\n",
        "mask_url = \"https://raw.githubusercontent.com/huggingface/amused/main/assets/inpainting_512_mask.png\"  # @param {type: \"string\"}\n",
        "strength = 0.7 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "generate_image(\n",
        "      prompt,\n",
        "      input_image_url = input_image_url if mode != \"txt\" else None,\n",
        "      mask_url = mask_url if mode == \"img_mask\" else None,\n",
        "      strength = strength\n",
        "  )\n",
        "\n",
        "# If you want to save the image to a file:\n",
        "# image = pipe(prompt, input_image, mask, generator=torch.Generator('cuda').manual_seed(0)).images[0]\n",
        "# image.save('inpainting_512.png')\n"
      ]
    }
  ]
}