{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMT9sVpIa7FWdEzPKE7AQ6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasMatuszewski/Python-colab-notebooks/blob/main/CrewAI_Chroma_RAG_NewsAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CrewAI RAG with Chroma DB and NewsAPI\n",
        "Based on [this YouTube video](https://www.youtube.com/watch?v=77xSbC-9yn4)"
      ],
      "metadata": {
        "id": "_tRhWzZnskyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "pLTW7fsElT32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai\n",
        "!pip install 'crewai[tools]'\n",
        "!pip install duckduckgo-search langchain-community langchain-openai langchain-mistralai requests chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP46fbRml_lM",
        "outputId": "597e5dfc-20da-4e95-cc94-d38210f24cc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-0.19.0-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai) (8.1.7)\n",
            "Collecting instructor<0.6.0,>=0.5.2 (from crewai)\n",
            "  Downloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai)\n",
            "  Downloading langchain-0.1.10-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.2/806.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai<0.0.6,>=0.0.5 (from crewai)\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Collecting openai<2.0.0,>=1.13.3 (from crewai)\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.23.0-py3-none-any.whl (16 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.6.3)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /usr/local/lib/python3.10/dist-packages (from crewai) (2023.12.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (3.9.3)\n",
            "Collecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (8.2.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (0.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (2.0.27)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.28 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading langsmith-0.1.14-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (2.31.0)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai<0.0.6,>=0.0.5->crewai)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.13.3->crewai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (4.10.0)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.62.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.23.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (3.20.3)\n",
            "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (2.16.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading marshmallow-3.21.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.14.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai) (3.17.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain<0.2.0,>=0.1.10->crewai) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.10->crewai) (3.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, marshmallow, jsonpointer, importlib-metadata, h11, docstring-parser, deprecated, typing-inspect, tiktoken, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, httpcore, opentelemetry-sdk, langsmith, httpx, dataclasses-json, opentelemetry-exporter-otlp-proto-http, openai, langchain-core, langchain-text-splitters, langchain-openai, langchain-community, instructor, langchain, crewai\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed crewai-0.19.0 dataclasses-json-0.6.4 deprecated-1.2.14 docstring-parser-0.15 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 importlib-metadata-6.11.0 instructor-0.5.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.10 langchain-community-0.0.25 langchain-core-0.1.28 langchain-openai-0.0.5 langchain-text-splitters-0.0.1 langsmith-0.1.14 marshmallow-3.21.0 mypy-extensions-1.0.0 openai-1.13.3 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-http-1.23.0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 orjson-3.9.15 tiktoken-0.5.2 typing-inspect-0.9.0\n",
            "Requirement already satisfied: crewai[tools] in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (8.1.7)\n",
            "Requirement already satisfied: instructor<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (0.5.2)\n",
            "Requirement already satisfied: langchain<0.2.0,>=0.1.10 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (0.1.10)\n",
            "Requirement already satisfied: langchain-openai<0.0.6,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (0.0.5)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (1.13.3)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (2.6.3)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (2023.12.25)\n",
            "Collecting crewai-tools<0.0.16,>=0.0.15 (from crewai[tools])\n",
            "  Downloading crewai_tools-0.0.15-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (4.12.3)\n",
            "Collecting chromadb<0.5.0,>=0.4.22 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting embedchain[github,youtube]<0.2.0,>=0.1.85 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading embedchain-0.1.92-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lancedb<0.6.0,>=0.5.4 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyright<2.0.0,>=1.1.350 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading pyright-1.1.352-py3-none-any.whl (18 kB)\n",
            "Collecting pytest<9.0.0,>=8.0.0 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading pytest-8.1.0-py3-none-any.whl (335 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.5/335.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytube<16.0.0,>=15.0.0 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.31.0)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (3.9.3)\n",
            "Requirement already satisfied: docstring-parser<0.16,>=0.15 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (0.15)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (8.2.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (0.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (2.0.27)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.0.25)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.28 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.1.28)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.1.14)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (1.25.2)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai<0.0.6,>=0.0.5->crewai[tools]) (0.5.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (4.10.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.23.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (3.20.3)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai[tools]) (0.44b0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai[tools]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai[tools]) (2.16.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai[tools]) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai[tools]) (1.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.0.3)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading posthog-3.4.2-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (6.1.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.62.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.9.15)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (3.21.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (0.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (1.14.1)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.42.1)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading gptcache-0.1.43-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<4.0.0,>=3.11.0 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysbd<0.4.0,>=0.3.4 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv<2.0.0,>=1.0.0 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyGithub<2.0.0,>=1.59.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython<4.0.0,>=3.1.38 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (3.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai[tools]) (2.4)\n",
            "Collecting deprecation (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (5.3.3)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.10/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (14.0.2)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain<0.2.0,>=0.1.10->crewai[tools]) (23.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.4.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai[tools]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai[tools]) (2.16.1)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading trio-0.24.0-py3-none-any.whl (460 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.2/460.2 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.10->crewai[tools]) (3.0.3)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.0.0)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.12.2)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.0.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai[tools]) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=1.6.0->pyright<2.0.0,>=1.1.350->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (67.7.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.12)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema<0.8.0,>=0.7.5->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (21.6.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.20.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (1.0.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3<3,>=1.21.1->requests<3.0.0,>=2.31.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2023.6.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.16.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.21)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.5.1)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=c05bd804f0e011f863d50fbccbf5512031c00a1a81f5bf79fd2ef095f3c66804\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: ratelimiter, pypika, monotonic, mmh3, brotli, wsproto, websockets, uvloop, uvicorn, smmap, semver, schema, pytube, python-dotenv, pytest, pysbd, pypdf, pyjwt, pycryptodomex, py, pulsar-client, overrides, outcome, opentelemetry-util-http, nodeenv, mutagen, Mako, humanfriendly, httptools, deprecation, chroma-hnswlib, bcrypt, backoff, asgiref, yt_dlp, youtube-transcript-api, watchfiles, trio, starlette, retry, pyright, pynacl, pylance, posthog, gptcache, gitdb, coloredlogs, alembic, trio-websocket, opentelemetry-instrumentation, onnxruntime, lancedb, kubernetes, gitpython, fastapi, selenium, PyGithub, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, embedchain, crewai-tools\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed Mako-1.3.2 PyGithub-1.59.1 alembic-1.13.1 asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 brotli-1.1.0 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 crewai-tools-0.0.15 deprecation-2.1.0 embedchain-0.1.92 fastapi-0.110.0 gitdb-4.0.11 gitpython-3.1.42 gptcache-0.1.43 httptools-0.6.1 humanfriendly-10.0 kubernetes-29.0.0 lancedb-0.5.7 mmh3-4.1.0 monotonic-1.6 mutagen-1.47.0 nodeenv-1.8.0 onnxruntime-1.17.1 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-util-http-0.44b0 outcome-1.3.0.post0 overrides-7.7.0 posthog-3.4.2 pulsar-client-3.4.0 py-1.11.0 pycryptodomex-3.20.0 pyjwt-2.8.0 pylance-0.9.18 pynacl-1.5.0 pypdf-3.17.4 pypika-0.48.9 pyright-1.1.352 pysbd-0.3.4 pytest-8.1.0 python-dotenv-1.0.1 pytube-15.0.0 ratelimiter-1.2.0.post0 retry-0.9.2 schema-0.7.5 selenium-4.18.1 semver-3.0.2 smmap-5.0.1 starlette-0.36.3 trio-0.24.0 trio-websocket-0.11.1 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0 wsproto-1.2.0 youtube-transcript-api-0.6.2 yt_dlp-2023.12.30\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-4.5.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.0.5)\n",
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-0.0.5-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting curl-cffi>=0.6.1 (from duckduckgo-search)\n",
            "  Downloading curl_cffi-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lxml>=5.1.0 (from duckduckgo-search)\n",
            "  Downloading lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.28 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.28)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.14)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.2.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.13.3)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.5.2)\n",
            "Collecting mistralai<0.2,>=0.1 (from langchain-mistralai)\n",
            "  Downloading mistralai-0.1.3-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tokenizers<0.16.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from langchain-mistralai) (0.15.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.0.3)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.110.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.9.15)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.1->duckduckgo-search) (1.16.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain-community) (1.33)\n",
            "Collecting httpx<0.26.0,>=0.25.2 (from mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas<3.0.0,>=2.2.0 (from mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow<16.0.0,>=15.0.0 (from mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (0.20.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.28->langchain-community) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12.0->curl-cffi>=0.6.1->duckduckgo-search) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai<0.2,>=0.1->langchain-mistralai) (1.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.28->langchain-community) (2.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai) (2023.4)\n",
            "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Installing collected packages: tzdata, pyarrow, lxml, pandas, httpx, curl-cffi, mistralai, duckduckgo-search, langchain-mistralai\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.9.4\n",
            "    Uninstalling lxml-4.9.4:\n",
            "      Successfully uninstalled lxml-4.9.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.0\n",
            "    Uninstalling httpx-0.27.0:\n",
            "      Successfully uninstalled httpx-0.27.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.21.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.1 which is incompatible.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed curl-cffi-0.6.2 duckduckgo-search-4.5.0 httpx-0.25.2 langchain-mistralai-0.0.5 lxml-5.1.0 mistralai-0.1.3 pandas-2.2.1 pyarrow-15.0.0 tzdata-2024.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose get API Keys and set all ENV vars\n"
      ],
      "metadata": {
        "id": "2Tsuhml_l9dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "OpenAI_api_key = userdata.get(\"OpenAIkey\")\n",
        "os.environ['OPENAI_API_KEY'] = OpenAI_api_key\n",
        "Mistral_api_key = userdata.get(\"MistralKey\")\n",
        "os.environ['MISTRAL_API_KEY'] = Mistral_api_key\n",
        "news_api_key = userdata.get('NewsAPI')\n",
        "os.environ['NEWS_API_KEY'] = news_api_key\n",
        "\n",
        "# LangChain tracing LLM usage and bugs with LangSmith: https://python.langchain.com/docs/langsmith/walkthrough\n",
        "LangChain_api_key = userdata.get('LangChain')\n",
        "os.environ['LANGCHAIN_API_KEY'] = LangChain_api_key\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"NewsAPI RAG\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "\n",
        "# if secretName == \"MistralKey\":\n",
        "#   os.environ['OPENAI_API_BASE']=\"https://api.mistral.ai/v1\"\n",
        "#   os.environ['OPENAI_MODEL_NAME']=\"mistral-small\"\n",
        "# else:\n",
        "os.environ['OPENAI_API_BASE']=\"https://api.openai.com/v1\"\n",
        "os.environ[\"OPENAI_MODEL_NAME\"]=\"gpt-4-0125-preview\""
      ],
      "metadata": {
        "id": "zoEVh9O-mLiu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "hQJeayklppTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1KHs1rqUlIow"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from langchain_openai import ChatOpenAI # tool to interact with OpenAI chat-style LLM's (like ChatGPT)\n",
        "from langchain_mistralai.chat_models import ChatMistralAI # tool to interact with Mistral chat-style LLM's\n",
        "from langchain_core.retrievers import BaseRetriever # Abstract base class for a Document retrieval system (search for documents by queries): https://api.python.langchain.com/en/latest/retrievers/langchain_core.retrievers.BaseRetriever.html\n",
        "from langchain_community.document_loaders import WebBaseLoader # 1. Load the content of specific URL\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # 2. Split web conent into chunks\n",
        "from langchain_openai import OpenAIEmbeddings # 3. Convert splited web content to Embedings with OpenAI embedding models by API = costs money: https://platform.openai.com/docs/guides/embeddings\n",
        "from langchain_community.vectorstores import Chroma # 4. Store embedings in Chroma DB\n",
        "from langchain.tools import tool # build a pipeline, chain of different tools. Each tool has a description. Agent uses the description to choose the right tool for the job.\n",
        "from langchain_community.tools import DuckDuckGoSearchRun # performs a web search in DuckDuckGo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set our TOOLs"
      ],
      "metadata": {
        "id": "yixN_0lyvORQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_function = OpenAIEmbeddings()\n",
        "llm_provider = \"OpenAI\" # @param [\"Mistral\", \"OpenAI\"] {type:\"string\"}\n",
        "if llm_provider == \"OpenAI\":\n",
        "  llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
        "elif llm_provider == \"Mistral\":\n",
        "  mistral_api_key = os.getenv('MISTRAL_API_KEY')\n",
        "  llm = ChatMistralAI(mistral_api_key=mistral_api_key)\n",
        "else:\n",
        "  print(\"choose LLM Provider\")\n",
        "\n",
        "# Tool 1 : Save the news articles in a Chroma database\n",
        "class SearchNewsDB:\n",
        "  @tool(\"News DB Tool\")\n",
        "  def news (query: str):\n",
        "    \"\"\"Fetch news articles and process their contents.\"\"\"\n",
        "    NEWS_API_KEY = os.getenv('NEWS_API_KEY') # Fetch API key from environnent var\n",
        "    base_url = \"https://newsapi.org/v2/everything\"\n",
        "    # FREE VERSION OF NEWS API provides:\n",
        "    # - articles 1 day old (not from today) and not older than 1 month\n",
        "    # - 100 requests per day\n",
        "\n",
        "    params = {\n",
        "      'q': query,\n",
        "      'sortBy': 'publishedAt',\n",
        "      'apiKey': NEWS_API_KEY,\n",
        "      ' language': 'en',\n",
        "      'ageSize': 5,\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params) # Fetch list of news articles returned for our query\n",
        "    if response.status_code != 200:\n",
        "      return \"Failed to retrieve news.\"\n",
        "\n",
        "    articles = response.json().get('articles', [])\n",
        "    all_splits = [] # all splits from all fetched articles\n",
        "    for article in articles:\n",
        "      # Assuming WebBaseLoader can handle a list of URLS\n",
        "      loader = WebBaseLoader(article['url']) # load the content of specific article from internet by it's URL\n",
        "      docs = loader.load() # execute the loading\n",
        "\n",
        "      # This text splitter is the recommended one for generic text (split by: paragraphs, sentences, words)\n",
        "      text_splitter = RecursiveCharacterTextSplitter(\n",
        "          # DOCS: https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter\n",
        "          # Set a really small chunk size, just to show.\n",
        "          chunk_size=1000,\n",
        "          chunk_overlap=200,\n",
        "          # length_function=len,\n",
        "          # is_separator_regex=False,\n",
        "      )\n",
        "      splits = text_splitter.split_documents(docs) # OR: create_documents([docs]), split_text(docs)[:2]\n",
        "      all_splits.extend(splits)\n",
        "\n",
        "    # Index the accumulated content splits if there are any\n",
        "    if all_splits:\n",
        "      # Chrome is Vector DB, same as Redis (key:value pairs)\n",
        "      # DOCS: https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
        "      vectorstore = Chroma.from_documents(all_splits, embedding=embedding_function, persist_directory=\"./chroma_db\")\n",
        "      retriever = vectorstore.similarity_search(query) # search all splits of all articles by similarity to our query\n",
        "      return retriever\n",
        "    else:\n",
        "      return \"No content available for processing.\"\n",
        "\n",
        "# Tool 2 : Get the news articles from the database\n",
        "class GetNews:\n",
        "  @tool(\"Get News Tool\")\n",
        "  def news(query: str) -> str:\n",
        "    \"\"\"Search Chroma DB for relevant news information based on a query.\"\"\"\n",
        "    vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)\n",
        "    retriever = vectorstore.similarity_search(query)\n",
        "    return retriever\n",
        "\n",
        "# Tool 3 : Search for news articles on the web\n",
        "search_tool = DuckDuckGoSearchRun()"
      ],
      "metadata": {
        "id": "fZkNzPwmmnLm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Agents"
      ],
      "metadata": {
        "id": "dqEYZPlpvapY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent\n",
        "\n",
        "default_max_rpm=40\n",
        "\n",
        "# 2. Creating Agents\n",
        "news_search_agent = Agent(\n",
        "  role='News Searcher',\n",
        "  goal='Generate key points for each news article from the latest news',\n",
        "  backstory=\"\"\"Expert in analysing and generating key points from news content\n",
        "    for quick summaries of the most important data and information.\n",
        "    Pasionate about finding inspiring, surprising and numeric data and creating insights based on them.\"\"\",\n",
        "  tools=[SearchNewsDB().news],\n",
        "  allow_delegation=True,\n",
        "  verbose=True,\n",
        "  # max_iter=5,\n",
        "  max_rpm=default_max_rpm,\n",
        "  memory=True,\n",
        "  llm=llm\n",
        ")\n",
        "\n",
        "writer_agent = Agent(\n",
        "  role='Writer',\n",
        "  goal='Identify all the topics received. Use the Get News Tool to verify the each topic and use search_tool to verify facts and get more information.',\n",
        "  backstory=\"\"\"Expert in crafting engaging narratives from complex information.\"\"\",\n",
        "  tools=[GetNews().news, search_tool], # RAG - retriving data from embedings\n",
        "  allow_delegation=True,\n",
        "  verbose=True,\n",
        "  # max_iter=5,\n",
        "  max_rpm=default_max_rpm,\n",
        "  memory=True,\n",
        "  llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "hn7xSYA_vbUQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create tasks"
      ],
      "metadata": {
        "id": "FGz_LEhXxIaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Task\n",
        "# 3. Creating Tasks\n",
        "search_phrase=\"AI in Training Employees and eLearning 2024\"  # @param {type:\"string\"}\n",
        "\n",
        "news_search_task = Task(\n",
        "  description=f'Search for {search_phrase} and create key points for each news.',\n",
        "  agent=news_search_agent,\n",
        "  tools=[SearchNewsDB().news],\n",
        "  output_file='news-search-key-points.md',\n",
        "  expected_output='A markdown file with key points for each news.'\n",
        ")\n",
        "\n",
        "writer_task = Task(\n",
        "  description=\"\"\"\n",
        "  Go step by step.\n",
        "  Identify all the topics received.\n",
        "  Use the Get News Tool to verify the each topic by going through one by one.\n",
        "  Use the Search tool to search for information on each topic one by one.\n",
        "  Go through every topic and write an in-depth summary of the information retrieved.\n",
        "  Don't skip any topic.\n",
        "  \"\"\",\n",
        "  agent=writer_agent,\n",
        "  context=[news_search_task],\n",
        "  tools= [GetNews().news, search_tool],\n",
        "  output_file='written-summaries.md',\n",
        "  expected_output='A markdown file with in-depth summaries of the information retrieved.'\n",
        ")"
      ],
      "metadata": {
        "id": "WNCKKg46xI3Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Crew"
      ],
      "metadata": {
        "id": "Gf3vwaBCnQ_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Process\n",
        "# 4. Creating Crew\n",
        "news_crew = Crew(\n",
        "  agents=[news_search_agent, writer_agent],\n",
        "  tasks=[news_search_task, writer_task],\n",
        "  process=Process.sequential, # we can test also with herarchical Process\n",
        "  manager_llm=llm\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2TZFEgYnThu",
        "outputId": "e7121b68-c8af-46d0-fcc4-74e47a16b92f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run and print results"
      ],
      "metadata": {
        "id": "XhOleSPDnmKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = news_crew.kickoff()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8omKZ0fnqop",
        "outputId": "48667549-88b9-415e-8a91-051798597d38"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To begin, I need to gather recent news articles related to \"AI in Training Employees and eLearning 2024\" to understand the latest trends, innovations, and data in this area. This will involve using the News DB Tool to fetch relevant articles.\n",
            "\n",
            "Action: News DB Tool\n",
            "Action Input: {\"query\": \"AI in Training Employees and eLearning 2024\"}\u001b[0m\u001b[93m \n",
            "\n",
            "[Document(page_content='February 8, 2024                                                                                                                        \\n\\n                                        8 minutes to read                                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n+2\\n                            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                            Comments                                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                Summary:                            \\n                            eLearning in onboarding employs technologies like VR, microlearning, and gamification to enhance new employee training efficiency. It customizes learning, boosting engagement and productivity, while benefiting both employees and organizations in a dynamic work environment.', metadata={'description': 'Employing eLearning mechanisms in onboarding enhances training efficiency, customizes learning, and benefits both employees and organizations.', 'language': 'en-US', 'source': 'https://elearningindustry.com/adaptive-onboarding-elearning-as-a-customized-tool', 'title': 'eLearning In Onboarding: 6 Mechanisms To Try'}), Document(page_content=\"March 1, 2024                                                                                                                        \\n\\n                                        7 minutes to read                                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n+2\\n                            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                            Comments                                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                Summary:                            \\n                            Discover the top 6 microlearning courses to supercharge employee career goals in 2024. From enhancing productivity to mastering new tech, these bite-sized programs are designed for immediate impact and flexible learning. Empower your team's growth and drive success in the workplace.\", metadata={'description': \"Discover the top 6 microlearning courses to supercharge employee career resolutions in 2024. Empower your team's growth now.\", 'language': 'en-US', 'source': 'https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions', 'title': 'Employee Career Resolutions: Microlearning Courses For Success'}), Document(page_content=\"2. AI And Machine Learning\\n\\nObjective\\nTo empower employees with AI and ML skills, addressing the increasing need for tech-savviness in today's digital landscape. It's all about staying relevant in a world where AI is reshaping how we work.\\nContent\\nThe course could cover AI fundamentals, practical applications of Machine Learning, and leveraging tools like ChatGPT for enhanced workplace efficiency. It's tailored to enhance existing skills with a focus on real-world applications.\\nEmployee benefits\\nEmployees will gain a competitive edge, enhance problem-solving abilities, and learn to implement AI solutions effectively. This knowledge makes them indispensable in a tech-driven work environment.\\nOrganizational impact\\nBy upskilling in AI and ML, organizations stay ahead of tech trends, drive innovation, and boost overall productivity. Implementing AI tools like ChatGPT can lead to smarter business strategies and improved decision-making.\\n\\n3. Business Skills (Customer-First Mentality)\", metadata={'description': \"Discover the top 6 microlearning courses to supercharge employee career resolutions in 2024. Empower your team's growth now.\", 'language': 'en-US', 'source': 'https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions', 'title': 'Employee Career Resolutions: Microlearning Courses For Success'}), Document(page_content=\"6 eLearning Mechanisms For An Improved Onboarding Process\\n1. Personalization\\nDeloitte's study reveals that organizations personalizing the onboarding process achieve 32% higher employee satisfaction. eLearning supports this through the customization of training materials to match individual preferences and learning styles. AI and Machine Learning tools allow for data analysis and the creation of personalized development paths (Data-Driven Persona), which are more engaging and effective for new employees than traditional methods. There are already organizations that, based on data sets and AI algorithms, apply advanced approaches in customer analysis and segmentation, utilizing large data sets to create detailed profiles of employees or customers.\", metadata={'description': 'Employing eLearning mechanisms in onboarding enhances training efficiency, customizes learning, and benefits both employees and organizations.', 'language': 'en-US', 'source': 'https://elearningindustry.com/adaptive-onboarding-elearning-as-a-customized-tool', 'title': 'eLearning In Onboarding: 6 Mechanisms To Try'})]\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: Now that I have the content of relevant news articles, I need to analyze and extract key points from each article to create insightful summaries. The first step is to process the content of each document to identify the most important information, focusing on innovative uses of AI in employee training and eLearning trends for 2024.\n",
            "\n",
            "Final Answer:\n",
            "### eLearning In Onboarding: 6 Mechanisms To Try\n",
            "- **Published Date:** February 8, 2024\n",
            "- **Source:** [eLearning Industry](https://elearningindustry.com/adaptive-onboarding-elearning-as-a-customized-tool)\n",
            "- **Summary:** \n",
            "  - eLearning in onboarding employs technologies like VR, microlearning, and gamification to enhance new employee training efficiency.\n",
            "  - Customization of learning boosts engagement and productivity, benefiting both employees and organizations in a dynamic work environment.\n",
            "  - Key mechanisms include the use of AI and Machine Learning tools for data analysis, creating personalized development paths, and improving the engagement through customization.\n",
            "  - A Deloitte study reveals that organizations personalizing the onboarding process achieve 32% higher employee satisfaction.\n",
            "\n",
            "### Employee Career Resolutions: Microlearning Courses For Success\n",
            "- **Published Date:** March 1, 2024\n",
            "- **Source:** [eLearning Industry](https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions)\n",
            "- **Summary:**\n",
            "  - The article introduces the top 6 microlearning courses designed to supercharge employee career goals in 2024.\n",
            "  - These courses focus on enhancing productivity, mastering new technologies, and are designed for immediate impact and flexible learning.\n",
            "  - Microlearning courses empower team growth and drive success in the workplace by providing bite-sized, actionable learning experiences.\n",
            "  - AI and ML skills training is highlighted as crucial for staying relevant in a tech-driven work environment, with courses covering AI fundamentals, practical Machine Learning applications, and tools like ChatGPT to enhance workplace efficiency.\n",
            "\n",
            "### Key Insights:\n",
            "- The integration of AI and ML in eLearning is becoming increasingly important for both onboarding and ongoing employee development.\n",
            "- Personalization and microlearning are key trends, offering more engaging, efficient, and tailored learning experiences.\n",
            "- Organizations leveraging these technologies report higher employee satisfaction and productivity, underlining the strategic value of innovative eLearning solutions in the contemporary workplace.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to verify the information presented in the topics received one by one, focusing initially on the first topic about eLearning in onboarding. To do this, I'll use the Get News Tool to find relevant news information based on this topic and verify the facts presented. This process will help ensure the accuracy and relevance of the information before summarizing it in-depth.\n",
            "\n",
            "Action: Get News Tool\n",
            "Action Input: {\"query\": \"eLearning in Onboarding February 2024\"}\u001b[0m\u001b[93m \n",
            "\n",
            "[Document(page_content='February 8, 2024                                                                                                                        \\n\\n                                        8 minutes to read                                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n+2\\n                            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                            Comments                                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                Summary:                            \\n                            eLearning in onboarding employs technologies like VR, microlearning, and gamification to enhance new employee training efficiency. It customizes learning, boosting engagement and productivity, while benefiting both employees and organizations in a dynamic work environment.', metadata={'description': 'Employing eLearning mechanisms in onboarding enhances training efficiency, customizes learning, and benefits both employees and organizations.', 'language': 'en-US', 'source': 'https://elearningindustry.com/adaptive-onboarding-elearning-as-a-customized-tool', 'title': 'eLearning In Onboarding: 6 Mechanisms To Try'}), Document(page_content=\"When, Where, And How To Use eLearning In Onboarding\\nEmployee onboarding plays a crucial role in adapting and retaining talents within an organization. In 2024, this is obvious, yet it's worth asking how the impact and results of onboarding can be strengthened with EdTech technologies. eLearning, as an integral part of this process, plays an irreplaceable role, offering personalization, flexibility, and scalability of training. It also allows for a significant reduction in the length of the adaptation process, and as we know, time is money.\\nThe Data\", metadata={'description': 'Employing eLearning mechanisms in onboarding enhances training efficiency, customizes learning, and benefits both employees and organizations.', 'language': 'en-US', 'source': 'https://elearningindustry.com/adaptive-onboarding-elearning-as-a-customized-tool', 'title': 'eLearning In Onboarding: 6 Mechanisms To Try'}), Document(page_content=\"March 1, 2024                                                                                                                        \\n\\n                                        7 minutes to read                                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n+2\\n                            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                            Comments                                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                Summary:                            \\n                            Discover the top 6 microlearning courses to supercharge employee career goals in 2024. From enhancing productivity to mastering new tech, these bite-sized programs are designed for immediate impact and flexible learning. Empower your team's growth and drive success in the workplace.\", metadata={'description': \"Discover the top 6 microlearning courses to supercharge employee career resolutions in 2024. Empower your team's growth now.\", 'language': 'en-US', 'source': 'https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions', 'title': 'Employee Career Resolutions: Microlearning Courses For Success'}), Document(page_content='eLearning For Onboarding: Engaging The Remote Workforce                                    \\n\\n\\n\\n                                        Why eLearning Is The Perfect Tool For Onboarding New Staff                                    \\n\\n\\n\\n                                        How To Develop An Onboarding eLearning Package: The Basics                                    \\n\\n\\n\\n                                        Takeoff To An Empowering Onboarding Experience With A Learning Platform                                    \\n\\n\\n\\n                                        6 Tips To Create Online Onboarding Training Experiences That Stick                                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Write or read Comments                                \\n\\n\\n\\n\\n\\n\\n\\n                                Close                                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\neLearning Industry', metadata={'description': 'Employing eLearning mechanisms in onboarding enhances training efficiency, customizes learning, and benefits both employees and organizations.', 'language': 'en-US', 'source': 'https://elearningindustry.com/adaptive-onboarding-elearning-as-a-customized-tool', 'title': 'eLearning In Onboarding: 6 Mechanisms To Try'})]\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: \n",
            "The information retrieved from the Get News Tool confirms the details provided in the first topic regarding eLearning in onboarding. The summaries and source material align closely with the initial summary, discussing the use of technologies like VR, microlearning, and gamification, along with the benefits of customizing the learning experience. Now, I need to move on to verifying the second topic about Employee Career Resolutions and Microlearning Courses for Success using the same tool to ensure accuracy and relevance.\n",
            "\n",
            "Action: Get News Tool\n",
            "Action Input: {\"query\": \"Employee Career Resolutions Microlearning March 2024\"}\u001b[0m\u001b[93m \n",
            "\n",
            "[Document(page_content=\"March 1, 2024                                                                                                                        \\n\\n                                        7 minutes to read                                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n+2\\n                            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                            Comments                                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                Summary:                            \\n                            Discover the top 6 microlearning courses to supercharge employee career goals in 2024. From enhancing productivity to mastering new tech, these bite-sized programs are designed for immediate impact and flexible learning. Empower your team's growth and drive success in the workplace.\", metadata={'description': \"Discover the top 6 microlearning courses to supercharge employee career resolutions in 2024. Empower your team's growth now.\", 'language': 'en-US', 'source': 'https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions', 'title': 'Employee Career Resolutions: Microlearning Courses For Success'}), Document(page_content='Employee Career Resolutions: Microlearning Courses For Success\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJoin our email list\\n\\n\\nPost an article\\n\\n\\nAdvertise\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\neLearning Industry\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDashboard\\n\\n\\nPortfolio\\n\\n\\nBilling\\n\\n\\nProfile\\n\\n\\n\\n\\n\\nSign Out\\n\\n\\n\\n\\n\\n\\n\\nLogin\\n\\n\\nRegister\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\neLearning Industry\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nResources\\nResources\\n\\n\\n\\n\\n\\n\\nArticles\\n\\n\\neBooks\\n\\n\\nWebinars\\n\\n\\n\\n\\neLearning Courses\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPublish your article with us and reach a large community of eLearning professionals\\nSee more\\n\\n\\n\\n\\n\\n\\n\\nSoftware & Services\\nSoftware & Services\\n\\n\\n\\n\\n\\n\\neLearning Software & Services\\n\\n\\nSoftware & Services Directories\\n\\n\\nThe Best Learning Management Systems\\n\\n\\nThe Best eLearning Content Providers\\n\\n\\nAll Top Lists\\n\\n\\nFind LMS Vendor\\n\\n\\nCreate Free Directory Listing\\n\\n\\n\\nSponsored\\nForever Free LMS\\n\\n\\n\\n\\n\\n\\nHR Software\\n\\n\\nHR Software Directories\\n\\n\\nTop HR Companies / HR Software - Register NOW\\n\\n\\n\\nBy', metadata={'description': \"Discover the top 6 microlearning courses to supercharge employee career resolutions in 2024. Empower your team's growth now.\", 'language': 'en-US', 'source': 'https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions', 'title': 'Employee Career Resolutions: Microlearning Courses For Success'}), Document(page_content='Driving Growth With Microlearning Courses\\nEntering 2024, employees across the globe have set career resolutions to upskill, reskill, and achieve new heights in their professional journeys. One method that is paving the way for such career advancements is microlearning. A microlearning solution, with its bite-sized, focused, and easily digestible modules, is transforming the way employees learn and grow. It aligns perfectly with the fast-paced corporate world, allowing employees to learn at their own pace, anytime, anywhere. In this article, we will explore the top six microlearning courses that are set to boost employee career resolutions in 2024. These courses, with their targeted and efficient learning approach, are poised to play a pivotal role in shaping the careers of many.\\nMicrolearning: A Key To Achieving Employee Career Resolutions', metadata={'description': \"Discover the top 6 microlearning courses to supercharge employee career resolutions in 2024. Empower your team's growth now.\", 'language': 'en-US', 'source': 'https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions', 'title': 'Employee Career Resolutions: Microlearning Courses For Success'}), Document(page_content=\"Microlearning: A Key To Achieving Employee Career Resolutions\\nEmployees' career resolutions are personal targets set for professional advancement, including skill development, promotions, or career transitions. These goals act as a guide, steering individuals on their desired career journey. The significance of these resolutions is substantial. They provide focus, spur motivation, and contribute to both personal and professional growth. In an ever-changing job landscape, clear career goals help maintain relevance and competitiveness. Enter microlearning: its concise and targeted approach makes it an excellent method for achieving these career aspirations. This is how it works:\", metadata={'description': \"Discover the top 6 microlearning courses to supercharge employee career resolutions in 2024. Empower your team's growth now.\", 'language': 'en-US', 'source': 'https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions', 'title': 'Employee Career Resolutions: Microlearning Courses For Success'})]\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: \n",
            "The results from the Get News Tool for the second topic about Employee Career Resolutions and Microlearning Courses for Success also align with the initial summary provided. The articles discuss the significance of microlearning courses in enhancing employee productivity, mastering new technologies, and providing flexible, immediate impact learning experiences. This verification confirms the accuracy and relevance of the second topic. Now, to complete the task, I need to summarize the information retrieved for both topics in-depth.\n",
            "\n",
            "Final Answer:\n",
            "### eLearning In Onboarding: 6 Mechanisms To Try\n",
            "\n",
            "**Published Date:** February 8, 2024  \n",
            "**Source:** [eLearning Industry](https://elearningindustry.com/adaptive-onboarding-elearning-as-a-customized-tool)\n",
            "\n",
            "**In-Depth Summary:**\n",
            "\n",
            "The adoption of eLearning in onboarding processes marks a significant shift towards employing advanced technologies like VR (Virtual Reality), microlearning, and gamification to enhance the efficiency of new employee training. This approach not only optimizes the learning experience by making it more engaging but also caters to the dynamic needs of the modern work environment by allowing for the customization of learning paths. Key mechanisms that are highlighted include:\n",
            "\n",
            "- **AI and Machine Learning Tools:** These are utilized for data analysis to create personalized development paths for employees, thereby improving engagement through customization.\n",
            "- **VR, Microlearning, and Gamification:** These technologies are used to make learning more interactive, engaging, and efficient, which is particularly beneficial in a remote or hybrid work setting.\n",
            "- **Benefits to Organizations:** A notable outcome of personalized onboarding processes is a significant increase in employee satisfaction. According to a study by Deloitte cited in the article, organizations that personalize the onboarding experience see a 32% higher employee satisfaction rate.\n",
            "\n",
            "This approach underscores the importance of integrating technology in onboarding processes to cater to the evolving expectations of new employees and the changing dynamics of work environments.\n",
            "\n",
            "### Employee Career Resolutions: Microlearning Courses For Success\n",
            "\n",
            "**Published Date:** March 1, 2024  \n",
            "**Source:** [eLearning Industry](https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions)\n",
            "\n",
            "**In-Depth Summary:**\n",
            "\n",
            "The article introduces six top microlearning courses aimed at supercharging employee career goals in 2024. These courses are designed to address the immediate learning needs of employees, enhancing their productivity and ability to master new technologies. The key features of these microlearning courses include:\n",
            "\n",
            "- **Focused Learning:** Courses are designed to provide bite-sized, actionable learning experiences, making it easier for employees to absorb and apply new knowledge.\n",
            "- **Flexibility:** The courses offer flexible learning options that fit within the busy schedules of working professionals, allowing them to learn at their own pace and on their own time.\n",
            "- **Immediate Impact:** Courses are developed with the goal of having an immediate impact on the learner’s ability to perform tasks or understand new concepts, thereby driving success in the workplace.\n",
            "- **AI and ML Skills Training:** Highlighting the importance of staying relevant in a tech-driven work environment, the courses offer training on AI fundamentals, practical Machine Learning applications, and tools like ChatGPT.\n",
            "\n",
            "By focusing on microlearning, the article emphasizes the strategic value of short, targeted courses in empowering team growth and achieving success in the workplace.\n",
            "\n",
            "### Key Insights:\n",
            "\n",
            "The integration of AI and Machine Learning in eLearning is becoming increasingly important for both onboarding and ongoing employee development. The focus on personalization and microlearning highlights a trend towards more engaging, efficient, and tailored learning experiences. Organizations leveraging these technologies not only report higher employee satisfaction but also see significant gains in productivity, underlining the strategic value of innovative eLearning solutions in the contemporary workplace.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "### eLearning In Onboarding: 6 Mechanisms To Try\n",
            "\n",
            "**Published Date:** February 8, 2024  \n",
            "**Source:** [eLearning Industry](https://elearningindustry.com/adaptive-onboarding-elearning-as-a-customized-tool)\n",
            "\n",
            "**In-Depth Summary:**\n",
            "\n",
            "The adoption of eLearning in onboarding processes marks a significant shift towards employing advanced technologies like VR (Virtual Reality), microlearning, and gamification to enhance the efficiency of new employee training. This approach not only optimizes the learning experience by making it more engaging but also caters to the dynamic needs of the modern work environment by allowing for the customization of learning paths. Key mechanisms that are highlighted include:\n",
            "\n",
            "- **AI and Machine Learning Tools:** These are utilized for data analysis to create personalized development paths for employees, thereby improving engagement through customization.\n",
            "- **VR, Microlearning, and Gamification:** These technologies are used to make learning more interactive, engaging, and efficient, which is particularly beneficial in a remote or hybrid work setting.\n",
            "- **Benefits to Organizations:** A notable outcome of personalized onboarding processes is a significant increase in employee satisfaction. According to a study by Deloitte cited in the article, organizations that personalize the onboarding experience see a 32% higher employee satisfaction rate.\n",
            "\n",
            "This approach underscores the importance of integrating technology in onboarding processes to cater to the evolving expectations of new employees and the changing dynamics of work environments.\n",
            "\n",
            "### Employee Career Resolutions: Microlearning Courses For Success\n",
            "\n",
            "**Published Date:** March 1, 2024  \n",
            "**Source:** [eLearning Industry](https://elearningindustry.com/top-microlearning-courses-to-boost-employee-career-resolutions)\n",
            "\n",
            "**In-Depth Summary:**\n",
            "\n",
            "The article introduces six top microlearning courses aimed at supercharging employee career goals in 2024. These courses are designed to address the immediate learning needs of employees, enhancing their productivity and ability to master new technologies. The key features of these microlearning courses include:\n",
            "\n",
            "- **Focused Learning:** Courses are designed to provide bite-sized, actionable learning experiences, making it easier for employees to absorb and apply new knowledge.\n",
            "- **Flexibility:** The courses offer flexible learning options that fit within the busy schedules of working professionals, allowing them to learn at their own pace and on their own time.\n",
            "- **Immediate Impact:** Courses are developed with the goal of having an immediate impact on the learner’s ability to perform tasks or understand new concepts, thereby driving success in the workplace.\n",
            "- **AI and ML Skills Training:** Highlighting the importance of staying relevant in a tech-driven work environment, the courses offer training on AI fundamentals, practical Machine Learning applications, and tools like ChatGPT.\n",
            "\n",
            "By focusing on microlearning, the article emphasizes the strategic value of short, targeted courses in empowering team growth and achieving success in the workplace.\n",
            "\n",
            "### Key Insights:\n",
            "\n",
            "The integration of AI and Machine Learning in eLearning is becoming increasingly important for both onboarding and ongoing employee development. The focus on personalization and microlearning highlights a trend towards more engaging, efficient, and tailored learning experiences. Organizations leveraging these technologies not only report higher employee satisfaction but also see significant gains in productivity, underlining the strategic value of innovative eLearning solutions in the contemporary workplace.\n"
          ]
        }
      ]
    }
  ]
}