{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXFpgTZstid5BSCZepYpfn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasMatuszewski/Python-colab-notebooks/blob/main/CrewAI_Chroma_RAG_NewsAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CrewAI RAG with Chroma DB and NewsAPI\n",
        "Based on [this YouTube video](https://www.youtube.com/watch?v=77xSbC-9yn4)"
      ],
      "metadata": {
        "id": "_tRhWzZnskyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "for Data / Dependencies Persistance we can save them in our Google drive\n",
        "Either as Virtual Env (for separation of packages if we install them for many different tools) or just by mounting Drive.\n",
        "\n",
        "More: https://stackoverflow.com/questions/55253498/how-do-i-install-a-library-permanently-in-colab\n",
        "\n",
        "More about mounting with Virtual Env:\n",
        "https://netraneupane.medium.com/how-to-install-libraries-permanently-in-google-colab-fb15a585d8a5"
      ],
      "metadata": {
        "id": "ObIGDpnUn_aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PERSISTENCE of dependencies!\n",
        "# to don't have to install dependencies each time we start a runtime, we can save files to Google Drive:\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "gdrive = '/content/notebooks'\n",
        "link_target = '/content/drive/My Drive/Colab Notebooks'\n",
        "if not os.path.islink(gdrive):  # Check if the symlink already exists\n",
        "    os.symlink(link_target, gdrive)  # Create it if it doesn't\n",
        "sys.path.insert(0,gdrive) # or append(nb_path)\n",
        "\n",
        "# and then we can install like this:\n",
        "# !pip install --target=$gdrive crewai\n",
        "\n",
        "\n",
        "# ALTERNATIVE: Virtual Environment:\n",
        "\n",
        "# Install virtualenv:\n",
        "# !pip install virtualenv\n",
        "\n",
        "# # Mount Google Drive:\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")\n",
        "\n",
        "# # Activate Virtual Environment and Install required libraries:\n",
        "# !virtualenv /content/drive/MyDrive/vir_env\n",
        "# !source /content/drive/MyDrive/vir_env/bin/activate; pip install numpy\n",
        "\n",
        "# # Adding the Virtual Environment to sys.path:\n",
        "# import sys\n",
        "# sys.path.append(\"/content/drive/MyDrive/vir_env/lib/python3.10/site-packages\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pCJmTbe3n-xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995a6d48-ed74-4947-c981-c6fecc6e5cd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "pLTW7fsElT32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install only once. Tomorrow, you can skip this (it will be loaded from Google Drive)\n",
        "\n",
        "!pip install --target=$gdrive crewai\n",
        "!pip install --target=$gdrive 'crewai[tools]'\n",
        "!pip install --target=$gdrive duckduckgo-search langchain-community langchain-openai langchain-mistralai requests chromadb\n",
        "!pip install chromadb\n",
        "# !pip install groq\n",
        "!pip install --target=$gdrive langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP46fbRml_lM",
        "outputId": "e4c09a23-cb63-4630-b0f3-95476cf63d59"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai\n",
            "  Using cached crewai-0.19.0-py3-none-any.whl (42 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai) (8.1.7)\n",
            "Collecting instructor<0.6.0,>=0.5.2 (from crewai)\n",
            "  Using cached instructor-0.5.2-py3-none-any.whl (33 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai)\n",
            "  Using cached langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "Collecting langchain-openai<0.0.6,>=0.0.5 (from crewai)\n",
            "  Using cached langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Collecting openai<2.0.0,>=1.13.3 (from crewai)\n",
            "  Using cached openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.23.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_http-1.23.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai) (1.23.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.6.3)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /usr/local/lib/python3.10/dist-packages (from crewai) (2023.12.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (3.9.3)\n",
            "Collecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai)\n",
            "  Using cached docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (8.2.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai) (0.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (2.0.28)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Using cached langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.29 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (0.1.30)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (0.1.22)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai) (2.31.0)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai<0.0.6,>=0.0.5->crewai)\n",
            "  Using cached tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai) (4.10.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (1.23.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.23.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (3.20.3)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai) (0.44b0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai) (2.16.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai) (1.14.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai) (3.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain<0.2.0,>=0.1.10->crewai) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.10->crewai) (3.9.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.10->crewai) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.10->crewai) (3.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, docstring-parser, typing-inspect, tiktoken, openai, dataclasses-json, opentelemetry-exporter-otlp-proto-http, instructor, langchain-text-splitters, langchain-openai, langchain-community, langchain, crewai\n",
            "Successfully installed crewai-0.19.0 dataclasses-json-0.6.4 docstring-parser-0.15 instructor-0.5.2 langchain-0.1.11 langchain-community-0.0.27 langchain-openai-0.0.5 langchain-text-splitters-0.0.1 marshmallow-3.21.1 mypy-extensions-1.0.0 openai-1.13.3 opentelemetry-exporter-otlp-proto-http-1.23.0 tiktoken-0.5.2 typing-inspect-0.9.0\n",
            "Requirement already satisfied: crewai[tools] in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (8.1.7)\n",
            "Requirement already satisfied: instructor<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (0.5.2)\n",
            "Requirement already satisfied: langchain<0.2.0,>=0.1.10 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (0.1.11)\n",
            "Requirement already satisfied: langchain-openai<0.0.6,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (0.0.5)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (1.13.3)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (2.6.3)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /usr/local/lib/python3.10/dist-packages (from crewai[tools]) (2023.12.25)\n",
            "Collecting crewai-tools<0.0.16,>=0.0.15 (from crewai[tools])\n",
            "  Using cached crewai_tools-0.0.15-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (4.12.3)\n",
            "Requirement already satisfied: chromadb<0.5.0,>=0.4.22 in /usr/local/lib/python3.10/dist-packages (from crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.4.24)\n",
            "Collecting embedchain[github,youtube]<0.2.0,>=0.1.85 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached embedchain-0.1.94-py3-none-any.whl (190 kB)\n",
            "Collecting lancedb<0.6.0,>=0.5.4 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
            "Collecting pyright<2.0.0,>=1.1.350 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached pyright-1.1.352-py3-none-any.whl (18 kB)\n",
            "Collecting pytest<9.0.0,>=8.0.0 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached pytest-8.0.2-py3-none-any.whl (333 kB)\n",
            "Collecting pytube<16.0.0,>=15.0.0 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.31.0)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached selenium-4.18.1-py3-none-any.whl (10.0 MB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (3.9.3)\n",
            "Requirement already satisfied: docstring-parser<0.16,>=0.15 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (0.15)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (8.2.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor<0.6.0,>=0.5.2->crewai[tools]) (0.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (2.0.28)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.0.27)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.29 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.1.30)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (0.1.22)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.10->crewai[tools]) (1.25.2)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai<0.0.6,>=0.0.5->crewai[tools]) (0.5.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.13.3->crewai[tools]) (4.10.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.19 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.23.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai[tools]) (3.20.3)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai[tools]) (0.44b0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai[tools]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai[tools]) (2.16.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor<0.6.0,>=0.5.2->crewai[tools]) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai[tools]) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.13.3->crewai[tools]) (1.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.1.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.110.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.27.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.5.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.17.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.44b0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (6.1.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.62.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (4.1.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (29.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.9.15)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (0.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (1.14.1)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.43.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached gptcache-0.1.43-py3-none-any.whl (131 kB)\n",
            "Collecting pypdf<4.0.0,>=3.11.0 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.0.1)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Collecting PyGithub<2.0.0,>=1.59.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
            "Collecting gitpython<4.0.0,>=3.1.38 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.13.3->crewai[tools]) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai[tools]) (3.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai[tools]) (2.4)\n",
            "Collecting deprecation (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "Collecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (5.3.3)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.10/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (14.0.2)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain<0.2.0,>=0.1.10->crewai[tools]) (23.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.4.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai[tools]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai[tools]) (2.16.1)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached trio-0.24.0-py3-none-any.whl (460 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.10->crewai[tools]) (3.0.3)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.0.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.36.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.23.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.0.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor<0.6.0,>=0.5.2->crewai[tools]) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=1.6.0->pyright<2.0.0,>=1.1.350->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (67.7.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.12)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.44b0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.2.1)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema<0.8.0,>=0.7.5->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (21.6.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.20.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.10->crewai[tools]) (1.0.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3<3,>=1.21.1->requests<3.0.0,>=2.31.0->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (12.0)\n",
            "Collecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "Collecting pycryptodomex (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Collecting brotli (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools])\n",
            "  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.7.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2023.6.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.16.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (2.21)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai-tools<0.0.16,>=0.0.15->crewai[tools]) (0.5.1)\n",
            "Installing collected packages: ratelimiter, brotli, wsproto, smmap, semver, schema, pytube, pytest, pysbd, pypdf, pyjwt, pycryptodomex, py, outcome, nodeenv, mutagen, Mako, deprecation, yt_dlp, youtube-transcript-api, trio, retry, pyright, pynacl, pylance, gptcache, gitdb, alembic, trio-websocket, lancedb, gitpython, selenium, PyGithub, embedchain, crewai-tools\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed Mako-1.3.2 PyGithub-1.59.1 alembic-1.13.1 brotli-1.1.0 crewai-tools-0.0.15 deprecation-2.1.0 embedchain-0.1.94 gitdb-4.0.11 gitpython-3.1.42 gptcache-0.1.43 lancedb-0.5.7 mutagen-1.47.0 nodeenv-1.8.0 outcome-1.3.0.post0 py-1.11.0 pycryptodomex-3.20.0 pyjwt-2.8.0 pylance-0.9.18 pynacl-1.5.0 pypdf-3.17.4 pyright-1.1.352 pysbd-0.3.4 pytest-8.0.2 pytube-15.0.0 ratelimiter-1.2.0.post0 retry-0.9.2 schema-0.7.5 selenium-4.18.1 semver-3.0.2 smmap-5.0.1 trio-0.24.0 trio-websocket-0.11.1 wsproto-1.2.0 youtube-transcript-api-0.6.2 yt_dlp-2023.12.30\n",
            "Collecting duckduckgo-search\n",
            "  Using cached duckduckgo_search-5.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.27)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.0.5)\n",
            "Collecting langchain-mistralai\n",
            "  Using cached langchain_mistralai-0.0.5-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting curl-cffi>=0.6.2 (from duckduckgo-search)\n",
            "  Using cached curl_cffi-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "Collecting lxml>=5.1.0 (from duckduckgo-search)\n",
            "  Using cached lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.30 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.30)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.22)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.2.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.13.3)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.5.2)\n",
            "Collecting mistralai<0.2,>=0.1 (from langchain-mistralai)\n",
            "  Using cached mistralai-0.1.3-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tokenizers<0.16.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from langchain-mistralai) (0.15.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.1.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.110.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.9.15)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.6.2->duckduckgo-search) (1.16.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain-community) (1.33)\n",
            "Collecting httpx<0.26.0,>=0.25.2 (from mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Using cached httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "Collecting pandas<3.0.0,>=2.2.0 (from mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Using cached pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Collecting pyarrow<16.0.0,>=15.0.0 (from mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Using cached pyarrow-15.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (0.20.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.30->langchain-community) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12.0->curl-cffi>=0.6.2->duckduckgo-search) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai<0.2,>=0.1->langchain-mistralai) (1.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.30->langchain-community) (2.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai) (2023.4)\n",
            "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Installing collected packages: tzdata, pyarrow, lxml, pandas, httpx, curl-cffi, mistralai, duckduckgo-search, langchain-mistralai\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.9.4\n",
            "    Uninstalling lxml-4.9.4:\n",
            "      Successfully uninstalled lxml-4.9.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.0\n",
            "    Uninstalling httpx-0.27.0:\n",
            "      Successfully uninstalled httpx-0.27.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.1 which is incompatible.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed curl-cffi-0.6.2 duckduckgo-search-5.0 httpx-0.25.2 langchain-mistralai-0.0.5 lxml-5.1.0 mistralai-0.1.3 pandas-2.2.1 pyarrow-15.0.1 tzdata-2024.1\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.24)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.1.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.110.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.9.15)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.23.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.4.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.1.30)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-groq) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-groq) (0.1.22)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-groq) (23.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-groq) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain-groq) (8.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-groq) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-groq) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-groq) (2.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get API Keys and set all ENV vars\n"
      ],
      "metadata": {
        "id": "2Tsuhml_l9dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "OpenAI_api_key = userdata.get(\"OpenAIkey\")\n",
        "os.environ['OPENAI_API_KEY'] = OpenAI_api_key\n",
        "Mistral_api_key = userdata.get(\"MistralKey\")\n",
        "os.environ['MISTRAL_API_KEY'] = Mistral_api_key\n",
        "\n",
        "Groq_api_key = userdata.get(\"GroqKey\")\n",
        "os.environ['GROQ_API_KEY'] = Groq_api_key\n",
        "\n",
        "news_api_key = userdata.get('NewsAPI')\n",
        "os.environ['NEWS_API_KEY'] = news_api_key\n",
        "\n",
        "# LangChain tracing LLM usage and bugs with LangSmith: https://python.langchain.com/docs/langsmith/walkthrough\n",
        "LangChain_api_key = userdata.get('LangChain')\n",
        "os.environ['LANGCHAIN_API_KEY'] = LangChain_api_key\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"NewsAPI RAG\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "\n",
        "# if secretName == \"MistralKey\":\n",
        "#   os.environ['OPENAI_API_BASE']=\"https://api.mistral.ai/v1\"\n",
        "#   os.environ['OPENAI_MODEL_NAME']=\"mistral-small\"\n",
        "# else:\n",
        "os.environ['OPENAI_API_BASE']=\"https://api.openai.com/v1\"\n",
        "os.environ[\"OPENAI_MODEL_NAME\"]=\"gpt-4-0125-preview\""
      ],
      "metadata": {
        "id": "zoEVh9O-mLiu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "hQJeayklppTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1KHs1rqUlIow"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "from langchain_openai import ChatOpenAI # tool to interact with OpenAI chat-style LLM's (like ChatGPT)\n",
        "from langchain_mistralai.chat_models import ChatMistralAI # tool to interact with Mistral chat-style LLM's\n",
        "from langchain_core.retrievers import BaseRetriever # Abstract base class for a Document retrieval system (search for documents by queries): https://api.python.langchain.com/en/latest/retrievers/langchain_core.retrievers.BaseRetriever.html\n",
        "from langchain_community.document_loaders import WebBaseLoader # 1. Load the content of specific URL\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # 2. Split web conent into chunks\n",
        "from langchain_openai import OpenAIEmbeddings # 3. Convert splited web content to Embedings with OpenAI embedding models by API = costs money: https://platform.openai.com/docs/guides/embeddings\n",
        "from langchain_community.vectorstores import Chroma # 4. Store embedings in Chroma DB\n",
        "from langchain.tools import tool # build a pipeline, chain of different tools. Each tool has a description. Agent uses the description to choose the right tool for the job.\n",
        "from langchain_community.tools import DuckDuckGoSearchRun # performs a web search in DuckDuckGo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set our TOOLs"
      ],
      "metadata": {
        "id": "yixN_0lyvORQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "embedding_function = OpenAIEmbeddings()\n",
        "llm_provider = \"Groq\" # @param [\"Mistral\", \"OpenAI\", \"Groq\"] {type:\"string\"}\n",
        "if llm_provider == \"OpenAI\":\n",
        "  llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
        "elif llm_provider == \"Mistral\":\n",
        "  mistral_api_key = os.getenv('MISTRAL_API_KEY')\n",
        "  llm = ChatMistralAI(mistral_api_key=mistral_api_key)\n",
        "elif llm_provider == \"Groq\":\n",
        "  # https://python.langchain.com/docs/integrations/chat/groq\n",
        "  # from groq import Groq\n",
        "  from langchain_groq import ChatGroq\n",
        "  groq_api_key = os.getenv('GROQ_API_KEY')\n",
        "  llm = ChatGroq(temperature=0.5, groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\")\n",
        "else:\n",
        "  print(\"choose LLM Provider\")\n",
        "\n",
        "# Tool 1 : Save the news articles in a Chroma database\n",
        "class SearchNewsDB:\n",
        "  @tool(\"News DB Tool\")\n",
        "  def news (query: str):\n",
        "    \"\"\"Fetch news articles and process their contents.\"\"\"\n",
        "    NEWS_API_KEY = os.getenv('NEWS_API_KEY') # Fetch API key from environnent var\n",
        "    base_url = \"https://newsapi.org/v2/everything\"\n",
        "    # FREE VERSION OF NEWS API provides:\n",
        "    # - articles 1 day old (not from today) and not older than 1 month\n",
        "    # - 100 requests per day\n",
        "\n",
        "    print(f'>>>> query: {query}')\n",
        "\n",
        "    params = {\n",
        "      'q': query,\n",
        "      'sortBy': 'publishedAt',\n",
        "      'apiKey': NEWS_API_KEY,\n",
        "      'language': 'en',\n",
        "      'ageSize': 5,\n",
        "      'pageSize': 20\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params) # Fetch list of news articles returned for our query\n",
        "    if response.status_code != 200:\n",
        "      return \"Failed to retrieve news.\"\n",
        "\n",
        "    articles = response.json().get('articles', [])\n",
        "    all_splits = [] # all splits from all fetched articles\n",
        "    for article in articles:\n",
        "      print(f'article: {article[\"title\"]}')\n",
        "      print(f'article: {article[\"url\"]}')\n",
        "      # Assuming WebBaseLoader can handle a list of URLS\n",
        "      loader = WebBaseLoader(article['url']) # load the content of specific article from internet by it's URL\n",
        "      # loader.requests_kwargs = {\"verify\":False}\n",
        "      docs = loader.load() # execute the loading\n",
        "\n",
        "      # This text splitter is the recommended one for generic text (split by: paragraphs, sentences, words)\n",
        "      text_splitter = RecursiveCharacterTextSplitter(\n",
        "          # DOCS: https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter\n",
        "          # Set a really small chunk size, just to show.\n",
        "          chunk_size=1000,\n",
        "          chunk_overlap=200,\n",
        "          # length_function=len,\n",
        "          # is_separator_regex=False,\n",
        "      )\n",
        "      splits = text_splitter.split_documents(docs) # OR: create_documents([docs]), split_text(docs)[:2]\n",
        "      print(f'Splits: {splits}')\n",
        "      all_splits.extend(splits)\n",
        "\n",
        "    # Index the accumulated content splits if there are any\n",
        "    if all_splits:\n",
        "      # Chrome is Vector DB, same as Redis (key:value pairs)\n",
        "      # DOCS: https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
        "      vectorstore = Chroma.from_documents(all_splits, embedding=embedding_function, persist_directory=\"./chroma_db\")\n",
        "      retriever = vectorstore.similarity_search(query) # search all splits of all articles by similarity to our query\n",
        "      print(f'>>>>>> News DB Tool retriever: {retriever}')\n",
        "      return retriever\n",
        "    else:\n",
        "      return \"No content available for processing.\"\n",
        "\n",
        "# Tool 2 : Get the news articles from the database\n",
        "class GetNews:\n",
        "  @tool(\"Get News Tool\")\n",
        "  def news(query: str) -> str:\n",
        "    \"\"\"Search Chroma DB for relevant news information based on a query.\"\"\"\n",
        "    vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)\n",
        "    retriever = vectorstore.similarity_search(query)\n",
        "    print(f'>>>>>> Get News Tool retriever: {retriever}')\n",
        "    return retriever\n",
        "\n",
        "# Tool 3 : Search for news articles on the web\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "\n",
        "# Tool 4 : sanitize query to make safe filename\n",
        "import re\n",
        "class SanitizeFilename:\n",
        "  @tool(\"Sanitize Filename\")\n",
        "  def sanitize(query):\n",
        "      \"\"\"Removes unsafe characters and replaces spaces with hyphens.\"\"\"\n",
        "      # Characters to keep: letters, numbers, hyphens, underscores\n",
        "      safe_chars = r\" -_a-zA-Z0-9\"\n",
        "      # Regex to match anything NOT in your safe characters\n",
        "      unsafe_pattern = re.compile(rf\"[^{safe_chars}]\")\n",
        "      # Replace unsafe parts with an empty string\n",
        "      sanitized_query = unsafe_pattern.sub(\"\", query)\n",
        "      # Replace spaces with hyphens\n",
        "      return sanitized_query.replace(\" \", \"-\")\n"
      ],
      "metadata": {
        "id": "fZkNzPwmmnLm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Agents"
      ],
      "metadata": {
        "id": "dqEYZPlpvapY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent\n",
        "\n",
        "default_max_rpm=40\n",
        "\n",
        "# 2. Creating Agents\n",
        "news_search_agent = Agent(\n",
        "  role='News Searcher',\n",
        "  goal='Generate key points for each news article from the latest news. Use Markdown formatting',\n",
        "  backstory=\"\"\"Expert in analysing and generating key points from news content\n",
        "    for quick summaries of the most important data and information.\n",
        "    Pasionate about finding inspiring, surprising and numeric data and creating insights based on them.\n",
        "    You specialize in finding information about Business, HR, Education and IT / Tech startups.\n",
        "    You make analysis for Hacker News, TechCrunch and Mashable.\n",
        "    You write in light, informal style, with small jokes and little irony, but still very professional.\n",
        "    You always add exact links to sources of the information.\n",
        "    You like to write a well structured text formatted in Markdown, with Headers, subheaders, quotes and bolded important fragments.\"\"\",\n",
        "  tools=[SearchNewsDB().news],\n",
        "  allow_delegation=False,\n",
        "  verbose=True,\n",
        "  # max_iter=6,\n",
        "  max_rpm=default_max_rpm,\n",
        "  memory=True,\n",
        "  llm=llm\n",
        ")\n",
        "\n",
        "writer_agent = Agent(\n",
        "  role='Writer',\n",
        "  goal=\"\"\"Identify all the topics received. Use the search_tool to verify the each topic delivered by News Searcher agent.\n",
        "    Verify facts and get more information on each topic provided. Write engaging articles based on all data using Markdown formatting.\"\"\",\n",
        "  backstory=\"\"\"Expert in crafting engaging narratives from complex information.\n",
        "    You specialize in translating articles about Business, HR, Education and IT / Tech startups.\n",
        "    You write for Hacker News, TechCrunch and Mashable.\n",
        "    You write in light, informal style, with small jokes and little irony, but still very professional.\n",
        "    You always add exact links to sources of the information.\n",
        "    You like to write a well structured text formatted in Markdown, with Headers, subheaders, quotes and bolded important fragments.\"\"\",\n",
        "  tools=[GetNews().news, search_tool], # RAG - retriving data from embedings\n",
        "  allow_delegation=False,\n",
        "  verbose=True,\n",
        "  # max_iter=5,\n",
        "  max_rpm=default_max_rpm,\n",
        "  memory=True,\n",
        "  llm=llm\n",
        ")\n",
        "\n",
        "translator_agent = Agent(\n",
        "  role='Translator',\n",
        "  goal=\"\"\"Make a well structured Polish translation of articles from Writer agent and News Searcher agent, use natural native polish language\"\"\",\n",
        "  backstory=\"\"\"Expert translator, half-polish and half-american origins, both languages are your native languages.\n",
        "    You specialize in translating articles about Business, HR, Education and IT / Tech startups.\n",
        "    You translate articles from Hacker News, TechCrunch and Mashable to polish media like Mam Startup, Business Insider, Startup Magazine and My Company.\n",
        "    You write in light, informal style, with small jokes and little irony, but still very professional.\n",
        "    You always add exact links to sources of the information.\n",
        "    You like to write a well structured text formatted in Markdown, with Headers, subheaders, quotes and bolded important fragments.\"\"\",\n",
        "  allow_delegation=False,\n",
        "  verbose=True,\n",
        "  # max_iter=2,\n",
        "  max_rpm=default_max_rpm,\n",
        "  memory=True,\n",
        "  llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "hn7xSYA_vbUQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create tasks"
      ],
      "metadata": {
        "id": "FGz_LEhXxIaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Task\n",
        "from datetime import datetime\n",
        "\n",
        "# 3. Creating Tasks\n",
        "search_phrase=\"Large Language Models, LLM, AI\"  # @param {type:\"string\"}\n",
        "\n",
        "clean_phrase = SanitizeFilename().sanitize(search_phrase)\n",
        "\n",
        "# Get current datetime\n",
        "now = datetime.now()\n",
        "formatted_datetime = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "news_search_task = Task(\n",
        "  description=f'Search once for {search_phrase} and create key points for most interesting news.',\n",
        "  agent=news_search_agent,\n",
        "  tools=[SearchNewsDB().news],\n",
        "  output_file=f\"{clean_phrase}--search-{formatted_datetime}.md\",\n",
        "  expected_output='A Markdown formatted text with key points for most interesting news and with exact links to the source in markdown format.'\n",
        ")\n",
        "\n",
        "writer_task = Task(\n",
        "  description=\"\"\"\n",
        "  Go step by step.\n",
        "  Identify all the topics received.\n",
        "  Use the Get News Tool to verify each topic by going through one by one.\n",
        "  Use the Search tool to search for more information on each topic one by one.\n",
        "  Go through every topic and write an in-depth article based on the information retrieved.\n",
        "  Don't skip any topic.\n",
        "  Add 3 short tags for most important information in a form: #tag-1-name #tag-2-name.\n",
        "  Use Markdown formatting, paragraphs, headers, subheaders, quotes, links to sources and bold text for important fragments.\n",
        "  \"\"\",\n",
        "  agent=writer_agent,\n",
        "  context=[news_search_task],\n",
        "  tools= [GetNews().news, search_tool],\n",
        "  output_file=f\"{clean_phrase}--summary-{formatted_datetime}.md\",\n",
        "  expected_output='A Markdown formatted article with in-depth summaries of the information retrieved and with exact link to the source in markedown format.'\n",
        ")\n",
        "\n",
        "translator_task = Task(\n",
        "  description=\"\"\"\n",
        "  Go step by step.\n",
        "  Translate each paragraph of text, but try to use natural polish language, not exact translation.\n",
        "  Write articles in natural Polish language on the same topics, with the same information provided.\n",
        "  Go through every topic and make sure you didn't omit any information and didn't make new facts not provided.\n",
        "  Don't skip any topic.\n",
        "  Add 3 short tags in Polish for most important information in a form: #tag-1-name #tag-2-name.\n",
        "  Use Markdown formatting, paragraphs, headers, subheaders, quotes, links to sources and bold text for important fragments.\n",
        "  \"\"\",\n",
        "  agent=translator_agent,\n",
        "  context=[news_search_task, writer_task],\n",
        "  output_file=f\"{clean_phrase}--translation-{formatted_datetime}.md\",\n",
        "  expected_output='A Markdown formatted text with polish translation of article retrieved and with exact link to the source in markedown format.'\n",
        ")"
      ],
      "metadata": {
        "id": "WNCKKg46xI3Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Crew"
      ],
      "metadata": {
        "id": "Gf3vwaBCnQ_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Process\n",
        "# 4. Creating Crew\n",
        "news_crew = Crew(\n",
        "  agents=[news_search_agent, writer_agent, translator_agent],\n",
        "  tasks=[news_search_task, writer_task, translator_task],\n",
        "  process=Process.sequential, # we can test also with herarchical Process\n",
        "  verbose=3,\n",
        "  manager_llm=llm\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2TZFEgYnThu",
        "outputId": "74c8c635-d9f5-40de-b42a-0766b0f13f20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run and print results"
      ],
      "metadata": {
        "id": "XhOleSPDnmKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "result = news_crew.kickoff()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8omKZ0fnqop",
        "outputId": "ca8660f8-2907-4ba9-a4f9-35873d94234e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG]: Working Agent: News Searcher\n",
            "[INFO]: Starting Task: Search once for Large Language Models, LLM, AI and create key points for most interesting news.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSure, I'm ready to generate key points for the most interesting news about Large Language Models (LLM), AI!\n",
            "\n",
            "Action: News DB Tool\n",
            "Action Input: {\"query\": \"Large Language Models OR LLM OR AI\"}\n",
            "\u001b[0m>>>> query: Large Language Models OR LLM OR AI\n",
            "article: Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline (March 17, 2024)\n",
            "article: https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html\n",
            "Splits: [Document(page_content='Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nW3C home\\nMailing lists\\nPublic\\nsemantic-web@w3.org\\nMarch 2024\\n\\n\\nDeadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThis message: Message body\\nRespond\\nMore options\\n\\n\\nRelated messages: \\n\\nNext message\\nPrevious message\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom: Dr. Sanju Tiwari <sanju.tiwari.2007@gmail.com>\\n\\nDate: Thu, 7 Mar 2024 08:33:37 +0530\\nTo: semantic-web@w3.org, announcements@ubicomp.org, tccc-announce@comsoc.org,  wi@lists.kit.edu, dl@dl.kr.org, public-lod <public-lod@w3.org>\\n\\nMessage-ID: <CAOprRZ+dVJjaKpuuaCby9vEKaxD1wEEKaf++WrJZegqcQrnvOg@mail.gmail.com>\\n\\n\\n\\n\\n*INTERNATIONAL WORKSHOP ON KNOWLEDGE GRAPH GENERATION FROM TEXT (TEXT2KG\\n2024) collocated with ESWC 2024*', metadata={'source': 'https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)', 'language': 'en'}), Document(page_content='Message-ID: <CAOprRZ+dVJjaKpuuaCby9vEKaxD1wEEKaf++WrJZegqcQrnvOg@mail.gmail.com>\\n\\n\\n\\n\\n*INTERNATIONAL WORKSHOP ON KNOWLEDGE GRAPH GENERATION FROM TEXT (TEXT2KG\\n2024) collocated with ESWC 2024*\\n\\n*Workshop website*: https://aiisc.ai/text2kg2024/\\n*Paper Submission: *7th March 2024 (AoE time) 17th of March 2024 (AoE time)\\n\\n\\nThis workshop aims to bring together researchers from multiple focus areas\\nsuch as Natural Language Processing (NLP), Entity Linking (EL), Relation\\nExtraction (RE), Knowledge Representation and Reasoning (KRR), Deep\\nLearning (DL), Knowledge Base Construction (KBC), Large Language Models\\n(LLMs), Semantic Web, Linked Data, and other related fields to foster a\\ndiscussion and enhance the state-of-the-art in knowledge graph generation\\nfrom text.', metadata={'source': 'https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)', 'language': 'en'}), Document(page_content='The participants will find opportunities to present and hear about other\\nemerging research and applications, to exchange ideas and experiences, and\\nto identify new opportunities for collaborations across disciplines. We\\nplan to involve the many prominent research groups in the Semantic Web\\ncommunity which in the last years focused on the generation of knowledge\\ngraphs from textual sources in different fields, such as research data\\n(ORKG, AI-KG, Nano publications), question answering (ParaQA, NSQA), common\\nsense (CSKG), automotive (CoSI, ASKG), biomedical (Hetionet), and many\\nothers.\\n\\n*THEMES & TOPICS*\\n\\nWe are interested in (including but not limited to) the following themes\\nand topics that study the generation of Knowledge Graphs from text, based\\non quantitative, qualitative, and mixed research methods.', metadata={'source': 'https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)', 'language': 'en'}), Document(page_content='- Approaches for generating Knowledge Graphs from text\\n   -  Ontologies for representing provenance/metadata of generated\\n   Knowledge Graphs\\n   -  Benchmarks for KG generation from text\\n   -  Evaluation methods for KGs generated from text\\n   - Open Information Extraction\\n   -  Deep Learning and Generative approaches\\n   -  Human-in-the-loop methods\\n   - Large Language Models and Knowledge Graphs\\n   -\\n   - Industrial applications involving KGs generation from text\\n   -  Entity and relation extraction\\n   -  Entity and relation linking\\n   -  Semantic Parsing\\n   -\\n\\n* IMPORTANT DATES*\\n\\nPaper submissions due: March 17, 2024\\n\\nFinal decision notification: April 4, 2024\\n\\nCamera-ready submissions due: April 18th, 2024\\n\\n\\n*Keynote Speaker*\\n\\n*Paul Groth, *University of Amsterdam\\n\\n\\n*Industry Talk*\\n\\n*Prasad Yalamanchi, *Lead Semantics, United States\\n\\n\\n*Submission Instructions*', metadata={'source': 'https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)', 'language': 'en'}), Document(page_content='*Submission Instructions*\\n\\nWe invite full research papers, negative results, position papers, dataset\\nand system demo papers. Submissions must be original and should not have\\nbeen published previously or be under consideration for publication while\\nbeing evaluated for this workshop. Submissions will be evaluated by the\\nprogram committee based on the quality of the work and its fit to the\\nworkshop themes. All submissions are double-blind and a high-resolution PDF\\nof the paper should be uploaded to the EasyChair submission site before the\\npaper submission deadline. The accepted papers will be presented at the\\nText2KG workshop integrated with the conference, and they will be published\\nas CEUR proceedings. All must be submitted and formatted in the style of\\nthe CEUR proceedings format. For details on CEUR style, see CEUR’s Author\\nInstruction. Overleaf Template:\\nhttps://www.overleaf.com/latex/templates/template-for-submissions-to-ceur-workshop-proceedings-ceur-ws-dot-org/wqyfdgftmcfw', metadata={'source': 'https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)', 'language': 'en'}), Document(page_content='*Submission Link:* https://easychair.org/conferences/?conf=text2kg2024\\n\\n*Workshop Link: *https://aiisc.ai/text2kg2024/\\n\\n*Contact Person: *Sanju Tiwari <tiwarisanju18@ieee.org> (Please feel free\\nto write…)\\n\\n\\n\\n*Organizing Chairs:*\\n\\nSanju Tiwari, BVICAM, New Delhi, India & UAT Mexico\\n\\nNandana Mihindukulasooriya, MIT-IBM Watson AI Lab, USA\\n\\nFrancesco Osborne, KMi, The Open University\\n\\nDimitris Kontokostas, Diffbot, Greece\\nJennifer D’Souza, TIB, Germany\\n\\nMayank Kejriwal, University of Southern California, USA\\n\\nPublicity Chair:\\n\\nJoey Yip, University of South Carolina, USA\\n\\n\\n\\n*Advisory Committee*\\n\\n· Edlira Vakaj, Birmigham City University, UK\\n\\n· Anna Fensel, Wageningen University & Research, The Netherlands\\n\\n· Maria Esther Vidal, Leibniz University of Hannover and TIB, Germany\\n\\n· Amit Sheth, University of South Carolina, USA\\n\\n· Sören Auer, Leibniz University of Hannover and TIB, Germany\\n\\n· Enrico Motta, The Open University, United Kingdom', metadata={'source': 'https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)', 'language': 'en'}), Document(page_content='· Amit Sheth, University of South Carolina, USA\\n\\n· Sören Auer, Leibniz University of Hannover and TIB, Germany\\n\\n· Enrico Motta, The Open University, United Kingdom\\n\\n· Fernando Ortiz-Rodriguez, Universidad Autonoma de Tamaulipas, Mexico\\n\\n· Sven Groppe, University of Lubeck, Germany\\n-- \\nRegards\\nDr. Sanju Tiwari (CEO & Founder of Shodhguru Research Labs)\\nFull Professor, BVICAM, New Delhi, India\\nSr. Researcher, Universidad Autonoma de Tamaulipas, Mexico\\nResarch Fellow of ORKG, TIB Hannover, Germany\\nVisiting Researcher, InfAI, Leipzig University, Germany\\nExternal Supervisor, University of Lubeck, Germany\\nDAAD Post-Doc-Net AI Fellow\\nGeneral Chair *KGSWC-2023*\\nhttp://www.kgswc.org <http://www.kgswc.org/indo-american/>/\\n\"Do what you love, Love what you do\"\\n\\n\\nReceived on Thursday,  7 March 2024 03:03:57 UTC\\n\\n\\n\\n\\n\\nThis message: Message body', metadata={'source': 'https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)', 'language': 'en'}), Document(page_content='Received on Thursday,  7 March 2024 03:03:57 UTC\\n\\n\\n\\n\\n\\nThis message: Message body\\n\\nNext message: Francesco Calimeri: \"Fwd: HC@AIxIA: AI&Health Seminar Series (2024) - MARCH 8th\"\\nPrevious message: cimiano@cit-ec.uni-bielefeld.de: \"3rd CFP,  1st International Workshop on Actionable Knowledge  Representation for Robots (AKR3)\"\\n\\n\\n\\n\\nMail actions: respond to this message\\nmail a new topic\\nContemporary messages sorted: by date\\nby thread\\nby subject\\nby author\\n\\nHelp: \\nhow to use the archives\\nsearch the archives\\n\\n\\n\\n\\n\\n\\nThis archive was generated by hypermail 3.0.0: Thursday,  7 March 2024 03:03:57 UTC', metadata={'source': 'https://lists.w3.org/Archives/Public/semantic-web/2024Mar/0018.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (semantic-web@w3.org from March 2024)', 'language': 'en'})]\n",
            "article: Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline (March 17, 2024)\n",
            "article: https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html\n",
            "Splits: [Document(page_content='Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nW3C home\\nMailing lists\\nPublic\\npublic-lod@w3.org\\nMarch 2024\\n\\n\\nDeadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThis message: Message body\\nRespond\\nMore options\\n\\n\\nRelated messages: \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom: Dr. Sanju Tiwari <sanju.tiwari.2007@gmail.com>\\n\\nDate: Thu, 7 Mar 2024 08:33:37 +0530\\nTo: semantic-web@w3.org, announcements@ubicomp.org, tccc-announce@comsoc.org,  wi@lists.kit.edu, dl@dl.kr.org, public-lod <public-lod@w3.org>\\n\\nMessage-ID: <CAOprRZ+dVJjaKpuuaCby9vEKaxD1wEEKaf++WrJZegqcQrnvOg@mail.gmail.com>\\n\\n\\n\\n\\n*INTERNATIONAL WORKSHOP ON KNOWLEDGE GRAPH GENERATION FROM TEXT (TEXT2KG\\n2024) collocated with ESWC 2024*\\n\\n*Workshop website*: https://aiisc.ai/text2kg2024/\\n*Paper Submission: *7th March 2024 (AoE time) 17th of March 2024 (AoE time)', metadata={'source': 'https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)', 'language': 'en'}), Document(page_content='*Workshop website*: https://aiisc.ai/text2kg2024/\\n*Paper Submission: *7th March 2024 (AoE time) 17th of March 2024 (AoE time)\\n\\n\\nThis workshop aims to bring together researchers from multiple focus areas\\nsuch as Natural Language Processing (NLP), Entity Linking (EL), Relation\\nExtraction (RE), Knowledge Representation and Reasoning (KRR), Deep\\nLearning (DL), Knowledge Base Construction (KBC), Large Language Models\\n(LLMs), Semantic Web, Linked Data, and other related fields to foster a\\ndiscussion and enhance the state-of-the-art in knowledge graph generation\\nfrom text.', metadata={'source': 'https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)', 'language': 'en'}), Document(page_content='The participants will find opportunities to present and hear about other\\nemerging research and applications, to exchange ideas and experiences, and\\nto identify new opportunities for collaborations across disciplines. We\\nplan to involve the many prominent research groups in the Semantic Web\\ncommunity which in the last years focused on the generation of knowledge\\ngraphs from textual sources in different fields, such as research data\\n(ORKG, AI-KG, Nano publications), question answering (ParaQA, NSQA), common\\nsense (CSKG), automotive (CoSI, ASKG), biomedical (Hetionet), and many\\nothers.\\n\\n*THEMES & TOPICS*\\n\\nWe are interested in (including but not limited to) the following themes\\nand topics that study the generation of Knowledge Graphs from text, based\\non quantitative, qualitative, and mixed research methods.', metadata={'source': 'https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)', 'language': 'en'}), Document(page_content='- Approaches for generating Knowledge Graphs from text\\n   -  Ontologies for representing provenance/metadata of generated\\n   Knowledge Graphs\\n   -  Benchmarks for KG generation from text\\n   -  Evaluation methods for KGs generated from text\\n   - Open Information Extraction\\n   -  Deep Learning and Generative approaches\\n   -  Human-in-the-loop methods\\n   - Large Language Models and Knowledge Graphs\\n   -\\n   - Industrial applications involving KGs generation from text\\n   -  Entity and relation extraction\\n   -  Entity and relation linking\\n   -  Semantic Parsing\\n   -\\n\\n* IMPORTANT DATES*\\n\\nPaper submissions due: March 17, 2024\\n\\nFinal decision notification: April 4, 2024\\n\\nCamera-ready submissions due: April 18th, 2024\\n\\n\\n*Keynote Speaker*\\n\\n*Paul Groth, *University of Amsterdam\\n\\n\\n*Industry Talk*\\n\\n*Prasad Yalamanchi, *Lead Semantics, United States\\n\\n\\n*Submission Instructions*', metadata={'source': 'https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)', 'language': 'en'}), Document(page_content='*Submission Instructions*\\n\\nWe invite full research papers, negative results, position papers, dataset\\nand system demo papers. Submissions must be original and should not have\\nbeen published previously or be under consideration for publication while\\nbeing evaluated for this workshop. Submissions will be evaluated by the\\nprogram committee based on the quality of the work and its fit to the\\nworkshop themes. All submissions are double-blind and a high-resolution PDF\\nof the paper should be uploaded to the EasyChair submission site before the\\npaper submission deadline. The accepted papers will be presented at the\\nText2KG workshop integrated with the conference, and they will be published\\nas CEUR proceedings. All must be submitted and formatted in the style of\\nthe CEUR proceedings format. For details on CEUR style, see CEUR’s Author\\nInstruction. Overleaf Template:\\nhttps://www.overleaf.com/latex/templates/template-for-submissions-to-ceur-workshop-proceedings-ceur-ws-dot-org/wqyfdgftmcfw', metadata={'source': 'https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)', 'language': 'en'}), Document(page_content='*Submission Link:* https://easychair.org/conferences/?conf=text2kg2024\\n\\n*Workshop Link: *https://aiisc.ai/text2kg2024/\\n\\n*Contact Person: *Sanju Tiwari <tiwarisanju18@ieee.org> (Please feel free\\nto write…)\\n\\n\\n\\n*Organizing Chairs:*\\n\\nSanju Tiwari, BVICAM, New Delhi, India & UAT Mexico\\n\\nNandana Mihindukulasooriya, MIT-IBM Watson AI Lab, USA\\n\\nFrancesco Osborne, KMi, The Open University\\n\\nDimitris Kontokostas, Diffbot, Greece\\nJennifer D’Souza, TIB, Germany\\n\\nMayank Kejriwal, University of Southern California, USA\\n\\nPublicity Chair:\\n\\nJoey Yip, University of South Carolina, USA\\n\\n\\n\\n*Advisory Committee*\\n\\n· Edlira Vakaj, Birmigham City University, UK\\n\\n· Anna Fensel, Wageningen University & Research, The Netherlands\\n\\n· Maria Esther Vidal, Leibniz University of Hannover and TIB, Germany\\n\\n· Amit Sheth, University of South Carolina, USA\\n\\n· Sören Auer, Leibniz University of Hannover and TIB, Germany\\n\\n· Enrico Motta, The Open University, United Kingdom', metadata={'source': 'https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)', 'language': 'en'}), Document(page_content='· Amit Sheth, University of South Carolina, USA\\n\\n· Sören Auer, Leibniz University of Hannover and TIB, Germany\\n\\n· Enrico Motta, The Open University, United Kingdom\\n\\n· Fernando Ortiz-Rodriguez, Universidad Autonoma de Tamaulipas, Mexico\\n\\n· Sven Groppe, University of Lubeck, Germany\\n-- \\nRegards\\nDr. Sanju Tiwari (CEO & Founder of Shodhguru Research Labs)\\nFull Professor, BVICAM, New Delhi, India\\nSr. Researcher, Universidad Autonoma de Tamaulipas, Mexico\\nResarch Fellow of ORKG, TIB Hannover, Germany\\nVisiting Researcher, InfAI, Leipzig University, Germany\\nExternal Supervisor, University of Lubeck, Germany\\nDAAD Post-Doc-Net AI Fellow\\nGeneral Chair *KGSWC-2023*\\nhttp://www.kgswc.org <http://www.kgswc.org/indo-american/>/\\n\"Do what you love, Love what you do\"\\n\\n\\nReceived on Thursday,  7 March 2024 03:03:55 UTC\\n\\n\\n\\n\\n\\nThis message: Message body\\n\\n\\n\\n\\n\\nMail actions: respond to this message\\nmail a new topic\\nContemporary messages sorted: by date\\nby thread\\nby subject\\nby author', metadata={'source': 'https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)', 'language': 'en'}), Document(page_content='This message: Message body\\n\\n\\n\\n\\n\\nMail actions: respond to this message\\nmail a new topic\\nContemporary messages sorted: by date\\nby thread\\nby subject\\nby author\\n\\nHelp: \\nhow to use the archives\\nsearch the archives\\n\\n\\n\\n\\n\\n\\nThis archive was generated by hypermail 3.0.0: Thursday,  7 March 2024 03:03:56 UTC', metadata={'source': 'https://lists.w3.org/Archives/Public/public-lod/2024Mar/0000.html', 'title': 'Deadline Extended: 3rd TEXT2KG Workshop @ ESWC-2024 Extended Deadline  (March 17, 2024) from Dr. Sanju Tiwari on 2024-03-07 (public-lod@w3.org from March 2024)', 'language': 'en'})]\n",
            "article: AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs\n",
            "article: https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html\n",
            "Splits: [Document(page_content=\"AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCelebrating 25 years of tech publishing!NewsAll NewsBusiness, Financial & LegalCases, Cooling & PSUContests & GiveawaysCPU, APU & ChipsetsDealsDisplays & ProjectorsGamingMotherboardsScience, Space, Health & RoboticsStorageVideo Cards & GPUsVirtual & Augmented RealityReviews & ArticlesAll ReviewsAll ArticlesAudio, Sound & SpeakersCases, Cooling & PSUCPUs, Chipsets & SoCsComputer SystemsDisplays & ProjectorsGamingMotherboardsNetworkingPeripheralsRAMStorageVideo Cards & GPUsGuidesGamingGPUsSSDsNewsletterAboutForumsContactTT ShowPlayStation 6AMD Zen 5GTA 6PlayStation 5 ProRTX 4060RTX 4090RTX 4070TRENDING: Samsung sent four S24 Ultra's to space on balloons to snap 150+ photos of EarthArtificial Intelligence\", metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content='AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs\\nAMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!\\n VIEW GALLERY - 2\\n\\n\\n\\nShare on Facebook\\n\\n\\n\\n\\nShare on Twitter\\n\\n\\n\\nShare on Reddit\\n\\nAnthony Garreffa\\n@anthony256\\n\\n\\n\\nPublished Mar 6, 2024 9:00 PM CST1 minute & 44 seconds read time', metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content=\"AMD has just announced its own localized and GPT-based LLM-powered AI chatbot, capable of running on Ryzen AI processors and Radeon RX 7000 series GPUs.  2VIEW GALLERY - 2 IMAGES AMD's new LLM-based GPT chatbot can run on a bunch of different Ryzen AI platforms, including Ryzen 7000 and Ryzen 8000 series APUs that feature AMD's new XDNA NPUs, as well as Radeon RX 7000 series GPUs that pack AI accelerator cores.Popular Now: Samsung sent four S24 Ultra's to space on balloons to snap 150+ photos of EarthThe company published a new blog that helps you through the setup, so you can run your own localized chatbot powered by GPT-based LLMs (Large Language Models). If you've got a Ryzen AI processor, you'll need the standard LM Studio copy for Windows, while if you've got an RDNA 3-based Radeon RX 7000 series GPU, you'll need the ROCm Technical Preview.  Read more: Ever wanted to chat to your GPU? NVIDIA's new RTX-powered AI chatbot is here  Read more: AMD Ryzen 8040 series 'Hawk Point' APUs:\", metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content='7000 series GPU, you\\'ll need the ROCm Technical Preview.  Read more: Ever wanted to chat to your GPU? NVIDIA\\'s new RTX-powered AI chatbot is here  Read more: AMD Ryzen 8040 series \\'Hawk Point\\' APUs: Zen 4 CPU, RDNA 3 GPU, XDNA for AI Read more: AMD powers 90% of the AI PC market so far Read more: AMD on the AI PC market: we expect \\'tremendous momentum\\' for AI PCs in 2025  AMD isn\\'t the first to do this, with NVIDIA recently launching \"Chat with RTX\" which is an AI chatbot powered by GeForce RTX 40 and RTX 30 series GPUs. It\\'s accelerated with the TensorRT-LLM feature set, offering fast generative AI results based on localized dataset. AMD is now following in their footsteps with its new LLM-powered ChatGPT chatbot which you can learn how to configure on AMD\\'s website here.AMD Ryzen 5 8500G 6-Core, 24-Thread Desktop ProcessorTodayYesterday7 days ago30 days ago$139.99$139.99$139.99-Buy$179.00$179.00--Buy* Prices last scanned on 3/6/2024 at 6:50 pm CST - prices may not be accurate, click', metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content='6-Core, 24-Thread Desktop ProcessorTodayYesterday7 days ago30 days ago$139.99$139.99$139.99-Buy$179.00$179.00--Buy* Prices last scanned on 3/6/2024 at 6:50 pm CST - prices may not be accurate, click links above for the latest price. We may earn an affiliate commission.', metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content='NEWS SOURCE:community.amd.com', metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content=\"Anthony Garreffa\\n\\nAnthony joined the TweakTown team in 2010 and has since reviewed 100s of graphics cards. Anthony is a long time PC enthusiast with a passion of hate for games built around consoles. FPS gaming since the pre-Quake days, where you were insulted if you used a mouse to aim, he has been addicted to gaming and hardware ever since. Working in IT retail for 10 years gave him great experience with custom-built PCs. His addiction to GPU tech is unwavering and has recently taken a keen interest in artificial intelligence (AI) hardware.\\n\\n\\nWhat's in Anthony's PC?CPU: Intel Core i5-12600K MOTHERBOARD: GIGABYTE Z690 AERO-G RAM: Corsair 32GB DDR4-3200 GPU: NVIDIA GeForce RTX 4090 24GB SSD: Sabrent 4TB Rocket 4 Plus OS: Windows 11 Pro CASE: Lian Li O11 Dynamic XL PSU: ASUS ROG Strix 850W KEYBOARD: Logitech G915 Wireless MOUSE: Logitech G502X Wireless MONITOR: LG C3 48-inch OLED TV 4K 120Hz \\nNewsletter Subscription\\n\\n\\n\\n\\n\\n\\n\\nSimilar News\", metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content=\"Similar News\\n\\nAMD Ryzen Threadripper PRO 7000 WX series CPUs top out at 96 cores, 192 threads Zen 4 for $9999\\n\\nAMD confirm Ryzen 9 7950X, Ryzen 9 7900X, Ryzen 7 7700X, Ryzen 5 7600X\\n\\nAMD 'Zen 4' CPU launch delayed because of BIOS issues says reviewer\\n\\nThis is our first look at the AMD Ryzen 7 7700X 'Zen 4' processor\\n\\nASUS TRX50-SAGE mobo: ready for AMD Ryzen Threadripper 7000 series CPUs\\n\\nAMD Ryzen 5 7600X engineering sample CPU hits the Chinese black market\", metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content='Related Tags', metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content=\"AMDNVIDIAAIAI chatbotLLMRyzen AIRyzen AI processorRadeon RX 7000 seriesRDNA 3AI chatbot LLMNewsletter SubscriptionLatest NewsIntel set to show off Arrow Lake at Computex 2024 - might the CPUs arrive sooner than thought?Microsoft is testing having Copilot AI spring more readily into action on Windows 11 PCsGoogle engineer faces 10 years in prison for stealing AI secrets for ChinaTesla might finally launch an Apple Watch app if CEO Elon Musk is to be believedA Steve Jobs check paying for Apple's phone service could sell for thousandsView More NewsLatest ReviewsCooler Master GX III 850w 80 PLUS Gold ATX 3.0 PSU ReviewMSI MPG 271QRX QD-OLED 1440p 360Hz Gaming Monitor ReviewASRock CL27FF Gaming Monitor Review - 1080p 100Hz for just $110GIGABYTE AORUS Z790 Master X Motherboard ReviewSuper Mario Bros. (1993) 4K Blu-ray Reviewbe quiet! Straight Power 12 1000w ATX 3.0 80 PLUS Platinum PSU ReviewMSI MEG Z790 Godlike Max Motherboard ReviewSapphire NITRO+ Radeon RX 7900 GRE Review - AMD Strikes\", metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'}), Document(page_content='Bros. (1993) 4K Blu-ray Reviewbe quiet! Straight Power 12 1000w ATX 3.0 80 PLUS Platinum PSU ReviewMSI MEG Z790 Godlike Max Motherboard ReviewSapphire NITRO+ Radeon RX 7900 GRE Review - AMD Strikes Backbe quiet! Shadow Base 800 Mid-Tower Chassis ReviewXFX Radeon RX 7900 GRE Review - Great GPU, Confusing NameView More ReviewsLatest ArticlesASUS OLED Premium Care defends the ROG Swift OLED PG32UCDM gaming monitor from burn-inPatriot Viper Xtreme 5 Engineering Prototype 48GB Dual-Channel Memory Kit Preview2023 ASUS Holiday Tech Buyers Guide - The best gifts for PC gamers and tech lovers in your lifeNon-binary 24 Gbit memory and what it means for PC gamers with Kingston FURY DDR5 RAMOLED displays are incredible for gaming, with ASUS OLED technology leading the packView More ArticlesSitemapAdvertisingAboutContactRSS FEEDSLegal & PRIVACY POLICY© 1999-2024 Tweak Town Pty Ltd. All Rights Reserved. TweakTown® and its logo are registered trademarks.', metadata={'source': 'https://www.tweaktown.com/news/96686/amd-now-allows-ryzen-ai-cpus-and-radeon-rx-7000-gpus-to-run-localized-chatbots-using-llms/index.html', 'title': 'AMD now allows Ryzen AI CPUs and Radeon RX 7000 GPUs to run localized AI chatbots using LLMs', 'description': 'AMD details how to run a Large Language Model (LLM) AI-powered chatbot on your Ryzen AI PC or Radeon RX 7000 series GPU, you can try it out right now!', 'language': 'en-US'})]\n",
            "article: hfautogen.py 1.2\n",
            "article: https://pypi.org/project/hfautogen.py/\n",
            "Splits: [Document(page_content='hfautogen.py · PyPI\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\nSwitch to mobile version    \\n\\n\\n\\n\\n\\n\\n\\nWarning\\n\\nSome features may not work without JavaScript. Please try enabling it if you encounter problems.\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch PyPI\\n\\n\\n\\nSearch\\n\\n\\n\\n \\n\\n\\nHelp\\nSponsors\\nLog in\\nRegister\\n\\n\\n\\n\\nMenu      \\n\\n\\n\\n\\nHelp\\nSponsors\\nLog in\\nRegister\\n\\n\\n\\n \\n\\n\\n\\n\\nSearch PyPI\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        hfautogen.py 1.4\\n      \\n\\n\\npip install hfautogen.py\\n\\n\\nCopy PIP instructions\\n\\n\\n\\n\\n\\n\\nLatest version\\n\\n\\nReleased: \\n  Mar 7, 2024\\n \\n\\n\\n\\n\\n\\n \\nA seemless way to use HuggingFace Inference API with Autogen.\\n \\n\\n\\n\\n\\n\\n\\n\\nNavigation\\n\\n\\n\\n\\n\\nProject description                \\n\\n\\n\\n\\nRelease history                \\n\\n\\n\\n\\nDownload files                \\n\\n\\n\\n\\n\\nProject links\\n\\n\\n\\nHomepage\\n      \\n\\n\\n\\nBug Tracker\\n      \\n\\n\\n\\n\\nStatistics\\n\\nGitHub statistics:    \\n\\n\\n\\nStars:\\n\\n\\n\\n\\n\\n\\nForks:\\n\\n\\n\\n\\n\\n\\nOpen issues:\\n\\n\\n\\n\\n\\n\\nOpen PRs:\\n\\n\\n\\n\\n\\n\\nView statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='GitHub statistics:    \\n\\n\\n\\nStars:\\n\\n\\n\\n\\n\\n\\nForks:\\n\\n\\n\\n\\n\\n\\nOpen issues:\\n\\n\\n\\n\\n\\n\\nOpen PRs:\\n\\n\\n\\n\\n\\n\\nView statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery \\n\\n\\nMeta\\nLicense: MIT License\\nAuthor: Solomon Ince\\n\\nRequires: Python >=3.6\\n  \\n\\n\\nMaintainers\\n\\n\\n\\n\\n\\n\\n            Solonce\\n          \\n\\n\\n\\n\\nClassifiers\\n\\n\\nLicense\\n\\n\\n\\n            OSI Approved :: MIT License\\n          \\n\\n\\n\\n\\nOperating System\\n\\n\\n\\n            OS Independent\\n          \\n\\n\\n\\n\\nProgramming Language\\n\\n\\n\\n            Python :: 3\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProject description              \\n\\n\\n\\n\\nProject details              \\n\\n\\n\\n\\nRelease history            \\n\\n\\n\\n\\nDownload files              \\n\\n\\n\\n\\nProject description', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"Project description              \\n\\n\\n\\n\\nProject details              \\n\\n\\n\\n\\nRelease history            \\n\\n\\n\\n\\nDownload files              \\n\\n\\n\\n\\nProject description\\n\\nHFAutogen\\nSeemlessly use models provided by the HuggingFace Inference API  with Autogen.\\nIntroduction\\nHFAutogen bridges the gap between Hugging Face's powerful inference API and the convenience of AutoGen, providing a seamless integration for developers looking to leverage the best of both worlds. This software enables the use of Hugging Face models with AutoGen's automated code generation capabilities, making it easier to implement AI-powered features without the need for large computational power.\\nTable of Contents\\n\\nInstallation\\nUsage\\nFeatures\\nDependencies\\nExamples\\nLicense\\n\\nInstallation\\npip install hfautogen\", metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Installation\\nUsage\\nFeatures\\nDependencies\\nExamples\\nLicense\\n\\nInstallation\\npip install hfautogen\\n\\nExamples\\nExample 1\\nIn this example, we are importing the required functions to set up a user agent, an assistant agent, and initializing the chat between the two. We start the chat with the prompt given with _input.\\nfrom hfautogen import ModelAgent, UserAgent, InitChat\\n\\n_input = input(\"Enter text or press Enter to load automated message.\\\\n\")\\nhf_key = \"hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\\n\\nuser = UserAgent(\"user_proxy\")\\nassistant = ModelAgent(\"assistant\",\\n                        hf_key,\\n                        system_message=\"You are a friendly AI assistant.\")\\n\\nInitChat(user, assistant, _input)', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"InitChat(user, assistant, _input)\\n\\nFeatures\\nFree to use, extremely lightweight access to open source HuggingFace Models.\\nHFAutogen leverages the power of open-source technology by integrating HuggingFace's Inference API with Autogen. HFAutogen provides users with state-of-the-art AI capabilities at no cost. This feature means that developers and researchers can access a wide range of pre-trained models for natural language processing (NLP) found on the HuggingFace Model Hub without worrying about the financial overhead. The lightweight nature of AutoGen's access mechanism ensures that users can start experimenting and deploying AI features in their projects quickly and efficiently, without the need for extensive setup or high-end computational resources.\", metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Automatic Code Execution\\nWith HFAutogen, users benefit from an environment that automates the code execution process. This feature is inhereted from Autogen, while reducing the barrier for entry into the tool. Designed to streamline the development workflow, HFAutogen makes it easier and faster to test and deploy multi-agent communication systems than ever before. Automatic code execution means that once the user configures their project settings and inputs, HFAutogen takes care of the rest—compiling, running, and providing outputs without manual intervention. This automation reduces the potential for human error, speeds up the development cycle, and allows users to focus more on the strategic aspects of their projects.', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"Multi Agent Communication\\nMulti-agent communication is at the heart of AutoGen's capabilities, enabling different AI agents to interact with each other in a coordinated manner. This feature is crucial for developing complex systems where multiple agents need to share information, make decisions, or work together towards a common goal. HFAutogen facilitates this by providing a seamless communication framework between the user and Autogen\", metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Fast Prototyping\\nHFAutogen is designed to accelerate the prototyping phase of project development, allowing users to quickly move from concept to a working prototype. This feature is particularly beneficial in the fast-paced world of technology, where speed to market can be a critical competitive advantage. With HFAutogen, developers can rapidly test hypotheses, iterate on designs, and refine their projects with minimal delay. The combination of easy access to powerful AI models, automatic code execution, and support for multi-agent communication means that prototyping with HFAutogen is not only fast but also highly effective, enabling users to explore innovative ideas and solutions with agility.\\nUsage\\nHFAutogen uses three objects that are useful to the user. ModelAgent(), UserAgent(), and InitChat()\\nModelAgent(name, hf_key, hf_url, system_message, code_execution)\\n    name - _str_ required\\n        The name of the `ModelAgent()`', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='hf_key - _str_ required\\n        The API Key obtained on HuggingFace.\\n\\n    hf_url - _str_ optional\\n        _default_: \"\"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\"\\n        The HuggingFace Inference API URL.\\n\\n    system_message - _str_ optional\\n        _default:_ \"\"\\n        The contextual prompt for `ModelAgent()`\\n\\n    code_execution - _dict_ optional\\n        _default:_ False\\n        A dictionary that contains a `work_dir` and `use_docker` entry:\\n\\n        Ex:\\n           {\"work_dir\": \"coding\", \"use_docker\": False}\\n\\n\\nUserAgent(name, max_consecutive_auto_reply, code_dir, use_docker, system_message)\\n  - name - _str_ required\\n    The name of the `ModelAgent()`\\n\\n  - max_consecutive_auto_reply - _int_ optional\\n    _default:_ 2\\n    The maximum number of consecutive automatic replies made by the `UserAgent()`\\n\\n  - coding_dir - _str_ optional\\n    _default:_ \"coding\"\\n    The directory `UserAgent()` will use and operate out of.', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='- coding_dir - _str_ optional\\n    _default:_ \"coding\"\\n    The directory `UserAgent()` will use and operate out of.\\n\\n  - user_docker - _bool_ optional\\n    _default:_ False\\n    If true, `UserAgent()` will use a docker.\\n\\n  - system_message - _str_ optional\\n    _default:_ \"\"\\n    The contextual prompt for `UserAgent()`\\n\\nInitChat(user, agent, _input)\\n  - user - _`UserAgent()`_ required\\n    A `UserAgent()` object\\n\\n  - agent - _`ModeAgent()`_ required\\n    A `ModelAgent()` object\\n\\n  - _input - _str_ required\\n    The initial input prompt.\\n\\n\\nDependencies\\npyautogen ==0.2.10\\ntransformers =4.38.0\\n\\n\\n\\n\\nProject details\\n\\nProject links\\n\\n\\n\\nHomepage\\n      \\n\\n\\n\\nBug Tracker\\n      \\n\\n\\n\\n\\nStatistics\\n\\nGitHub statistics:    \\n\\n\\n\\nStars:\\n\\n\\n\\n\\n\\n\\nForks:\\n\\n\\n\\n\\n\\n\\nOpen issues:\\n\\n\\n\\n\\n\\n\\nOpen PRs:\\n\\n\\n\\n\\n\\n\\nView statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery \\n\\n\\nMeta\\nLicense: MIT License\\nAuthor: Solomon Ince\\n\\nRequires: Python >=3.6\\n  \\n\\n\\nMaintainers', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"View statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery \\n\\n\\nMeta\\nLicense: MIT License\\nAuthor: Solomon Ince\\n\\nRequires: Python >=3.6\\n  \\n\\n\\nMaintainers\\n\\n\\n\\n\\n\\n\\n            Solonce\\n          \\n\\n\\n\\n\\nClassifiers\\n\\n\\nLicense\\n\\n\\n\\n            OSI Approved :: MIT License\\n          \\n\\n\\n\\n\\nOperating System\\n\\n\\n\\n            OS Independent\\n          \\n\\n\\n\\n\\nProgramming Language\\n\\n\\n\\n            Python :: 3\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelease history\\n\\nRelease notifications |\\n              RSS feed \\n\\n\\n\\n\\n\\nThis version\\n\\n\\n\\n\\n\\n\\n\\n                  1.4\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  1.3\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  1.2\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\nDownload files\\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\\n\\nSource Distribution\", metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\nDownload files\\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\\n\\nSource Distribution            \\n\\n\\n\\n\\n\\n\\n          hfautogen.py-1.4.tar.gz\\n        \\n        (7.2 kB\\n        view hashes)\\n        \\n          Uploaded \\n  Mar 7, 2024\\n\\nsource\\n\\n\\n\\n\\nBuilt Distribution            \\n\\n\\n\\n\\n\\n\\n          hfautogen.py-1.4-py3-none-any.whl\\n        \\n        (7.5 kB\\n        view hashes)\\n        \\n          Uploaded \\n  Mar 7, 2024\\n\\npy3\\n\\n\\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\nHashes for hfautogen.py-1.4.tar.gz      \\n\\nHashes for hfautogen.py-1.4.tar.gz\\n\\n\\nAlgorithm\\nHash digest\\n\\n\\n\\n\\n\\nSHA256\\n991b8ac7e4993d9213e790cfb5b230a83c9e4bee5da4aed23326aea2543dcb88\\n\\n\\nCopy              \\n\\n\\n\\nMD5\\n3f1cb2afb71c50288873680ba0ef9624\\n\\n\\nCopy              \\n\\n\\n\\nBLAKE2b-256\\n601d279162b9bc37484ff8a0ba6f7377125a352ea903b29ad4a0eb40c0e33931\\n\\n\\nCopy              \\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\nHashes for hfautogen.py-1.4-py3-none-any.whl      \\n\\nHashes for hfautogen.py-1.4-py3-none-any.whl\", metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Copy              \\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\nHashes for hfautogen.py-1.4-py3-none-any.whl      \\n\\nHashes for hfautogen.py-1.4-py3-none-any.whl\\n\\n\\nAlgorithm\\nHash digest\\n\\n\\n\\n\\n\\nSHA256\\ne664f74866edb924a3ddb36185c858fd588cd3efea15643e7cb398524e6e79bd\\n\\n\\nCopy              \\n\\n\\n\\nMD5\\nb5084b298300f7b0d8a8e9070c36a445\\n\\n\\nCopy              \\n\\n\\n\\nBLAKE2b-256\\nd0e2b63a46a092d1fad779fda4f7309dc636bb47609124b80f1901860ed7a605\\n\\n\\nCopy              \\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHelp\\n\\n\\nInstalling packages\\nUploading packages\\nUser guide\\nProject name retention\\nFAQs\\n\\n\\n\\n\\nAbout PyPI\\n\\n\\nPyPI on Twitter\\nInfrastructure dashboard\\nStatistics\\nLogos & trademarks\\nOur sponsors\\n\\n\\n\\n\\nContributing to PyPI\\n\\n\\nBugs and feedback\\nContribute on GitHub\\nTranslate PyPI\\nSponsor PyPI\\nDevelopment credits\\n\\n\\n\\n\\nUsing PyPI\\n\\n\\nCode of conduct\\nReport security issue\\nPrivacy policy\\nTerms of use\\nAcceptable Use Policy\\n\\n\\n\\n\\n\\n\\nStatus:\\nall systems operational\\n\\n\\nDeveloped and maintained by the Python community, for the Python community.          \\nDonate today!', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Status:\\nall systems operational\\n\\n\\nDeveloped and maintained by the Python community, for the Python community.          \\nDonate today!\\n\\n\\n          \"PyPI\", \"Python Package Index\", and the blocks logos are registered trademarks of the Python Software Foundation.\\n\\n\\n          © 2024 Python Software Foundation\\nSite map\\n\\n\\n\\n\\nSwitch to desktop version        \\n\\n\\n\\n\\n\\n\\n\\n              English\\n            \\n\\n\\n\\n              español\\n            \\n\\n\\n\\n              français\\n            \\n\\n\\n\\n              日本語\\n            \\n\\n\\n\\n              português (Brasil)\\n            \\n\\n\\n\\n              українська\\n            \\n\\n\\n\\n              Ελληνικά\\n            \\n\\n\\n\\n              Deutsch\\n            \\n\\n\\n\\n              中文 (简体)\\n            \\n\\n\\n\\n              中文 (繁體)\\n            \\n\\n\\n\\n              русский\\n            \\n\\n\\n\\n              עברית\\n            \\n\\n\\n\\n              esperanto\\n            \\n\\n\\n\\n\\n\\nSupported by\\n\\n\\n\\nAWS\\n\\n            Cloud computing and Security Sponsor\\n          \\n\\n\\n\\nDatadog', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='עברית\\n            \\n\\n\\n\\n              esperanto\\n            \\n\\n\\n\\n\\n\\nSupported by\\n\\n\\n\\nAWS\\n\\n            Cloud computing and Security Sponsor\\n          \\n\\n\\n\\nDatadog\\n\\n            Monitoring\\n          \\n\\n\\n\\nFastly\\n\\n            CDN\\n          \\n\\n\\n\\nGoogle\\n\\n            Download Analytics\\n          \\n\\n\\n\\nMicrosoft\\n\\n            PSF Sponsor\\n          \\n\\n\\n\\nPingdom\\n\\n            Monitoring\\n          \\n\\n\\n\\nSentry\\n\\n            Error logging\\n          \\n\\n\\n\\nStatusPage\\n\\n            Status page', metadata={'source': 'https://pypi.org/project/hfautogen.py/', 'title': 'hfautogen.py · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'})]\n",
            "article: Harnessing Explanations: LLM-to-LM Interpreter for Enhanced\n",
            " Text-Attributed Graph Representation Learning\n",
            "article: http://arxiv.org/abs/2305.19523v5\n",
            "Splits: [Document(page_content='[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n\\n\\n\\n\\n > cs > arXiv:2305.19523v5\\n  \\n\\n\\n\\n\\n\\nHelp | Advanced Search\\n\\n\\n\\n\\nAll fields\\nTitle\\nAuthor\\nAbstract\\nComments\\nJournal reference\\nACM classification\\nMSC classification\\nReport number\\narXiv identifier\\nDOI\\nORCID\\narXiv author ID\\nHelp pages\\nFull text\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nopen search\\n\\n\\n\\n\\n\\n\\nGO\\n\\n\\n\\nopen navigation menu\\n\\n\\nquick links\\n\\nLogin\\nHelp Pages\\nAbout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComputer Science > Machine Learning\\n\\n\\narXiv:2305.19523v5 (cs)', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content='Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nopen search\\n\\n\\n\\n\\n\\n\\nGO\\n\\n\\n\\nopen navigation menu\\n\\n\\nquick links\\n\\nLogin\\nHelp Pages\\nAbout\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComputer Science > Machine Learning\\n\\n\\narXiv:2305.19523v5 (cs)\\n    \\n\\n\\n\\n\\n  [Submitted on 31 May 2023 (v1), last revised 7 Mar 2024 (this version, v5)]\\nTitle:Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning\\nAuthors:Xiaoxin He, Xavier Bresson, Thomas Laurent, Adam Perold, Yann LeCun, Bryan Hooi Download a PDF of the paper titled Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning, by Xiaoxin He and 5 other authors\\nDownload PDF\\nHTML (experimental)', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content='Abstract:Representation learning on text-attributed graphs (TAGs) has become a critical research problem in recent years. A typical example of a TAG is a paper citation graph, where the text of each paper serves as node attributes. Initial graph neural network (GNN) pipelines handled these text attributes by transforming them into shallow or hand-crafted features, such as skip-gram or bag-of-words features. Recent efforts have focused on enhancing these pipelines with language models (LMs), which typically demand intricate designs and substantial computational resources. With the advent of powerful large language models (LLMs) such as GPT or Llama2, which demonstrate an ability to reason and to utilize general knowledge, there is a growing need for techniques which combine the textual modelling abilities of LLMs with the structural learning capabilities of GNNs. Hence, in this work, we focus on leveraging LLMs to capture textual information as features, which can be used to boost GNN', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content='abilities of LLMs with the structural learning capabilities of GNNs. Hence, in this work, we focus on leveraging LLMs to capture textual information as features, which can be used to boost GNN performance on downstream tasks. A key innovation is our use of explanations as features: we prompt an LLM to perform zero-shot classification, request textual explanations for its decision-making process, and design an LLM-to-LM interpreter to translate these explanations into informative features for downstream GNNs. Our experiments demonstrate that our method achieves state-of-the-art results on well-established TAG datasets, including Cora, PubMed, ogbn-arxiv, as well as our newly introduced dataset, tape-arxiv23. Furthermore, our method significantly speeds up training, achieving a 2.88 times improvement over the closest baseline on ogbn-arxiv. Lastly, we believe the versatility of the proposed method extends beyond TAGs and holds the potential to enhance other tasks involving graph-text', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content='improvement over the closest baseline on ogbn-arxiv. Lastly, we believe the versatility of the proposed method extends beyond TAGs and holds the potential to enhance other tasks involving graph-text data. Our codes and datasets are available at: this https URL.', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content='Comments:\\nIn Proceedings of ICLR 2024\\n\\n\\nSubjects:\\n\\nMachine Learning (cs.LG)\\n\\nCite as:\\narXiv:2305.19523 [cs.LG]\\n\\n\\n\\xa0\\n(or \\narXiv:2305.19523v5 [cs.LG] for this version)\\n          \\n \\n\\xa0\\n\\nhttps://doi.org/10.48550/arXiv.2305.19523\\n\\n\\n\\nFocus to learn more\\n\\n\\n\\n\\n                arXiv-issued DOI via DataCite\\n              \\n\\n\\n\\n\\n\\n\\n\\nSubmission history From: Xiaoxin He [view email]       [v1]\\n        Wed, 31 May 2023 03:18:03 UTC (1,169 KB)\\n[v2]\\n        Fri, 6 Oct 2023 08:32:53 UTC (1,253 KB)\\n[v3]\\n        Mon, 23 Oct 2023 05:04:38 UTC (1,253 KB)\\n[v4]\\n        Wed, 28 Feb 2024 09:01:41 UTC (1,279 KB)\\n[v5]\\n        Thu, 7 Mar 2024 02:45:36 UTC (1,280 KB)\\n\\n\\n\\n \\n\\nFull-text links:\\nAccess Paper:\\n\\n\\nDownload a PDF of the paper titled Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning, by Xiaoxin He and 5 other authorsDownload PDFHTML (experimental)TeX SourceOther Formats\\nview license\\n\\n \\n    Current browse context: cs.LG\\n\\n\\n<\\xa0prev\\n\\n\\xa0 | \\xa0 \\nnext\\xa0>', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content='Current browse context: cs.LG\\n\\n\\n<\\xa0prev\\n\\n\\xa0 | \\xa0 \\nnext\\xa0>\\n\\n\\nnew\\n | \\nrecent\\n | \\n2305\\n\\n    Change to browse by:\\n    \\ncs\\n\\n\\n\\n\\nReferences & Citations\\n\\nNASA ADSGoogle Scholar\\nSemantic Scholar\\n\\n\\n\\n\\na\\nexport BibTeX citation\\nLoading...\\n\\n\\n\\n\\nBibTeX formatted citation\\n×\\n\\n\\nloading...\\n\\n\\nData provided by: \\n\\n\\n\\n\\nBookmark\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nBibliographic Tools\\n\\nBibliographic and Citation Tools\\n\\n\\n\\n\\n\\n\\nBibliographic Explorer Toggle\\n\\n\\n\\nBibliographic Explorer (What is the Explorer?)\\n\\n\\n\\n\\n\\n\\n\\nLitmaps Toggle\\n\\n\\n\\nLitmaps (What is Litmaps?)\\n\\n\\n\\n\\n\\n\\n\\nscite.ai Toggle\\n\\n\\n\\nscite Smart Citations (What are Smart Citations?)\\n\\n\\n\\n\\n\\n\\n\\n\\nCode, Data, Media\\n\\nCode, Data and Media Associated with this Article\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\\n\\n\\n\\n\\n\\n\\n\\nDagsHub Toggle\\n\\n\\n\\nDagsHub (What is DagsHub?)\\n\\n\\n\\n\\n\\n\\n\\nGotitPub Toggle\\n\\n\\n\\nGotit.pub (What is GotitPub?)\\n\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nPapers with Code (What is Papers with Code?)\\n\\n\\n\\n\\n\\n\\n\\nScienceCast Toggle\\n\\n\\n\\nScienceCast (What is ScienceCast?)', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content='GotitPub Toggle\\n\\n\\n\\nGotit.pub (What is GotitPub?)\\n\\n\\n\\n\\n\\n\\n\\nLinks to Code Toggle\\n\\n\\n\\nPapers with Code (What is Papers with Code?)\\n\\n\\n\\n\\n\\n\\n\\nScienceCast Toggle\\n\\n\\n\\nScienceCast (What is ScienceCast?)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDemos\\n\\nDemos\\n\\n\\n\\n\\n\\n\\nReplicate Toggle\\n\\n\\n\\nReplicate (What is Replicate?)\\n\\n\\n\\n\\n\\n\\n\\nSpaces Toggle\\n\\n\\n\\nHugging Face Spaces (What is Spaces?)\\n\\n\\n\\n\\n\\n\\n\\nSpaces Toggle\\n\\n\\n\\nTXYZ.AI (What is TXYZ.AI?)\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Papers\\n\\nRecommenders and Search Tools\\n\\n\\n\\n\\n\\n\\nLink to Influence Flower\\n\\n\\n\\nInfluence Flower (What are Influence Flowers?)\\n\\n\\n\\n\\n\\n\\n\\nConnected Papers Toggle\\n\\n\\n\\nConnected Papers (What is Connected Papers?)\\n\\n\\n\\n\\n\\n\\n\\nCore recommender toggle\\n\\n\\n\\nCORE Recommender (What is CORE?)\\n\\n \\n\\n\\n\\n\\nIArxiv recommender toggle\\n\\n\\n\\nIArxiv Recommender\\n(What is IArxiv?)\\n\\n\\n\\n\\n\\n\\nAuthor\\nVenue\\nInstitution\\nTopic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        About arXivLabs', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content=\"CORE Recommender (What is CORE?)\\n\\n \\n\\n\\n\\n\\nIArxiv recommender toggle\\n\\n\\n\\nIArxiv Recommender\\n(What is IArxiv?)\\n\\n\\n\\n\\n\\n\\nAuthor\\nVenue\\nInstitution\\nTopic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        About arXivLabs\\n      \\n\\n\\n\\narXivLabs: experimental projects with community collaborators\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhich authors of this paper are endorsers? |\\n    Disable MathJax (What is MathJax?)\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\nHelp\\n\\n\\n\\n\\n\\ncontact arXivClick here to contact arXiv\\n Contact\\n\\n\\nsubscribe to arXiv mailingsClick here to subscribe\\n Subscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright\\nPrivacy Policy\", metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'}), Document(page_content='About\\nHelp\\n\\n\\n\\n\\n\\ncontact arXivClick here to contact arXiv\\n Contact\\n\\n\\nsubscribe to arXiv mailingsClick here to subscribe\\n Subscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCopyright\\nPrivacy Policy\\n\\n\\n\\n\\nWeb Accessibility Assistance\\n\\n\\narXiv Operational Status \\n                    Get status notifications via\\n                    email\\n                    or slack', metadata={'source': 'http://arxiv.org/abs/2305.19523v5', 'title': '[2305.19523v5] Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning', 'language': 'en'})]\n",
            "article: hfautogen added to PyPI\n",
            "article: https://pypi.org/project/hfautogen/\n",
            "Splits: [Document(page_content='hfautogen · PyPI\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\nSwitch to mobile version    \\n\\n\\n\\n\\n\\n\\n\\nWarning\\n\\nSome features may not work without JavaScript. Please try enabling it if you encounter problems.\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch PyPI\\n\\n\\n\\nSearch\\n\\n\\n\\n \\n\\n\\nHelp\\nSponsors\\nLog in\\nRegister\\n\\n\\n\\n\\nMenu      \\n\\n\\n\\n\\nHelp\\nSponsors\\nLog in\\nRegister\\n\\n\\n\\n \\n\\n\\n\\n\\nSearch PyPI\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        hfautogen 1.5\\n      \\n\\n\\npip install hfautogen\\n\\n\\nCopy PIP instructions\\n\\n\\n\\n\\n\\n\\nLatest version\\n\\n\\nReleased: \\n  Mar 7, 2024\\n \\n\\n\\n\\n\\n\\n \\nA seemless way to use HuggingFace Inference API with Autogen.\\n \\n\\n\\n\\n\\n\\n\\n\\nNavigation\\n\\n\\n\\n\\n\\nProject description                \\n\\n\\n\\n\\nRelease history                \\n\\n\\n\\n\\nDownload files                \\n\\n\\n\\n\\n\\nProject links\\n\\n\\n\\nHomepage\\n      \\n\\n\\n\\nBug Tracker\\n      \\n\\n\\n\\n\\nStatistics\\n\\nGitHub statistics:    \\n\\n\\n\\nStars:\\n\\n\\n\\n\\n\\n\\nForks:\\n\\n\\n\\n\\n\\n\\nOpen issues:\\n\\n\\n\\n\\n\\n\\nOpen PRs:\\n\\n\\n\\n\\n\\n\\nView statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='GitHub statistics:    \\n\\n\\n\\nStars:\\n\\n\\n\\n\\n\\n\\nForks:\\n\\n\\n\\n\\n\\n\\nOpen issues:\\n\\n\\n\\n\\n\\n\\nOpen PRs:\\n\\n\\n\\n\\n\\n\\nView statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery \\n\\n\\nMeta\\nLicense: MIT License\\nAuthor: Solomon Ince\\n\\nRequires: Python >=3.6\\n  \\n\\n\\nMaintainers\\n\\n\\n\\n\\n\\n\\n            Solonce\\n          \\n\\n\\n\\n\\nClassifiers\\n\\n\\nLicense\\n\\n\\n\\n            OSI Approved :: MIT License\\n          \\n\\n\\n\\n\\nOperating System\\n\\n\\n\\n            OS Independent\\n          \\n\\n\\n\\n\\nProgramming Language\\n\\n\\n\\n            Python :: 3\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProject description              \\n\\n\\n\\n\\nProject details              \\n\\n\\n\\n\\nRelease history            \\n\\n\\n\\n\\nDownload files              \\n\\n\\n\\n\\nProject description', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"Project description              \\n\\n\\n\\n\\nProject details              \\n\\n\\n\\n\\nRelease history            \\n\\n\\n\\n\\nDownload files              \\n\\n\\n\\n\\nProject description\\n\\nHFAutogen\\nSeemlessly use models provided by the HuggingFace Inference API  with Autogen.\\nIntroduction\\nHFAutogen bridges the gap between Hugging Face's powerful inference API and the convenience of AutoGen, providing a seamless integration for developers looking to leverage the best of both worlds. This software enables the use of Hugging Face models with AutoGen's automated code generation capabilities, making it easier to implement AI-powered features without the need for large computational power.\\nTable of Contents\\n\\nInstallation\\nUsage\\nFeatures\\nDependencies\\nExamples\\nLicense\\n\\nInstallation\\npip install hfautogen\", metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Installation\\nUsage\\nFeatures\\nDependencies\\nExamples\\nLicense\\n\\nInstallation\\npip install hfautogen\\n\\nExamples\\nExample 1\\nIn this example, we are importing the required functions to set up a user agent, an assistant agent, and initializing the chat between the two. We start the chat with the prompt given with _input.\\nfrom hfautogen import ModelAgent, UserAgent, InitChat\\n\\n_input = input(\"Enter text or press Enter to load automated message.\\\\n\")\\nhf_key = \"hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\\n\\nuser = UserAgent(\"user_proxy\")\\nassistant = ModelAgent(\"assistant\",\\n                        hf_key,\\n                        system_message=\"You are a friendly AI assistant.\")\\n\\nInitChat(user, assistant, _input)', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"InitChat(user, assistant, _input)\\n\\nFeatures\\nFree to use, extremely lightweight access to open source HuggingFace Models.\\nHFAutogen leverages the power of open-source technology by integrating HuggingFace's Inference API with Autogen. HFAutogen provides users with state-of-the-art AI capabilities at no cost. This feature means that developers and researchers can access a wide range of pre-trained models for natural language processing (NLP) found on the HuggingFace Model Hub without worrying about the financial overhead. The lightweight nature of AutoGen's access mechanism ensures that users can start experimenting and deploying AI features in their projects quickly and efficiently, without the need for extensive setup or high-end computational resources.\", metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Automatic Code Execution\\nWith HFAutogen, users benefit from an environment that automates the code execution process. This feature is inhereted from Autogen, while reducing the barrier for entry into the tool. Designed to streamline the development workflow, HFAutogen makes it easier and faster to test and deploy multi-agent communication systems than ever before. Automatic code execution means that once the user configures their project settings and inputs, HFAutogen takes care of the rest—compiling, running, and providing outputs without manual intervention. This automation reduces the potential for human error, speeds up the development cycle, and allows users to focus more on the strategic aspects of their projects.', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"Multi Agent Communication\\nMulti-agent communication is at the heart of AutoGen's capabilities, enabling different AI agents to interact with each other in a coordinated manner. This feature is crucial for developing complex systems where multiple agents need to share information, make decisions, or work together towards a common goal. HFAutogen facilitates this by providing a seamless communication framework between the user and Autogen\", metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Fast Prototyping\\nHFAutogen is designed to accelerate the prototyping phase of project development, allowing users to quickly move from concept to a working prototype. This feature is particularly beneficial in the fast-paced world of technology, where speed to market can be a critical competitive advantage. With HFAutogen, developers can rapidly test hypotheses, iterate on designs, and refine their projects with minimal delay. The combination of easy access to powerful AI models, automatic code execution, and support for multi-agent communication means that prototyping with HFAutogen is not only fast but also highly effective, enabling users to explore innovative ideas and solutions with agility.\\nUsage\\nHFAutogen uses three objects that are useful to the user. ModelAgent(), UserAgent(), and InitChat()\\nModelAgent(name, hf_key, hf_url, system_message, code_execution)\\n    name - _str_ required\\n        The name of the `ModelAgent()`', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='hf_key - _str_ required\\n        The API Key obtained on HuggingFace.\\n\\n    hf_url - _str_ optional\\n        _default_: \"\"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\"\\n        The HuggingFace Inference API URL.\\n\\n    system_message - _str_ optional\\n        _default:_ \"\"\\n        The contextual prompt for `ModelAgent()`\\n\\n    code_execution - _dict_ optional\\n        _default:_ False\\n        A dictionary that contains a `work_dir` and `use_docker` entry:\\n\\n        Ex:\\n           {\"work_dir\": \"coding\", \"use_docker\": False}\\n\\n\\nUserAgent(name, max_consecutive_auto_reply, code_dir, use_docker, system_message)\\n  - name - _str_ required\\n    The name of the `ModelAgent()`\\n\\n  - max_consecutive_auto_reply - _int_ optional\\n    _default:_ 2\\n    The maximum number of consecutive automatic replies made by the `UserAgent()`\\n\\n  - coding_dir - _str_ optional\\n    _default:_ \"coding\"\\n    The directory `UserAgent()` will use and operate out of.', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='- coding_dir - _str_ optional\\n    _default:_ \"coding\"\\n    The directory `UserAgent()` will use and operate out of.\\n\\n  - user_docker - _bool_ optional\\n    _default:_ False\\n    If true, `UserAgent()` will use a docker.\\n\\n  - system_message - _str_ optional\\n    _default:_ \"\"\\n    The contextual prompt for `UserAgent()`\\n\\nInitChat(user, agent, _input)\\n  - user - _`UserAgent()`_ required\\n    A `UserAgent()` object\\n\\n  - agent - _`ModeAgent()`_ required\\n    A `ModelAgent()` object\\n\\n  - _input - _str_ required\\n    The initial input prompt.\\n\\n\\nDependencies\\npyautogen ==0.2.10\\ntransformers =4.38.0\\n\\n\\n\\n\\nProject details\\n\\nProject links\\n\\n\\n\\nHomepage\\n      \\n\\n\\n\\nBug Tracker\\n      \\n\\n\\n\\n\\nStatistics\\n\\nGitHub statistics:    \\n\\n\\n\\nStars:\\n\\n\\n\\n\\n\\n\\nForks:\\n\\n\\n\\n\\n\\n\\nOpen issues:\\n\\n\\n\\n\\n\\n\\nOpen PRs:\\n\\n\\n\\n\\n\\n\\nView statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery \\n\\n\\nMeta\\nLicense: MIT License\\nAuthor: Solomon Ince\\n\\nRequires: Python >=3.6\\n  \\n\\n\\nMaintainers', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='View statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery \\n\\n\\nMeta\\nLicense: MIT License\\nAuthor: Solomon Ince\\n\\nRequires: Python >=3.6\\n  \\n\\n\\nMaintainers\\n\\n\\n\\n\\n\\n\\n            Solonce\\n          \\n\\n\\n\\n\\nClassifiers\\n\\n\\nLicense\\n\\n\\n\\n            OSI Approved :: MIT License\\n          \\n\\n\\n\\n\\nOperating System\\n\\n\\n\\n            OS Independent\\n          \\n\\n\\n\\n\\nProgramming Language\\n\\n\\n\\n            Python :: 3\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelease history\\n\\nRelease notifications |\\n              RSS feed \\n\\n\\n\\n\\n\\nThis version\\n\\n\\n\\n\\n\\n\\n\\n                  1.5\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  1.4\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  1.2\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  1.1.30624\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  1.0.30624\\n                \\n\\n\\n  Mar 7, 2024', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content=\"Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  1.1.30624\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  1.0.30624\\n                \\n\\n\\n  Mar 7, 2024\\n\\n\\n\\n\\n\\n\\n\\nDownload files\\nDownload the file for your platform. If you're not sure which to choose, learn more about installing packages.\\n\\nSource Distribution            \\n\\n\\n\\n\\n\\n\\n          hfautogen-1.5.tar.gz\\n        \\n        (7.2 kB\\n        view hashes)\\n        \\n          Uploaded \\n  Mar 7, 2024\\n\\nsource\\n\\n\\n\\n\\nBuilt Distribution            \\n\\n\\n\\n\\n\\n\\n          hfautogen-1.5-py3-none-any.whl\\n        \\n        (7.5 kB\\n        view hashes)\\n        \\n          Uploaded \\n  Mar 7, 2024\\n\\npy3\\n\\n\\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\nHashes for hfautogen-1.5.tar.gz      \\n\\nHashes for hfautogen-1.5.tar.gz\\n\\n\\nAlgorithm\\nHash digest\\n\\n\\n\\n\\n\\nSHA256\\nbc2873dac96e9fee6481960a7569a6a4e7c9f78741fa5bb2a1de44f2d497ad9a\\n\\n\\nCopy              \\n\\n\\n\\nMD5\\n0f9fde0627ade3182a70beb5d45cd3a6\\n\\n\\nCopy              \\n\\n\\n\\nBLAKE2b-256\\nb05e35ec9af5de792ab980b2b99bbaf7463e76d37df8a409da8d79174b7c0e13\", metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Copy              \\n\\n\\n\\nMD5\\n0f9fde0627ade3182a70beb5d45cd3a6\\n\\n\\nCopy              \\n\\n\\n\\nBLAKE2b-256\\nb05e35ec9af5de792ab980b2b99bbaf7463e76d37df8a409da8d79174b7c0e13\\n\\n\\nCopy              \\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\nHashes for hfautogen-1.5-py3-none-any.whl      \\n\\nHashes for hfautogen-1.5-py3-none-any.whl\\n\\n\\nAlgorithm\\nHash digest\\n\\n\\n\\n\\n\\nSHA256\\n1c7cb87cd4d39796ebcf4c3956ee4f24f29ec0060611ff981d48a361b397e706\\n\\n\\nCopy              \\n\\n\\n\\nMD5\\ndd322812f41bd258043fc0c6bbfd1d60\\n\\n\\nCopy              \\n\\n\\n\\nBLAKE2b-256\\nd8802b09f7fa15e1316223941db5205d71bb7d88b1c29e09f57fccd5053616ae\\n\\n\\nCopy              \\n\\n\\n\\n\\n\\n\\nClose\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHelp\\n\\n\\nInstalling packages\\nUploading packages\\nUser guide\\nProject name retention\\nFAQs\\n\\n\\n\\n\\nAbout PyPI\\n\\n\\nPyPI on Twitter\\nInfrastructure dashboard\\nStatistics\\nLogos & trademarks\\nOur sponsors\\n\\n\\n\\n\\nContributing to PyPI\\n\\n\\nBugs and feedback\\nContribute on GitHub\\nTranslate PyPI\\nSponsor PyPI\\nDevelopment credits\\n\\n\\n\\n\\nUsing PyPI', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='Contributing to PyPI\\n\\n\\nBugs and feedback\\nContribute on GitHub\\nTranslate PyPI\\nSponsor PyPI\\nDevelopment credits\\n\\n\\n\\n\\nUsing PyPI\\n\\n\\nCode of conduct\\nReport security issue\\nPrivacy policy\\nTerms of use\\nAcceptable Use Policy\\n\\n\\n\\n\\n\\n\\nStatus:\\nall systems operational\\n\\n\\nDeveloped and maintained by the Python community, for the Python community.          \\nDonate today!\\n\\n\\n          \"PyPI\", \"Python Package Index\", and the blocks logos are registered trademarks of the Python Software Foundation.\\n\\n\\n          © 2024 Python Software Foundation\\nSite map\\n\\n\\n\\n\\nSwitch to desktop version        \\n\\n\\n\\n\\n\\n\\n\\n              English\\n            \\n\\n\\n\\n              español\\n            \\n\\n\\n\\n              français\\n            \\n\\n\\n\\n              日本語\\n            \\n\\n\\n\\n              português (Brasil)\\n            \\n\\n\\n\\n              українська\\n            \\n\\n\\n\\n              Ελληνικά\\n            \\n\\n\\n\\n              Deutsch\\n            \\n\\n\\n\\n              中文 (简体)\\n            \\n\\n\\n\\n              中文 (繁體)', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'}), Document(page_content='українська\\n            \\n\\n\\n\\n              Ελληνικά\\n            \\n\\n\\n\\n              Deutsch\\n            \\n\\n\\n\\n              中文 (简体)\\n            \\n\\n\\n\\n              中文 (繁體)\\n            \\n\\n\\n\\n              русский\\n            \\n\\n\\n\\n              עברית\\n            \\n\\n\\n\\n              esperanto\\n            \\n\\n\\n\\n\\n\\nSupported by\\n\\n\\n\\nAWS\\n\\n            Cloud computing and Security Sponsor\\n          \\n\\n\\n\\nDatadog\\n\\n            Monitoring\\n          \\n\\n\\n\\nFastly\\n\\n            CDN\\n          \\n\\n\\n\\nGoogle\\n\\n            Download Analytics\\n          \\n\\n\\n\\nMicrosoft\\n\\n            PSF Sponsor\\n          \\n\\n\\n\\nPingdom\\n\\n            Monitoring\\n          \\n\\n\\n\\nSentry\\n\\n            Error logging\\n          \\n\\n\\n\\nStatusPage\\n\\n            Status page', metadata={'source': 'https://pypi.org/project/hfautogen/', 'title': 'hfautogen · PyPI', 'description': 'A seemless way to use HuggingFace Inference API with Autogen.', 'language': 'en'})]\n",
            "article: Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums\n",
            "article: https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html\n",
            "Splits: [Document(page_content='Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content='Friday, 8 March 2024ePaperPuzzlesOur JournalismOur StoryContact UsLog InNewsOpinionBusinessSportLifeStyleEntertainmentTravelVideoIrish NewsPoliticsEducationHealthCourtsCrimeEnvironmentSeachtainDublinLocal NewsSelect your countyLocal ePapersReferendumsWorldEuropeBritainNorth AmericaLatin AmericaMiddle EastAsia-PacificAustralasiaAfricaFarmingNewsAgri-businessDairyTillageBeefSheepFarm PropertyMachineryLegal AdviceCommentRural LifeSchemesFinanceLatest NewsSubscriber ExclusivesPodcastsThe Indo DailyThe Left WingThe Big Tech ShowReal Health PodcastThe Throw-InTopicsSearch for articlesNewsOverviewIrish NewsOverviewPoliticsEducationHealthCourtsCrimeEnvironmentSeachtainDublinLocal NewsOverviewSelect your countyLocal ePapersReferendumsWorldOverviewEuropeBritainNorth AmericaLatin AmericaMiddle EastAsia-PacificAustralasiaAfricaFarmingOverviewNewsAgri-businessDairyTillageBeefSheepFarm PropertyMachineryLegal AdviceCommentRural LifeSchemesFinanceLatest NewsSubscriber ExclusivesPodcastsOverviewThe', metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content=\"PropertyMachineryLegal AdviceCommentRural LifeSchemesFinanceLatest NewsSubscriber ExclusivesPodcastsOverviewThe Indo DailyThe Left WingThe Big Tech ShowReal Health PodcastThe Throw-InOpinionOverviewLettersEditorialAnalysisCommentBusinessOverviewIrishWorldTechnologyPersonal FinanceSmall BusinessJobsCommercial PropertyIn The WorkplaceSportOverviewRugbyOverviewThe Left WingChampions CupUnited Rugby ChampionshipSix NationsLeinster RugbyMunster RugbyUlster RugbyConnacht RugbyGAAOverviewGaelic FootballHurlingThe Throw InU-20 Gaelic FootballU-20 HurlingCamogieLadies FootballSoccerOverviewPremier LeagueInternational SoccerChampions LeagueLeague of IrelandOther SoccerThe Left WingWomen's SportGolfHorse RacingOther SportsOverviewCricketCyclingHockeyAthleticsBoxingEquestrianMotor SportSnookerSwimmingTennisICycleLifeOverviewHealth & WellbeingOverviewHealth FeaturesHealthy EatingFitnessMental HealthBaby LossHome & GardenOverviewHomesNew HomesGardensInteriorsFamilyOverviewFamily\", metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content='SportSnookerSwimmingTennisICycleLifeOverviewHealth & WellbeingOverviewHealth FeaturesHealthy EatingFitnessMental HealthBaby LossHome & GardenOverviewHomesNew HomesGardensInteriorsFamilyOverviewFamily FeaturesLearningParentingMothers & BabiesParenting Food & DrinkOverviewRecipesFood NewsFood ReviewsWineMotoringOverviewNewsReviewsCar TalkStyleOverviewCelebrityOverviewCelebrity NewsCelebrity FeaturesFashionOverviewFashion NewsFashion FixStyle TalkBeautyOverviewBodyHairMakeupSex & RelationshipsEntertainmentOverviewMoviesOverviewMovie NewsMovie ReviewsTelevisionOverviewTV NewsTV ReviewsMusicOverviewMusic NewsMusic ReviewsRadioBooksOverviewBook NewsBook ReviewsTheatre & ArtsGamesFestivalsPuzzlesCompetitionsTravelOverviewReader Travel AwardsTravel NewsStaycationsIrelandReviewsWalksEuropeWorld/USACruiseSkiVideoExtraePaperPuzzlesOur JournalismOur StoryContact Us', metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content='Home\\n\\n>\\n\\n\\n\\nIrish News\\n\\n>\\n\\n\\n\\nReferendums\\n\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n\\nEight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendumsMaeve McTaggart: March 8th referendum explained Fionnán SheahanYesterday at 03:30What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.Opinion polls are indicating a \\xadnarrowing of the leads for the Yes camp and a large amount of voter confusion.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJoin the Irish Independent WhatsApp channel\\nStay up to date with all the latest news', metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content=\"Latest ReferendumsReferendums hang in balance, says Leo Varadkar as he calls for Yes vote Marianne Heron: Rushing through changes poses risk to women’s rightsLeo Varadkar: The Constitution must catch up to give all families and carers surer footing – so vote Yes-YesEight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendumsThe Indo Daily: Yes/Yes Vs No/No - A debate special on Ireland's upcoming March 8th referendumsYes vote in care referendum would mean more supports for carers, says Social Protection Minister Heather HumphreysLetters: Our ageing Constitution needs more than endless bouts of patching upAnna Grainger: As a lone parent, I’ll be voting Yes this FridayMother of four disabled children calling for No vote in care referendumMarch 8 referendums explained: What changes on women and family are proposed for the Constitution – and why?Show more\", metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content=\"Top StoriesLifeModern Morals: My friend has turned into a social media troll who picks fights online. Should I unfollow her?IrelandFirst Look: The Leinster – is Dublin’s ‘luxury lifestyle’ hotel the hottest opening of 2024? RugbyTales from Twickenham: Tony O'Reilly's unlikely comeback and making Clive Woodward eat his wordsIrish NewsEverything you need to know about voting in the Friday referendums\", metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content=\"Latest NewsMoreWineSplendid sips for a Mother’s Day afternoon tea03:30LifeThe rise and rise of girl culture: ‘When grown women flock to unicorns or glitter pens, it shows they desperately crave more moments to destress’03:30FashionStyle Notes: Bold graffiti print keeps up element of surprise at Dior03:30Book ReviewsTana French evokes Wild west tensions in an Irish town in The Hunter03:30RugbyTales from Twickenham: Tony O'Reilly's unlikely comeback and making Clive Woodward eat his words03:30Book Reviews‘There was scarcely an inch of his flesh that was not gashed’: when Irish emigrants massacred Manhattan’s black community03:30MusicSeventy-year-old Kim Gordon channels her rage in captivating second album03:30TechnologyAsk Adrian: How can I avoid big phone bills on a trip to America?03:30Home & GardenA period home and its ground-floor shop on Enniscorthy’s Main Street has a unique selling point03:30Home & GardenYou can rest on your Laurels at extended Castleknock home03:30\", metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content=\"Top StoriesMoreVideosSupermac's owner Pat McDonagh reacts to dropping of legal casePersonal FinanceElectricity in Ireland is dearest in Europe at €700 a year more than EU averageHealth‘We’re helping to break gender bias’ – how HSE is tackling equality at senior level in a workplace that is 79pc womenSix NationsRúaidhrí O’Connor: Garry Ringrose's absence is a sign of changing times for IrelandCommentFionnuala O’Leary: That such a little girl could make such a big difference is testament to who Saoirse Ruane was\", metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content=\"Most Read ReferendumsIrish NewsEverything you need to know about voting in the Friday referendumsReferendumsEight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendumsReferendumsThe Indo Daily: Yes/Yes Vs No/No - A debate special on Ireland's upcoming March 8th referendumsReferendumsMarch 8 referendums explained: What changes on women and family are proposed for the Constitution – and why?ReferendumsPoll: Uncertainty among voters could lead to a referendum surprise yet\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe Indo DailyMore EpisodesThe Indo Daily: The Oscars scandals, snubs and controversies that shook Hollywood\", metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content=\"NewsLatest NewsIrish newsWorld NewsDublinLocal NewsLocal ePapersEnvironmentWeatherVideoTopicsOpinionLettersEditorialCommentJournalistsBusinessBudget 2023IrishWorldTechnologyPersonal FinanceSmall BusinessFarmingJobsCommercial PropertyIn The WorkplaceSportRugbyGAASoccerThe Left WingThe Throw InWomen's SportGolfHorse RacingOther SportsICycleLifeHealth & WellbeingHome & GardenFamilyParentingFood & DrinkMotoringStyleCelebrityFashionBeautySex & RelationshipsVoicesGalleriesEntertainmentMoviesTelevisionMusicRadioBooksTheatre & ArtsGamesFestivalsPuzzlesCompetitionsTravelReader Travel AwardsTravel NewsStaycationsIrelandReviewsWalksEuropeWorld/USATravel TVCruiseSkiPodcastsThe Indo DailyThe Left WingThe Big Tech ShowReal Health PodcastThe Throw InMoreOur JournalismOur StoryContact UsCorporate and Social ResponsibilitySubscription BundlesSubscriber RewardsSubscription PuzzlesFAQ'sePapersNewsletters_________StoryplusCarsIreland.ieCarzone.ieCartell.ieSwitcher.ieDiscount CodesReach\", metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'}), Document(page_content=\"and Social ResponsibilitySubscription BundlesSubscriber RewardsSubscription PuzzlesFAQ'sePapersNewsletters_________StoryplusCarsIreland.ieCarzone.ieCartell.ieSwitcher.ieDiscount CodesReach DelpacSocialsSitemapArchiveTerms & conditionsContact usPrivacy statementCookie PolicyGroup WebsitesAdvertise with UsAWEBSITE © independent.ieFollow us:SitemapArchiveTerms & conditionsContact usPrivacy statementCookie PolicyGroup WebsitesAdvertise with UsSubscription BundlesSubscription RewardsSubscription PuzzlesFAQ'sePapersNewsletters\", metadata={'source': 'https://www.independent.ie/irish-news/referendums/eight-reasons-official-ireland-is-nervy-of-a-not-so-durable-no-outcome-in-tomorrows-referendums/a2139031901.html', 'title': 'Eight reasons Official Ireland is nervy of a not-so-durable No outcome in tomorrow’s referendums | Independent.ie', 'description': 'What were pitched as straightforward cleaning-up exercises of outdated language in the Constitution have become tricky stumbling blocks for the Government. The so-called \\xadfamily and care referendums tomorrow are creating nervousness in the political system as polling day approaches.', 'language': 'en'})]\n",
            "article: How much we’re actually dreading this Biden-Trump rematch\n",
            "article: https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/\n",
            "Splits: [Document(page_content='How much we’re actually dreading this Biden-Trump rematch - The Washington PostAccessibility statementSkip to main contentDemocracy Dies in DarknessSign inThe Washington PostDemocracy Dies in DarknessPoliticsBiden administration The Fix The 202s Polling Democracy in America Election 2024 PoliticsBiden administration The Fix The 202s Polling Democracy in America Election 2024 How much we’re actually dreading this Biden-Trump rematchAnalysis by  Aaron BlakeStaff writerMarch 6, 2024 at 8:35 p.m. ESTFormer president Donald Trump in Iowa in January and President Biden in Delaware in November. (Tannen Maurybrendan Smialowski/AFP/Getty Images)Listen4 minShareComment on this storyCommentAdd to your saved storiesSaveIf the two parties’ respective nominating contests weren’t over weeks ago, they surely are now. That’s thanks to the post-Super Tuesday exits from the campaign of President Biden’s top challenger, Rep. Dean Phillips (D-Minn.), and Donald Trump’s top challenger, Nikki Haley.Cut', metadata={'source': 'https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/', 'title': 'How much we’re actually dreading this Biden-Trump rematch - The Washington Post', 'description': 'Putting the “rematch that nobody wants” into context.', 'language': 'en'}), Document(page_content='surely are now. That’s thanks to the post-Super Tuesday exits from the campaign of President Biden’s top challenger, Rep. Dean Phillips (D-Minn.), and Donald Trump’s top challenger, Nikki Haley.Cut through the 2024 election noise. Get The Campaign Moment newsletter.ArrowRightThis leaves us with a general-election matchup that’s been called the campaign that nobody wants.But just how much are Americans dreading it?Haley often oversold the problem. Among other things, she said that 70 percent of Americans didn’t want a 2020 rematch and that “the majority of Americans don’t just dislike one candidate; they dislike both.”Haley massaged her language to exaggerate the distaste. For example, it’s true that majorities of Americans dislike each candidate, but it’s not true that a single majority dislikes both Trump and Biden. It’s more like 20 percent, according to the polls.AdvertisementThat doesn’t mean the underlying point isn’t valid. It’s quite possible we’re confronting the most', metadata={'source': 'https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/', 'title': 'How much we’re actually dreading this Biden-Trump rematch - The Washington Post', 'description': 'Putting the “rematch that nobody wants” into context.', 'language': 'en'}), Document(page_content='dislikes both Trump and Biden. It’s more like 20 percent, according to the polls.AdvertisementThat doesn’t mean the underlying point isn’t valid. It’s quite possible we’re confronting the most disconcerting general election in modern history.And a few stats stand out.One is the above figure — the so-called “double-haters.” The percentage of Americans who dislike both candidates has registered, in various polls, at 24 percent, 22 percent, 19 percent, 18 percent and 17 percent.That’s compared to only about 5 percent who disliked both of the same two candidates at the end of their 2020 matchup, and just 3 percent who disliked both Barack Obama and Mitt Romney in 2012. About the only modern campaign that compares is Trump vs. Hillary Clinton in 2016, when exit polls showed 18 percent liked neither nominee.One thing Haley did get about right was that 6 in 10 Americans say both candidates are too old — again, not different groups of 6 in 10 saying each is too old, but one group totaling 59', metadata={'source': 'https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/', 'title': 'How much we’re actually dreading this Biden-Trump rematch - The Washington Post', 'description': 'Putting the “rematch that nobody wants” into context.', 'language': 'en'}), Document(page_content='nominee.One thing Haley did get about right was that 6 in 10 Americans say both candidates are too old — again, not different groups of 6 in 10 saying each is too old, but one group totaling 59 percent saying that both are, according to a recent ABC News/Ipsos poll.AdvertisementThat has to be unprecedented, in large part because we’ve never had a matchup of candidates this old. And the number appears to be on the rise even in this election cycle. Previous Washington Post/ABC News polls pegged it at 43 percent in May and 48 percent in September.Stumbles by both candidates, which have proliferated, could cause the figure to rise further.Another number that stands out is how satisfied Americans said they would be with the choices they now have.A December AP-NORC poll showed at least 56 percent of Americans said they would be dissatisfied with the nominations of each man. Only 3 in 10 said they would be satisfied with either one.Independents were especially disillusioned. Just 14 percent', metadata={'source': 'https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/', 'title': 'How much we’re actually dreading this Biden-Trump rematch - The Washington Post', 'description': 'Putting the “rematch that nobody wants” into context.', 'language': 'en'}), Document(page_content='of Americans said they would be dissatisfied with the nominations of each man. Only 3 in 10 said they would be satisfied with either one.Independents were especially disillusioned. Just 14 percent said they would be satisfied with Biden’s nomination, while 20 percent said they would be satisfied with Trump’s nomination.AdvertisementA huge majority of independents now gets to choose between nominees they never really wanted.Finally, there is the question of how much this election will be defined by voting against the other guy. The country has a long history of this, but it should be especially pronounced this time.A recent NBC News poll showed that 57 percent of Trump backers said their vote was mostly about supporting him. That’s down from about three-quarters in exit polls and late surveys of the 2020 race when Trump was president.Biden’s numbers here are particularly inauspicious. Just 31 percent said their vote was mostly about supporting him. That’s lower than the 54 percent who', metadata={'source': 'https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/', 'title': 'How much we’re actually dreading this Biden-Trump rematch - The Washington Post', 'description': 'Putting the “rematch that nobody wants” into context.', 'language': 'en'}), Document(page_content='of the 2020 race when Trump was president.Biden’s numbers here are particularly inauspicious. Just 31 percent said their vote was mostly about supporting him. That’s lower than the 54 percent who said their 2020 vote was mostly supporting him in exit polls, and it’s the lowest such number for any presidential candidate in the 21st century.AdvertisementAll told, about half of voters who named their preference between the two in the new poll said they were more animated by their opposition to the other guy than their support of their own.So it isn’t that Americans are unlikely to find something acceptable in at least one of the two major-party nominees or that they necessarily hate both of them. But they are quite disillusioned with their choice, and the decisive voters are quite likely to be those who never liked either man much.And that’s before the two candidates really start ripping the bark off each other.Share CommentsSign uplive updatespoliticsChevronRight11:44 PMBiden to propose', metadata={'source': 'https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/', 'title': 'How much we’re actually dreading this Biden-Trump rematch - The Washington Post', 'description': 'Putting the “rematch that nobody wants” into context.', 'language': 'en'}), Document(page_content='those who never liked either man much.And that’s before the two candidates really start ripping the bark off each other.Share CommentsSign uplive updatespoliticsChevronRight11:44 PMBiden to propose new $5,000 tax credit for first-time home buyers11:33 PMWhat to know about Sen. Katie Britt, GOP’s pick for State of the Union rebuttal11:29 PMBiden to use address to show contrast with Trump over abortion, American values11:21 PMVideo: Suozzi says Democrats need to ‘listen’ to people on border policy10:55 PMActors who played American presidents give Biden advice TOP STORIESPoliticsReporting and analysis from the Hill and the White HouseElection 2024 latest news: Trump, Biden turn attention to each other with rematch setBiden: Ban deductions for firms paying executives more than $1 millionAnalysis|How much we’re actually dreading this Biden-Trump rematchRefreshTry a different topicSign in or create a free account to save your preferenceswashingtonpost.com  © 1996-2024 The Washington', metadata={'source': 'https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/', 'title': 'How much we’re actually dreading this Biden-Trump rematch - The Washington Post', 'description': 'Putting the “rematch that nobody wants” into context.', 'language': 'en'}), Document(page_content='much we’re actually dreading this Biden-Trump rematchRefreshTry a different topicSign in or create a free account to save your preferenceswashingtonpost.com  © 1996-2024 The Washington Postwashingtonpost.com © 1996-2024 The Washington Post', metadata={'source': 'https://www.washingtonpost.com/politics/2024/03/06/how-much-were-actually-dreading-this-biden-trump-rematch/', 'title': 'How much we’re actually dreading this Biden-Trump rematch - The Washington Post', 'description': 'Putting the “rematch that nobody wants” into context.', 'language': 'en'})]\n",
            "article: Guiyang's tourist appeal grows\n",
            "article: https://www.investorsobserver.com/news/qm-pr/6327499745946530\n",
            "Splits: [Document(page_content=\"Guiyang's tourist appeal grows\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStocks\\nCrypto\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat We Do\\nReviews\\nAbout Us\\nPricing\\nSign Up\\nLogin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign Up\\nLogin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\nMy Portfolio\\n\\nStocks\\n\\nStocks Dashboard\\nTop 5 Stocks\\nStock Screener\\nSector & Industry\\n\\n\\n\\nOptions\\n\\nOptions Dashboard\\nOptions Portfolios\\nOptions Screener\\n\\n\\nCrypto\\n\\nCalendars\\n\\nEarnings Calendar\\nFDA Calendar\\n\\n\\nCompare\\nNews\\nHelp Center\\n\\n\\n\\n\\n×\\n\\n\\nHome\\nMy Portfolio\\n\\nStocks\\n\\nStocks Dashboard\\nTop 5 Stocks\\nStock Screener\\nSector & Industry\\n\\n\\n\\nOptions\\n\\nOptions Dashboard\\nOptions Portfolios\\nOptions Screener\\n\\n\\nCrypto\\n\\nCalendars\\n\\nEarnings Calendar\\nFDA Calendar\\n\\n\\nCompare\\nNews\\nHelp Center\\nPricing\\nWhat We Do\\nReviews\\nAbout Us\\nLogin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNews Home\\n\\nGuiyang's tourist appeal grows\\n\\nThursday, March 07, 2024 01:01 AM | PR Newswire via QuoteMedia\\n\\n\\n\\n\\nGuiyang's tourist appeal grows\\n\\n\\n\\n   Guiyang's tourist appeal grows\\n  \\n\\n\\n\\n\\n\\n    PR Newswire\\n   \\n\\n\\n\\n\\n\\n      BEIJING\\n     \\n\\n    ,\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content=\"Guiyang's tourist appeal grows\\n\\n\\n\\n   Guiyang's tourist appeal grows\\n  \\n\\n\\n\\n\\n\\n    PR Newswire\\n   \\n\\n\\n\\n\\n\\n      BEIJING\\n     \\n\\n    ,\\n    \\n\\n      March 6, 2024\\n     \\n\\n    /PRNewswire/ -- A news report from\\xa0chinadaily.com.cn:\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n     Guizhou\\n    \\n    provincial capital becomes a major attraction to visitors who are relishing the variety of sights and entertainment on offer,\\n    \\n     Yang Jun\\n    \\n    and\\n    \\n     Peng Chao\\n    \\n    report.\\n   \\n\\n\\n     Guiyang\\n    \\n    , the capital of\\n    \\n     Guizhou\\n    \\n    province, is not just a key transit hub for tourists traveling to\\n    \\n     Southwest China\\n    \\n    , but it is also transforming itself into a popular tourist destination in its own right. With an attractive blend of distinctive ethnic culture, breathtaking landscapes and a trendy, modern urban lifestyle, the city offers visitors a unique travel experience.\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='Statistics from\\n    \\n     Guiyang\\'s\\n    \\n    culture and tourism bureau show that in 2023 the city received 147 million visits, of which 31.2 million were overnight visitors, a year-on-year increase of 64.7 percent.\\n   \\n\\n    According to the 2024 Year of the Dragon Spring Festival travel report, released by Chinese online travel giant Ctrip, tourism orders in\\n    \\n     Guiyang\\n    \\n    saw a 105 percent increase compared to last year, with ticket sales increasing nearly sixfold.\\n   \\n\\n    The report also named\\n    \\n     Guiyang\\n    \\n    as one of the top 10 \"dark horse\" tourism destinations for domestic self-driving tours during the recent Spring Festival holiday.\\n   \\n\\n\\n     Museum in the village\\n    \\n\\n\\n    For those who want to enjoy a cultural experience, but escape the hustle and bustle of the city, they may be pleasantly surprised to find that there is a museum in a small village on the outskirts of\\n    \\n     Guiyang\\n    \\n    .', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='The Museum of Memory on Hands is located 20 kilometers west of the downtown area, in a village called Wenggong (from the language of the Miao ethnic group meaning \"golden spring\").\\n   \\n\\n    The museum collects a wide range of intangible cultural heritage artifacts from various ethnic groups in\\n    \\n     Guizhou\\n    \\n    , including, the Miao, Bouyei, Dong, Yao, Gelao, and Sui. It currently houses a total of 4,819 items.\\n   \\n\\n\\n     Wang Xiaomei\\n    \\n    , a former journalist, is the founder of this museum. It was in 2002, when Wang had just joined the workforce, that she collected her first piece of Miao wax-dyeing work.\\n   \\n\\n    Fascinated by the ancient craft, she has been collecting items related to wax dyeing, printing and dyeing, tie-dyeing, maple-fragrance dyeing, paste dyeing, as well as embroidery, ever since.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='In 2018, Wang returned to her home in Wenggong village and dedicated herself to a project focusing on the collection, study, exhibition and revitalization of traditional handicrafts, which later evolved into the Museum of Memory on Hands.\\n   \\n\\n    The new, phoenix-shaped building opened to the public in May last year. It is a harmonious blend of modern brick and concrete architecture and utilizes traditional mortise and tenon wooden frames. It has a permanent exhibition area of 1,500 square meters and a temporary exhibition area of 300 sq m, displaying exquisite embroidery and dyeing artworks from the various ethnic groups in\\n    \\n     Guizhou\\n    \\n    .\\n   \\n\\n    \"Unlike traditional museums, with their large glass display cases, we adopt an open storage approach, which is popular in\\n    \\n     Europe\\n    \\n    and\\n    \\n     the United States\\n    \\n    . It allows visitors to get a closer look at the exhibits and participate in their interpretation,\" she says.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='Visitors can also learn about ancient book restoration techniques in the studio, or experience traditional printing and dyeing handicraft using natural plant dyes in the intangible cultural heritage handicraft experience area.\\n   \\n\\n    \"The village has preserved many folk activities, and the museum is working with the villagers to revive some of the traditional customs. Any visitor to the museum can participate in these activities,\" Wang says.\\n   \\n\\n    The museum welcomed more than 17,000 visitors last year. However, Wang is not particularly concerned about the number of visitors, but more about whether they truly appreciate and cherish these artifacts.\\n   \\n\\n    \"I don\\'t want these beautiful artifacts to be merely display items. I hope more people who really have a passion for these crafts come to interact with us,\" she says.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='\"I don\\'t want these beautiful artifacts to be merely display items. I hope more people who really have a passion for these crafts come to interact with us,\" she says.\\n   \\n\\n    She says that the museum has built \"a craft-and-bed hotel\" with 22 rooms where visitors who really love traditional handicrafts can stay. Prices range from\\n    \\n     200 yuan\\n    \\n\\n     ($27.8)\\n    \\n    to\\n    \\n     1,000 yuan\\n    \\n    per night.\\n   \\n\\n    The hotel offers dozens of experiential courses, and, while staying there and indulging in traditional handicrafts, visitors are also provided with food sourced from local organic produce, Wang says.\\n   \\n\\n    The museum is only 5 kilometers from the nearest subway station. However, it is fairly secluded, due to the only access being along a rugged, 3-km country road. Wang thinks the location is appropriate.\\n   \\n\\n    \"In this bustling era, there is a need for a piece of land that can bring tranquility and offer healing to people,\" she says.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='\"In this bustling era, there is a need for a piece of land that can bring tranquility and offer healing to people,\" she says.\\n   \\n\\n\\n     Natural wonders\\n    \\n\\n\\n    For those who like to be close to nature, a visit to the Baihua Lake near Wenggong village is highly recommended.\\n   \\n\\n    The lake itself is about 11 square kilometers, dotted with 108 islands of different sizes and shapes. The lake was named Baihua, which literally means \"hundred kinds of flowers\" in Chinese, and every spring it is engulfed in a blaze of color.\\n   \\n\\n    \"Due to long-term strict ecological protection measures, no large-scale tourism development has been carried out here, allowing us to preserve an ecological wonder in the midst of the urban sprawl,\" says\\n    \\n     Zhao Ling\\n    \\n    , director of the general department of the Baihua Lake Scenic Area\\'s management office.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='The site covers 122 sq km, accounting for some 40 percent of the total area of Guanshanhu district in which it is located.\\n   \\n\\n    \"The period from April to October is peak tourist season, and it\\'s just a short Metro ride from downtown,\" he says.\\n   \\n\\n    Zhao says that the scenic area offers boat tours, allowing visitors to enjoy the full spectacle of the lake in about 40 to 50 minutes. Visitors can also enjoy barbecues, mahjong and sunbathing at farmhouses equipped to cater to visitors.\\n   \\n\\n    Tourists fascinated by\\n    \\n     Guizhou\\'s\\n    \\n    karst landscapes can also visit Panlong Cave within the scenic area. Inside the cave are well-preserved, densely covered stalactites and stalagmites.\\n   \\n\\n    One of the stalactite columns has a diameter of around 4 meters at its base and is about 15 meters in length. Based on the average growth rate of stalactites, which is one centimeter per 100 years, this stalactite has been formed over a span of at least 150,000 years.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='To better serve residents and tourists, the Guanshanhu district abolished the entrance fee to the scenic area in August last year.\\n   \\n\\n    Zhao says that villagers on the islands are renovating their houses into homestays to meet visitor accommodation needs.\\n   \\n\\n    \"A 46.6-km-long slow travel system is currently under construction around the Baihua Lake. Once completed, it will offer visitors a different immersive experience,\" he adds.\\n   \\n\\n    Visitors interested in exploring the mysteries of the area\\'s natural wonders should not miss the Geological Museum of\\n    \\n     Guizhou\\n    \\n    . With more than 100,000 exhibits, including ancient biological fossils, crystals, rock and mineral samples, the museum showcases\\n    \\n     Guizhou\\'s\\n    \\n    geological history of the past 900 million years and a paleontological history spanning 600 million years.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='Visitors can see rare fossils, including that of a 106-square-meter sea lily, as well as that of one of the most primitive reptiles on Earth, the Keichousaurus hui (an aquatic creature), and the extremely valuable remains of a Guanlingsaurus liangae (also a large marine creature) that was possibly pregnant at the time of its demise.\\n   \\n\\n\\n     Modern experiences\\n    \\n\\n\\n    As a modern metropolis,\\n    \\n     Guiyang\\n    \\n    offers a plethora of stylish and trendy experiences. A Yun Duo Cang, meaning \"my ideal place\" in the Yi language, is one of the latest hot spots where young people in\\n    \\n     Guiyang\\n    \\n    gather. With the architectural and interior design reflecting\\n    \\n     Guizhou\\'s\\n    \\n    natural landscapes, cultural heritage and urban art, it offers a diverse range of consumer experiences, such as motorcycle shops, camping-style bars converted from underground garages, illustration art stores, skateboard clubs, and niche coffee shops.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='For car enthusiasts seeking an exhilarating experience, a visit to the Guanshanhu Automobile Park would be difficult to pass up.\\n   \\n\\n    With free entry, it stands out as one of the few in the country where visitors can get up close to a wide range of luxury, superluxury and limited-edition supercars from around the world.\\n   \\n\\n    Here, visitors can also use simulators for free to experience the exhilaration of motor racing. Additionally, petrolheads can not only experience the ultimate thrill of accelerating from zero to 100 kilometers per hour in under three seconds in a real supercar, but also learn skills, for a fixed fee, under the guidance of a professional instructor.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='During the Guanshanhu Lantern Festival event, Guanshanhu Park attracted a total of 660,000 visitors during its celebrations from\\n    \\n     Jan 30 to Feb 25\\n    \\n    . The event covered a total area of more than 250,000 sq m, the largest such event in\\n    \\n     Guiyang\\n    \\n    to date, according to\\n    \\n     Zhou Hang\\n    \\n    , chief designer of the lantern festival.\\n   \\n\\n    \"Inspired by Shanhaijing (The Classic of Mountains and Seas), an ancient work of Chinese literature, as well as the splendid mountainous landscape of\\n    \\n     Guizhou\\n    \\n    , the lantern festival consisted of six themed lantern areas with nearly 100 sets of lanterns,\" he says, adding that 12 stages were set up at the lantern areas, offering a total of 500 performances, such as singing, dancing, acrobatics and cross-talk, in collaboration with various arts groups.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='Outside of such festivals, there is a vibrant urban nightlife to enjoy and, after a day of exploring, getting immersed in the city\\'s music scene at either the Gui Live House or Mengtian Live House is a perfect way to spend an evening.\\n   \\n\\n    \"\\n    \\n     Guiyang\\n    \\n    used to be more of a tourist transit city, but its appeal to tourists has been consistently growing in recent years,\" says He Hanxiao, marketing communications manager of the Renaissance Guiyang Hotel, who has been working in the city for seven years.\\n   \\n\\n    He says that the hotel\\'s guests used to be mainly business people, but last year it saw a significant increase in the number of tourists on family trips. The roadside concerts and large-scale music festivals held in the city also brought a noticeable increase in customer flow to the hotel, he adds.\\n   \\n\\n\\n\\n\\n    View original content to download multimedia:\\n    \\n     https://www.prnewswire.com/news-releases/guiyangs-tourist-appeal-grows-302082487.html', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content=\"View original content to download multimedia:\\n    \\n     https://www.prnewswire.com/news-releases/guiyangs-tourist-appeal-grows-302082487.html\\n    \\n\\n\\n    SOURCE  chinadaily.com.cn\\n   \\n\\n\\n\\n\\nPR NewswireMarch 6, 2024 - 10:01 PM PSTNews by QuoteMediawww.quotemedia.com\\n\\n\\nShare this article:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStay In The Know\\nSubscribe to our daily morning update newsletter and never miss out on the need-to-know market news, movements, and more.\\n\\n\\n\\nYour Name\\n\\n\\n\\nEmail Address\\n\\n\\n\\nGet Newsletter\\n\\n\\n\\n\\n\\n\\n\\nThank you for signing up! You're all set to receive the Morning Update newsletter\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Articles\\n\\n\\n\\nLiaoning set to play bigger role as key trade hub\\n\\n\\n                    Thursday, March 07, 2024 09:32 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nCrackdown on telecom fraud bears fruit, says chief of top procuratorate\\n\\n\\n                    Thursday, March 07, 2024 09:20 PM | PR Newswire via QuoteMedia\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='Crackdown on telecom fraud bears fruit, says chief of top procuratorate\\n\\n\\n                    Thursday, March 07, 2024 09:20 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nChina is attracting foreign investment, in stable amount under an optimized structure\\n\\n\\n                    Thursday, March 07, 2024 08:58 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nStation Casinos LLC Announces Pricing of Senior Notes Offering\\n\\n\\n                    Thursday, March 07, 2024 08:20 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\n\"LUKi & The Lights\" Animated Short Film Illuminates ALS Diagnosis for Young Audiences\\n\\n\\n                    Thursday, March 07, 2024 07:44 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nMindfulness Meditation Application Market Soars to US$ 172.3 Million in 2024, Predicted to Reach US$ 467.6 Million by 2034 | Future Market Insights, Inc.\\n\\n\\n                    Thursday, March 07, 2024 07:30 PM | GlobeNewswire via QuoteMedia', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='Thursday, March 07, 2024 07:30 PM | GlobeNewswire via QuoteMedia\\n                \\n\\n\\n\\n\\n\\n\\nYou May Also Like\\n\\n\\n\\n\\n\\n\\nRelated Articles\\n\\n\\n\\nLiaoning set to play bigger role as key trade hub\\n\\n\\n                    Thursday, March 07, 2024 09:32 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nCrackdown on telecom fraud bears fruit, says chief of top procuratorate\\n\\n\\n                    Thursday, March 07, 2024 09:20 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nChina is attracting foreign investment, in stable amount under an optimized structure\\n\\n\\n                    Thursday, March 07, 2024 08:58 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nStation Casinos LLC Announces Pricing of Senior Notes Offering\\n\\n\\n                    Thursday, March 07, 2024 08:20 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\n\"LUKi & The Lights\" Animated Short Film Illuminates ALS Diagnosis for Young Audiences', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='Thursday, March 07, 2024 08:20 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\n\"LUKi & The Lights\" Animated Short Film Illuminates ALS Diagnosis for Young Audiences\\n\\n\\n                    Thursday, March 07, 2024 07:44 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nMindfulness Meditation Application Market Soars to US$ 172.3 Million in 2024, Predicted to Reach US$ 467.6 Million by 2034 | Future Market Insights, Inc.\\n\\n\\n                    Thursday, March 07, 2024 07:30 PM | GlobeNewswire via QuoteMedia\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDownload the app\\n\\n\\n\\n\\n\\n\\n\\nContact\\n\\n435 Merchant Walk Square, Suite 300-145\\nCharlottesville, VA 22902\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStocks\\n\\n\\nStocks Dashboard\\nTop 5 Stocks\\nStock Screener\\n\\nOptions\\n\\nOptions Dashboard\\nOptions Portfolios\\nOptions Trade Screener\\n\\nCrypto\\n\\nCrypto Dashboard\\n\\n\\n\\nAccount and Support\\n\\nMy Account\\nAbout Us\\nNewsletters\\nContact Us\\nHelp Center\\nReviews\\nEmail Whitelist Instructions', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'}), Document(page_content='Crypto\\n\\nCrypto Dashboard\\n\\n\\n\\nAccount and Support\\n\\nMy Account\\nAbout Us\\nNewsletters\\nContact Us\\nHelp Center\\nReviews\\nEmail Whitelist Instructions\\n\\n\\n\\n\\nStock Price data may be delayed up to 15 minutes.\\nCopyright Â© 2024. Portions of this content may be copyrighted by Fresh Brewed Media, Investors Observer, and/or O2 Media LLC. All Rights Reserved. Portions of this content protected by US Patent numbers 7,865,496, 7,856,390, and 7,716,116. Investing in stocks, bonds, option and other financial instruments involve risks and may not be suitable for everyone. Portfolio results are unaudited and based on varying investment expiration dates. Terms of Service | Privacy Policy\\n\\n\\n\\n\\n\\n\\nGet the InvestorsObserver App', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/6327499745946530', 'title': \"Guiyang's tourist appeal grows\", 'description': \"Guiyang's tourist appeal grows           PR Newswire             BEIJING     ,     March 6, 2024     /PRNewswire/ -- A news report from&#xA0;chinadaily.com.cn:                   Guizhou   provincial capital becomes a major attraction to visitors who ar...\", 'language': 'en'})]\n",
            "article: IT World Canada fights for survival\n",
            "article: https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156\n",
            "Splits: [Document(page_content='IT World Canada fights for survival | IT World Canada News\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\nLinkedin\\n\\n\\n\\n\\n\\nTwitter\\n\\n\\n\\n\\n\\nYoutube\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\nTech News\\nCIO\\nResources\\n\\nTechnology Jobs\\nReports and Whitepapers\\nNews for CIOs\\nCIO Census\\nDigital Security Zone\\nWebinar Highlight Reports\\nRoundtable Highlight Reports\\n2023 IT Salary Calculator\\nAI Directory\\nITWC Talks\\nFeatured Partner Content Hubs\\nDigital Magazines\\nSenior Contributors\\n\\n\\nEvents\\n\\nPAST EVENTS\\n\\nTechnicity GTA\\nCIO OF THE YEAR\\nCDN Channel Innovation Awards\\nDigital Transformation Conference and Awards\\nCanada’s Top Women in Cybersecurity\\nCDN Top Women in the Channel\\nMapleSEC\\nAnalytics Unleashed\\n\\n\\nAll IT World Canada Events\\n\\n\\nVideos\\n\\nPresident to President\\nAll Tech Videos\\n\\n\\nPodcasts\\n\\nCyber Security Today\\nHashtag Trending\\nLeadership in the Digital Enterprise\\nCMO Talks\\nAll Hands on Tech Video Podcast Series\\nDeeper Dive\\nITWC Podcast Network\\n\\n\\nEngage', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='Podcasts\\n\\nCyber Security Today\\nHashtag Trending\\nLeadership in the Digital Enterprise\\nCMO Talks\\nAll Hands on Tech Video Podcast Series\\nDeeper Dive\\nITWC Podcast Network\\n\\n\\nEngage\\n\\nContributor Opportunities\\nGartner Corner\\nAbout Us\\nPrivacy Policy\\nContact Us\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nNewsPaper \\n\\n\\n \\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFacebookLinkedinTwitterYoutube\\n\\n\\n\\nDXAwards\\nCIO of The Year\\nLeadership\\nNews for CIOs\\nAnalytics Unleashed\\nTechnicity\\nEmerging Tech\\n\\n\\n\\n\\nIT World Canada \\n\\n\\nTech News\\n\\n\\n\\n\\n\\n\\nPOPULAR CATEGORIESEmerging Tech24485Security8721Infrastructure8593Government & Public Sector6289IoT6187\\n\\nContent TypesVideos\\xa0PodcastsBlogsSlideshows', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content=\"IT World Canada \\n\\n\\nTech News\\n\\n\\n\\n\\n\\n\\nPOPULAR CATEGORIESEmerging Tech24485Security8721Infrastructure8593Government & Public Sector6289IoT6187\\n\\nContent TypesVideos\\xa0PodcastsBlogsSlideshows\\n\\n\\n\\nALL CATEGORIESArtificial Intelligence\\xa0(1495)Blockchain\\xa0(182)CanadianCIO\\xa0(107)Careers & Education\\xa0(4484)Cloud\\xa0(2213)Communications & Telecom\\xa0(571)Companies\\xa0(1424)Data & Analytics\\xa0(1387)Development\\xa0(907)Digital Transformation\\xa0(1347)Distribution\\xa0(128)Emerging Tech\\xa0(24485)Financial\\xa0(195)FinTech\\xa0(115)Future of Work\\xa0(414)Governance\\xa0(145)Government & Public Sector\\xa0(6289)Human Resources\\xa0(926)Infrastructure\\xa0(8593)IoT\\xa0(6187)ITWC Morning Briefing\\xa0(179)Leadership\\xa0(4359)Legal\\xa0(231)Legislation\\xa0(252)Managed Services & Outsourcing\\xa0(4340)Mobility\\xa0(3443)Operations\\xa0(120)People\\xa0(198)Podcasts\\xa0(2560)Privacy\\xa0(808)Project Management\\xa0(1104)Security\\xa0(8721)Social Networks\\xa0(275)Software\\xa0(4228)Supply Chain\\xa0(131)Sustainability\\xa0(171)Wendy's\\xa0(0)Women in Tech\\xa0(209)\\n\\n\\n\\nCIO\\nResources\", metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='CIO\\nResources\\n\\nTechnology Jobs\\nReports and Whitepapers\\nNews for CIOs\\nCIO Census\\nDigital Security Zone\\nWebinar Highlight Reports\\nRoundtable Highlight Reports\\n2023 IT Salary Calculator\\nAI Directory\\nITWC Talks\\nFeatured Partner Content Hubs\\nDigital Magazines\\nSenior Contributors\\n\\n\\nEvents\\n\\nPAST EVENTS\\n\\nTechnicity GTA\\nCIO OF THE YEAR\\nCDN Channel Innovation Awards\\nDigital Transformation Conference and Awards\\nCanada’s Top Women in Cybersecurity\\nCDN Top Women in the Channel\\nMapleSEC\\nAnalytics Unleashed\\n\\n\\nAll IT World Canada Events\\n\\n\\nVideos\\n\\nPresident to President\\nAll Tech Videos\\n\\n\\nPodcasts\\n\\nCyber Security Today\\nHashtag Trending\\nLeadership in the Digital Enterprise\\nCMO Talks\\nAll Hands on Tech Video Podcast Series\\nDeeper Dive\\nITWC Podcast Network\\n\\n\\nEngage\\n\\nContributor Opportunities\\nGartner Corner\\nAbout Us\\nPrivacy Policy\\nContact Us\\n\\n\\n\\n\\n\\nSUBSCRIBE\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n617\\n0\\n\\n\\nCompanies\\nIT World Canada fights for survival\\n Jim Love\\n\\nMarch 6, 2024 \\n\\n\\n\\n\\n\\nFacebookTwitterLinkedinReddItEmailPrint', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada’s tech story?\\nAfter decades of serving the Canadian tech industry, IT World Canada needs help to survive.\\nAs of midnight tonight, the company is suspending publication for the first time in its more than 40-year history, announcing that unless the company finds an investor in the next few days or weeks, it may have to shut down for good.', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='For more than 40 years, IT World Canada and its publications have told the story of the Canadian tech industry.\\xa0 More than 30 years ago it launched what is now CanadianCIO, to tell the story of the emerging new role of technology as a strategic force in Canadian business. The company was the first major technology publication to go fully digital. It has launched the careers of several top journalists and it is a media partner that supports the efforts of many groups that are serving the Canadian technology industry.\\nWith millions of visits and over 250 thousand subscribers, this iconic company publishes on four daily news sites including ITWorldCanada.com, ITBusiness.ca, ChannelDailyNews.com, and a French language publication in Quebec, DirectionInformatique.com.', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='It also publishes CanadianCIO and a number of other targeted publications and newsletters. It has many hit podcasts, including CybersecurityToday and Hashtag Trending, both of which are consistently in the top 5 per cent of podcasts in North America. Its articles are also syndicated on several other major publishers and association sites in Canada and worldwide.\\nDespite all of these accomplishments, the company continues to struggle for survival. But somehow, stubbornly, it has held on while other publishers have failed.\\xa0\\n“I never even thought that I’d be in the publishing industry,” Jim Love, the remaining owner of IT World Canada reflected, “but I met this incredible person, Fawn Annan, more than a decade ago and she convinced me that somehow two individuals, neither of them with any large amount of capital, could rescue this iconic firm from bankruptcy. And somehow we did.”', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='“And in those 10 years under Fawn Annan’s leadership, we defied all odds and managed to survive. After her death last year, the team and her vision carried on. But it is possible that this time, our luck has run out.”\\n“We still have a strong readership and we’ve evolved new approaches that have gained huge interest,” Love noted, “but without additional investment, we simply cannot ‘thread the needle’ to get through this incredibly tough period.”\\n“How little we need to survive would surprise you,” said Love. “But with one individual as owner of a private company, there are limits to the funds we can raise.”\\nLove also noted the new move from American tech companies to bring their marketing spending back to their U.S. head offices, ignoring the Canadian market.', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='Love also noted the new move from American tech companies to bring their marketing spending back to their U.S. head offices, ignoring the Canadian market. \\xa0\\n“As well, the Canadian government has been of no help at all,” said Love. “Ironically, we are asked to be a media partner for government programs and many organizations that get government funding, but we are routinely neglected in government programs, even those that fund much larger publications.”\\nLast year, Love notes that the company was asked to be a media partner for a large event in Montreal with a budget of close to a million dollars, funded by the federal government. “We didn’t get a cent in support and they even asked us to pay our own expenses in covering this event. Everyone else – the venue, the caterers, the staff – all of them got paid. Not a cent for a publisher. They didn’t even place an ad.”', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='The company is struggling to negotiate with its bank and creditors, but without a surprisingly modest investment, the company simply cannot survive.\\xa0 Love has reached out to potential investors and the company has published this open letter appealing to the government, the tech industry, and other potential sources of investment. Failing that, the company may have to shut down for good.\\n“If that happens,” Love noted, “who will tell the stories of the Canadian technology community? Time and again, the audience we’ve attracted and the awards and accolades we’ve won have proven the need for a strong Canadian voice and those unique stories that our audience wants to hear, not some ‘maple-washed’ version from a large U.S. publisher.”\\nWill that voice be missed? As Love noted. “Ask yourself. Is a U.S. publisher with a page on Canada going to tell the stories we tell? Not likely.”\\xa0\\xa0\\nWill this iconic Canadian voice survive? Stay tuned.', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='Will this iconic Canadian voice survive? Stay tuned.\\nFor more information, you can contact me at [email\\xa0protected] and at least for the next few weeks, I’ll be continuing what is now my personal podcast, Hashtag Trending.', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content=\"TagsToday's NewsTop Story\\n\\n\\n\\n\\nWould you recommend this article?  \\n\\n\\n\\nShare\\nFacebookTwitterLinkedinReddItEmailPrint\\n\\n\\n\\nThanks for taking the time to let us know what you think of this article!\\n  We'd love to hear your opinion about this or any other story you read in our publication.\\n \\n \\nJim Love, Chief Content Officer, IT World Canada\\n\\t  \\n\\n\\nFeatured Download\\nJim LoveI've been in IT and business for over 30 years. I worked my way up, literally from the mail room and I've done every job from mail clerk to CEO. Today I'm CIO and Chief Digital Officer of IT World Canada - Canada's leader in ICT publishing and digital marketing.\\n\\n\\n \\n\\n\\n\\nPrevious articleRingCentral drills down the opportunities for AI to revamp customer interactionsNext articleOpenAI hits back at Elon Musk: Hashtag Trending for March 7, 2024\\n\\n \\n\\n\\nFeatured Articles\\n\\n\\n\\n \\n\\nCybersecurity in 2024: Priorities and challenges for Canadian organizations\\xa0\\nBy Derek Manky\\r\\n\\r\\nAs predictions for 2024 point to the continued expansion...\", metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='Featured Articles\\n\\n\\n\\n \\n\\nCybersecurity in 2024: Priorities and challenges for Canadian organizations\\xa0\\nBy Derek Manky\\r\\n\\r\\nAs predictions for 2024 point to the continued expansion...\\n\\nRead more\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nSurvey shows generative AI is a top priority for Canadian corporate leaders.\\nLeaders are devoting significant budget to generative AI for 2024\\r\\n\\r\\nCanadian corporate...\\n\\nRead more\\n\\n\\n\\n\\n\\n\\nRelated Tech News\\n\\n\\n\\n \\n\\nRingCentral drills down the opportunities for AI to revamp customer interactions\\n\\n\\nAshee Pamma -  March 6, 2024 \\n\\n\\n\\n\\n\\n\\n\\n \\n\\nFab wars: Intel, Tata Group, CG Power all launch foundry plans\\n\\n\\nLynn Greiner -  March 1, 2024 \\n\\n\\n\\n\\n\\n\\n\\n \\n\\nCompetition Bureau obtains court order to further investigation into Google’s ad practices\\n\\n\\nAshee Pamma -  March 1, 2024 \\n\\n\\n\\n\\n\\n\\nTech Jobs\\n\\n \\n\\n\\nSubscribe to our NewsletterOur experienced team of journalists and bloggers bring you engaging in-depth interviews, videos and content targeted to IT professionals and line-of-business executives.\\n\\n\\n\\nSUBSCRIBE', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'}), Document(page_content='SUBSCRIBE\\n\\n\\n\\nTech Companies Hiring Right Now\\n  \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n\\nPopular Stories This Week\\n\\n\\n\\n\\nPodcasts  \\n\\nHashtag Trending Mar.1- HP debacle; Humanoid robots closer to hitting our workplaces; Apple blew $10 billion on the electric car before pulling the plug\\n\\n\\n\\n\\n\\n\\nMobility  \\n\\nReview: OnePlus 12 vs OnePlus 12R – A solid pair of devices\\n\\n\\n\\n\\n\\n\\nPodcasts  \\n\\nCyber Security Today, March 6, 2024 – VMware and Apple rush out security updates, a new ScreenConnect malware is found, and more\\n\\n\\n\\n\\n\\n\\n\\n\\nITWC Network\\nITWC\\nIT Business\\nChannel Daily News\\nDirection Informatique\\nITWC Events\\nITWC Podcasts\\n\\n\\n\\nFollow Us\\n\\n\\nFacebookFacebookLinkedinLinkedinRSSRSSTwitterTwitterYoutubeYoutube\\n\\n\\n\\n\\n©\\n\\n2024 \\n\\nIT World Canada. All Rights Reserved.\\n\\n\\n\\nSUBSCRIBE\\n\\nAbout Us\\nContact Us\\nPrivacy Policy\\nITWC Events', metadata={'source': 'https://www.itworldcanada.com/article/it-world-canada-fights-for-survival/560156', 'title': 'IT World Canada fights for survival | IT World Canada News', 'description': \"Facing an unprecedented crisis, IT World Canada, a beacon of technology journalism, is on the brink of closure. This poses a critical question: Without IT World Canada, who will narrate Canada's tech story? After decades of serving the Canadian tech industry, IT World Canada needs help to survive. As of midnight tonight, the company is\", 'language': 'en-US'})]\n",
            "article: Google Gemini is Over a Year Behind OpenAI\n",
            "article: https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html\n",
            "Splits: [Document(page_content='Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content \\n\\n\\n\\n\\n\\n \\n \\nMenu \\n\\n\\n\\n\\nMenu \\nAbout\\nSuperconductor\\nContact\\nTerms\\nPrivacy\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome » Artificial intelligence » Google Gemini is Over a Year Behind OpenAI\\n\\n\\n\\n\\n \\nGoogle Gemini is Over a Year Behind OpenAI \\nMarch 6, 2024 by Brian Wang \\n\\n\\nGoogle Gemini is inferior to OpenAI GPT-4 in independent testing. GPT-4 was released over a year ago.\\n\\nAnthropic just released Claude 3. It is competitive with OpenAI GPT-4 in independent testing.\\n\\nThere are some testers who are finding Claude has less hallucination and is better at increasing computer coding productivity.\\n\\nHere is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would put it ahead of GPT4. GPT5 should be released in a few months.', metadata={'source': 'https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html', 'title': 'Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com', 'description': 'Here is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would', 'language': 'en-US'}), Document(page_content='Mistral AI is a French company selling artificial intelligence (AI) products. It was founded in April 2023 by previous employees of Meta Platforms and Google DeepMind. The company raised 385 million euros in October 2023 and in December 2023 it was valued at more than $2 billion.', metadata={'source': 'https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html', 'title': 'Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com', 'description': 'Here is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would', 'language': 'en-US'}), Document(page_content='It produces open source large language models, citing the foundational importance of open-source software, and as a response to proprietary models.\\nAs of March 2024, two models have been published and are available as weights. Three more models, Small, Medium and Large, are available via API only. Mistral 7B and Mixtral 8x7B are open but the other models are closed. Mixtral 8x7B is ranked as the best open model as of today.\\nBrian WangBrian Wang is a Futurist Thought Leader and a popular Science blogger with 1 million readers per month. His blog Nextbigfuture.com is ranked #1 Science News Blog. It covers many disruptive technology and trends including Space, Robotics, Artificial Intelligence, Medicine, Anti-aging Biotechnology, and Nanotechnology.', metadata={'source': 'https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html', 'title': 'Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com', 'description': 'Here is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would', 'language': 'en-US'}), Document(page_content='Known for identifying cutting edge technologies, he is currently a Co-Founder of a startup and fundraiser for high potential early-stage companies. He is the Head of Research for Allocations for deep technology investments and an Angel Investor at Space Angels.\\nA frequent speaker at corporations, he has been a TEDx speaker, a Singularity University speaker and guest at numerous interviews for radio and podcasts.\\xa0 He is open to public speaking and advising engagements.', metadata={'source': 'https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html', 'title': 'Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com', 'description': 'Here is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would', 'language': 'en-US'}), Document(page_content='Categories Artificial intelligence, Technology, World Tags anthropic, google, large language models, llm, openai, technology \\nChina’s Overall Hybrid and Battery Electric Car Sales Weak in Q1Zama Raises $73M in Series A Lead by Multicoin Capital and Protocol Labs to Commercialize Fully Homomorphic Encryption \\n\\n\\n\\n\\n\\n2 thoughts on “Google Gemini is Over a Year Behind OpenAI”\\n\\n\\n\\n\\n \\n\\nBrett Bellmore \\n\\n \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tMarch 7, 2024 at 5:15 am', metadata={'source': 'https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html', 'title': 'Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com', 'description': 'Here is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would', 'language': 'en-US'}), Document(page_content='2 thoughts on “Google Gemini is Over a Year Behind OpenAI”\\n\\n\\n\\n\\n \\n\\nBrett Bellmore \\n\\n \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tMarch 7, 2024 at 5:15 am\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n \\n\\n\\n\\nZvi Mowshowitz’s review on Substack is pretty positive, but Claude does still have some significant bias issues yet. Nothing as gross as Gemini, but clear bias in favor of racial/ethnic/sexual minorities and left-wing politics.\\nSupposedly despite an internal prompt reminding it not to be biased… Perhaps it’s training resulted in a warped notion of what “bias” means. I could see that happening.\\nThe other issue is, of course, refusals. Despite that internal prompt explicitly directing it to not refuse requests that embody views held by significant numbers of people, Claude is still much more likely to refuse tasks premised on ‘right wing’ views.\\nAvi is rather concerned about the whole notion of ‘harm’ based refusals being way too broad. So am I.\\nReply \\n\\n\\n\\n\\n\\n \\n\\nethan \\n\\n \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tMarch 6, 2024 at 5:12 pm', metadata={'source': 'https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html', 'title': 'Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com', 'description': 'Here is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would', 'language': 'en-US'}), Document(page_content='ethan \\n\\n \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tMarch 6, 2024 at 5:12 pm\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n \\n\\n\\n\\nYou got that correct, the more capable a model is the harder it is to general public proof it. GPT 4.5 could be a useful stop gap for open ai.\\nReply \\n\\n\\n\\n\\nLeave a Comment Cancel replyCommentName\\nEmail\\nWebsite\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCategoriesCategories\\nSelect Category\\nAntiaging\\nArtificial intelligence\\nAugmented reality\\nBlockchain\\nCryptocurrency\\nDrones\\nEcommerce\\nEnergy\\nFintech\\nGadgets\\nHumanoid Robot\\nIco\\nInterviews\\nMedicine\\nMilitary\\nNews\\npress release\\nQuantum computers\\nRobotics\\nScience\\nSpace\\nSponsored\\nSuperconductor\\nTechnology\\nUncategorized\\nVirtual reality\\nWorld\\n\\n\\n\\n\\n\\n\\n\\nRecent Posts\\n\\n\\nRivian’s New Smaller R2, R3 and R3X Electric Trucks for 2026\\n\\n\\n20 Megawatt Nuclear Reactors That Can Fit In a Truck\\n\\n\\nTesla FSD Car Data Infrastructure is Years Ahead\\n\\n\\nThe Cases For and Against LK99-Type Room Temperature Superconductors', metadata={'source': 'https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html', 'title': 'Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com', 'description': 'Here is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would', 'language': 'en-US'}), Document(page_content='20 Megawatt Nuclear Reactors That Can Fit In a Truck\\n\\n\\nTesla FSD Car Data Infrastructure is Years Ahead\\n\\n\\nThe Cases For and Against LK99-Type Room Temperature Superconductors\\n\\n\\nBadge Launches Partner Program to Expand Availability of its Privacy-Enhancing “Enroll Once and Authenticate on Any Device” Software\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t© 2024 Next Big Future', metadata={'source': 'https://www.nextbigfuture.com/2024/03/google-gemini-is-over-a-year-behind-openai.html', 'title': 'Google Gemini is Over a Year Behind OpenAI | NextBigFuture.com', 'description': 'Here is the huggingface area leaderboard for AI chatbots. Claude 3 is not yet ranked but the claim is that it is 200 points better than Claude 2. This would', 'language': 'en-US'})]\n",
            "article: Ghana's LGBT terror: 'We live in fear of snitches'\n",
            "article: https://www.bbc.co.uk/news/world-africa-68490872\n",
            "Splits: [Document(page_content=\"Ghana's LGBT terror: 'We live in fear of snitches' - BBC NewsBBC HomepageSkip to contentAccessibility HelpYour accountHomeNewsSportEarthReelWorklifeTravelMore menuMore menuSearch BBCHomeNewsSportEarthReelWorklifeTravelCultureFutureMusicTVWeatherSoundsClose menuBBC NewsMenuHomeIsrael-Gaza warWar in UkraineClimateVideoWorldUKBusinessTechScienceMoreEntertainment & ArtsHealthWorld News TVIn PicturesBBC VerifyNewsbeatWorldAfricaAsiaAustraliaEuropeLatin AmericaMiddle EastUS & CanadaGhana's LGBT terror: 'We live in fear of snitches'Published1 day agoShareclose panelShare pageCopy linkAbout sharingImage source, Sulley Lansah/BBCBy Favour Nunoo & Thomas NaadiBBC News, AccraHomophobia is not uncommon in Ghana, where gay sex is already against the law and carries a three-year prison sentence, but now the LGBTQ+ community is feeling terrorised.A new bill, passed by MPs last week, will impose a jail term of up to three years for simply identifying as LGBTQ+ and five years for promoting their\", metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content='now the LGBTQ+ community is feeling terrorised.A new bill, passed by MPs last week, will impose a jail term of up to three years for simply identifying as LGBTQ+ and five years for promoting their activities.\"A relative told me if this bill is passed, any chance he gets, he is going to poison me because I am an abomination to the family,\" Mensah, whose name has been changed to protect his identity, tells the BBC.Dressed in an all-black outfit, the young man in his late teens looks visibly terrified: \"I am very worried anyone can snitch on me, even in my own neighbourhood. It\\'s going to be very hard to live here.\"He has been living for some time with sympathetic friends in Ghana\\'s capital, Accra, since falling out with his family.It is not clear how large the LGBTQ+ community is in Ghana, a religious and traditionally conservative nation, but they tend to help each other out when one of them faces life as an outcast.Mensah says when his mother discovered several years ago that he was', metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content='a religious and traditionally conservative nation, but they tend to help each other out when one of them faces life as an outcast.Mensah says when his mother discovered several years ago that he was attracted to boys, she started taking him to churches for prayers with the hope he would change.\"No friends except my church friends were allowed to see me. I had to study the Bible 24/7, pray and I would sit at the back anytime we went for meetings.\" He says he was practically shunned at home - the wider family would not talk to him and he found their stares unbearable.\"They felt I would have influence on my cousins and the little ones.\"Then in 2020, when the prayers and Bible studies were deemed to have failed, Mensah was excommunicated from his church for being gay.His family were furious - and essentially outed him to their wider circle in an attempt to shame him. \"My family told a lot of my friends that this is who I am, I lost some good opportunities to further my education,\" he', metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content='- and essentially outed him to their wider circle in an attempt to shame him. \"My family told a lot of my friends that this is who I am, I lost some good opportunities to further my education,\" he says.\"It is very uncomfortable and very sad - these are people I grew up with, and now they don\\'t see the good in me, but they see me as an abomination.\"Mensah was eventually kicked out of the family home - and struggles to hold down a job.Now the softly spoken young man says he spends most of his time indoors to avoid offending people\\'s sensibilities. He wants to be less visible, less seen, less heard.Image source, ReutersImage caption, LGBT people are commonly referred to in the local Akan language as \"kojo besia\", meaning \"man-woman\"Mensah\\'s experiences are not uncommon.LGBT people are commonly referred to in the local Akan language as \"kojo besia\", literally \"man-woman\". They have always co-existed within Ghanaian communities, although there were occasional attacks.These have become more', metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content='referred to in the local Akan language as \"kojo besia\", literally \"man-woman\". They have always co-existed within Ghanaian communities, although there were occasional attacks.These have become more common in recent years.Kwame, who also requested his name be changed for his safety, is horrified by the passage of the anti-gay bill, saying it will legitimise homophobic attacks, something he has experienced himself.\"I am known to be gay where I live, so anybody that comes close to me - they feel like that person is also gay,\" he tells the BBC about an attack he suffered about 10 years ago.A male friend had visited and when stepping outside to wave him goodbye, some residents ganged up on them.\"They approached us, saying that we are gay and started attacking us. It wasn\\'t just one person, and they took our phones,\" he says.Kwame made an official report to the police, however after weeks of no action he had to live with the reality that he would get no justice.Now his mere existence - if', metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content='they took our phones,\" he says.Kwame made an official report to the police, however after weeks of no action he had to live with the reality that he would get no justice.Now his mere existence - if the bill is signed by the president - will be against the law.In his late twenties, Kwame is studying fashion design - but has also faced discrimination in the workplace when someone told his boss about his sexuality.His boss asked him to change his ways and then fired him when he refused. \"I lost my job because I was gay.\"Image source, Sulley Lansah/BBCImage caption, Kwame, like Mensah, is considering leaving the country because he feels it is getting more dangerous for the LGBTQ+ communityBoth Kwame and Mensah are hoping the bill, which has been backed by both of Ghana\\'s two main political parties, will be stopped by a legal challenge.A case has been filed at the Supreme Court and President Nana Akufo-Addo says he will wait for the outcome before taking action on the bill.He has been at', metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content=\"will be stopped by a legal challenge.A case has been filed at the Supreme Court and President Nana Akufo-Addo says he will wait for the outcome before taking action on the bill.He has been at pains to assure the diplomatic community that Ghana is committed to upholding human rights.The country's finance ministry is worried about the possible repercussions, saying Ghana could lose a total of $3.8bn (£3bn) in World Bank funding over the next five to six years.Ghana is suffering a major economic crisis and last year had a bailout from the International Monetary Fund (IMF).The US, UK and human rights groups have condemned the bill, with the US in particular indicating that it would have a chilling effect on foreign investment to Ghana.The West African nation is part of the trade agreement between Africa and the US - the African Growth and Opportunity Act (Agoa). Uganda was chucked out of the deal by the US after it passed a controversial anti-homosexuality law last year.Kwame and Mensah\", metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content='Africa and the US - the African Growth and Opportunity Act (Agoa). Uganda was chucked out of the deal by the US after it passed a controversial anti-homosexuality law last year.Kwame and Mensah are considering leaving Ghana as the situation has been so inflamed by politicians - the country feels like a more dangerous place for them.\"Where I am living is a very crowded area, so when your issue comes up everyone gets to find out, I\\'m actually scared. I will have to leave and go settle somewhere else,\" he says.Mensah agrees: \"I feel like relocating from the country itself to any country which is safe for me to live in.\"I have to count my steps to make sure I don\\'t offend anyone. I have to live like a refugee in my own country.\"You may also be interested in:Why Ghana’s LGBT community is ‘under attack’Will $3bn IMF loan solve Ghana\\'s economic crisis?Power cut to Ghana’s parliament over $1.8m debtTime to understand homosexuality - Ghana cardinalWhy are different African countries passing', metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content=\"attack’Will $3bn IMF loan solve Ghana's economic crisis?Power cut to Ghana’s parliament over $1.8m debtTime to understand homosexuality - Ghana cardinalWhy are different African countries passing anti-LGBT laws?Related TopicsLGBT rights in AfricaGhanaLGBTAround the BBCFocus on Africa podcastsTop StoriesLive.\\xa0Biden hails economic 'comeback' in State of the Union addressUS to set up temporary port on Gaza coast for aid deliveryPublished2 hours agoMH370: The families haunted by one of aviation's greatest mysteriesPublished3 hours agoFeaturesThe Iranian female DJs shaking the dance floorSingapore sting: How Russia listened in on German general'I'm really shy' - The return of Gossip's Beth DittoIndian troops to exit Maldives as China gains footholdWeekly quiz: Which billionaire hired Rihanna to celebrate a wedding?Pride, pilgrims and parades: Africa's top shotsNine extraordinary tattoos from around the world'We know what's coming': East Ukraine braces for Russian advanceNew Blanchett film\", metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content=\"celebrate a wedding?Pride, pilgrims and parades: Africa's top shotsNine extraordinary tattoos from around the world'We know what's coming': East Ukraine braces for Russian advanceNew Blanchett film tackles dark chapter for AustraliaElsewhere on the BBCThe 'golden handcuffs' of high-earning jobsEight of the world's most remarkable homesThe quest to depave the world's citiesMost Read1Media tycoon Rupert Murdoch engaged for sixth time2MH370: The families haunted by one of aviation's greatest mysteries3New Yorkers lukewarm on troop deployment in subway4The far-right former football pundit running for PM5More than 280 pupils abducted by Nigeria gunmen6Sweden formally joins Nato military alliance7US to set up temporary port on Gaza coast for aid delivery8Images show N Korea sealing its border with China9Mother charged over missing South African girl, 610Jury in first Trump criminal trial to be anonymousBBC News ServicesOn your mobileOn smart speakersGet news alertsContact BBC\", metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'}), Document(page_content='its border with China9Mother charged over missing South African girl, 610Jury in first Trump criminal trial to be anonymousBBC News ServicesOn your mobileOn smart speakersGet news alertsContact BBC NewsHomeNewsSportEarthReelWorklifeTravelCultureFutureMusicTVWeatherSoundsTerms of UseAbout the BBCPrivacy PolicyCookiesAccessibility HelpParental GuidanceContact the BBCGet Personalised NewslettersWhy you can trust the BBCAdvertise with us© 2024 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.', metadata={'source': 'https://www.bbc.co.uk/news/world-africa-68490872', 'title': \"Ghana's LGBT terror: 'We live in fear of snitches' - BBC News\", 'description': 'A bill that will impose jail terms for simply identifying as LGBTQ+ is terrifying the gay community.', 'language': 'en-GB'})]\n",
            "article: Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4\n",
            "article: https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/\n",
            "Splits: [Document(page_content='Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDEVELOPER\\n\\n\\n\\nHomeBlogForumsDocsDownloadsTraining\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\nJoin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Related Resources \\n\\n\\n\\n\\n\\n\\n\\n\\nGenerative AI / LLMs\\n\\n\\n\\nEnglish中文\\n\\n\\nTurning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4\\n\\n\\n            Mar 06, 2024\\n          \\n\\n            By Chester Chen, Ziyue Xu, Holger Roth and Mona Flores \\n\\n\\n  \\n\\n                Like              \\n\\n\\n\\n Discuss (0)\\n                \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nL\\nT\\nF\\nR\\nE', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial services, FL, as a privacy-enhanced technology, has become a critical component of the technical stack.\\nIn this post, we discuss FL and its advantages, delving into why federated learning is gaining traction. We also introduce three key features introduced in NVIDIA FLARE 2.4.0 release that facilitate a seamless transition from centralized machine learning to federated learning. These features also enhance large language model (LLM) support through a streaming API and demonstrate various parameter tuning tasks.\\xa0\\nThe latest version of FLARE has expanded FL workflow patterns, providing researchers with more options for workflow customization. We share different use cases in healthcare and banking, financial services, and insurance (BFSI) to show FL applications in production or through examples.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Federated learning in the age of decentralized data\\xa0\\nFL is a machine-learning approach that enables model training and data analysis across decentralized devices while keeping local data private. In contrast to traditional centralized training, FL enables model training locally and only shares model updates rather than raw data. This approach enables collaborative learning without compromising data governance and privacy.\\xa0\\nWhile FL introduces challenges like communication overhead and ensuring model consistency, it offers significant benefits in terms of privacy preservation, efficiency, and security.\\nNVIDIA FLARE (NVIDIA Federated Learning Application Runtime Environment) is an open-source federated learning framework widely adopted across various industrial sectors. It offers diverse examples covering machine learning and deep learning algorithms. FLARE has robust security features, advanced privacy protection techniques, and provides a flexible model-agnostic architecture.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='FLARE offers several advantages across various dimensions, making it a powerful approach in scenarios where data is distributed and privacy is a primary concern.\\xa0\\nWith increased concerns about data privacy regulation and the need for more data to train a better machine learning model, the interest and investments in privacy enhancement technology (PET), including FL and confidential computing, have increased dramatically in recent years.\\xa0\\nHere are some key advantages:', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Privacy preservation\\nData diversity\\nRegulatory compliance\\nSecurity', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Privacy preservation\\nModels are trained locally. In FLARE, only model updates or model differences are shared, while the private data is kept on the client. Aggregation happens securely to protect against information leakage during model updates.\\nData diversity\\nData diversity among clients is critical for robust model development. This diversity, especially including data from rare events, prevents bias and enables the model to learn effectively with FLARE.\\xa0\\nRegulatory compliance\\nIncreasingly, organizations and governments issue regulations to protect data privacy. Examples include the European Union’s General Data Privacy Regulation (GDPR) and China’s Personal Information Protection Law (PIPL). These regulations restrict data transfers from one region to another.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='In addition, there are also industry-specific laws and regulations, such as HIPAA (Health Insurance Portability and Accountability Act) for healthcare, that avoid revealing users’ personal data. As FLARE brings the computation to the data without moving data, it becomes the key to enable AI initiatives to avoid violating these regulations.\\nSecurity\\nFLARE offers decentralized security enforcement. Local institutions (banks, hospitals, and so on) can elect to add additional organization-specific security checks or policies\\xa0\\nFederated learning made easy with NVIDIA FLARE\\nHow to quickly leverage FL and build multi-modal foundation models with LLM has become a hot topic in many governments, financial institutions, healthcare, and drug-discovery industries.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='How to quickly leverage FL and build multi-modal foundation models with LLM has become a hot topic in many governments, financial institutions, healthcare, and drug-discovery industries.\\xa0\\nIn the FLARE 2.4.0 release, we introduce new features that make developing FL super easy, including a client API. With a few lines of code changes, you can easily transform pre-existing, centralized deep-learning code into FL code, in minutes instead of days.\\xa0\\xa0\\nThe following code example shows a common pattern when using the client API for a client trainer:', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='# import nvflare client API\\nimport nvflare.client as flare\\n# initialize NVFlare client API\\nflare.init()\\n# run continuously when launching once\\nwhile flare.is_running():\\n\\n\\n  # receive FLModel from NVFlare\\n  input_model = flare.receive()\\n  # loads model from NVFlare\\n  net.load_state_dict(input_model.params)\\n  # perform local training and evaluation on received model\\n  {existing centralized deep learning code} ...\\n  # construct output FLModel\\n  output_model = flare.FLModel(\\n      params=net.cpu().state_dict(),\\n      metrics={\"accuracy\": accuracy},\\n      meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\\n  )\\n  # send model back to NVFlare\\n  flare.send(output_model)\\n\\nThe key to understanding these easy-to-use APIs is that almost all FL algorithms essentially involve the following steps:', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='The key to understanding these easy-to-use APIs is that almost all FL algorithms essentially involve the following steps:\\xa0\\n\\nReceive the global model from the aggregator or a peer client.\\n(Optional) Evaluate the model.\\nUpdate the local model, and perform local model training with many epochs.\\xa0\\nSend the newly updated local model back to the aggregator or other peer clients.\\n\\nThe FLARE client API easily implements these actions:\\n\\nflare.init: Initialization.\\nflare.receive: Receive the model.\\nflare.send: Send the model back.\\nflare.is_running:\\xa0 Check whether the overall training is finished.\\n\\nWith these APIs, you don’t have to restructure the existing code or write new classes. The code conversion can be done in minutes by inserting the API commands in the relevant sections of your existing code.\\xa0\\nFor PyTorch Lightning, the change is even simpler. Apply a patch to the trainer instances:', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='flare.patch(trainer): Adds callbacks to the trainer to perform the flare.receive and flare.send functions.\\xa0\\n\\nThe model can be captured in the data structure, FLModel.\\xa0\\n\\nclass FLModel:\\n    def __init__(\\n        self,\\n        params_type: Union[None, str, ParamsType] = None,\\n        params: Any = None,\\n        optimizer_params: Any = None,\\n        metrics: Optional[Dict] = None,\\n        start_round: Optional[int] = 0, \\n        current_round: Optional[int] = None,\\n        total_rounds: Optional[int] = None,\\n        meta: Optional[Dict] = None,\\n    ):\\n\\nThe data structure is carefully designed and general purpose. It does not introduce any FLARE-specific concepts or structures but only contains concepts that data scientists already know:\\xa0\\n\\nparams: Weight parameters\\noptimizer_params: Optimizer parameters\\nmeta: Metadata.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='This new client API, simplifying the transition to FL, is a game changer for end users.\\xa0\\nFor more information about the client API and its use, see the ML to FL examples and read the client API documentation. For more examples, see the step-by-step series that uses client API to write the train script.\\nFederated learning in the age of LLMs\\nThe defining feature of LLMs is their sheer size, often comprising billions of parameters. Federated learning requires that users to transmit their local model parameters to a model aggregator, potentially situated in a different region or country, to construct a global model. Efficiently transferring such a massive model over a network demands a robust framework. To address this challenge, FLARE has developed a stream API tailored for such tasks.\\nStreaming API', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Streaming API\\nLLMs can be large in size. For example, a 7B-parameter model can be approximately 14 GB. To transfer such large objects over the network, you must overcome some limitations imposed by different communication protocols.\\xa0\\nTo support LLMs, the FLARE 2.4.0 release introduces the streaming API to facilitate the transfer of objects exceeding the 2-GB size limit imposed by gRPC. The addition of a new streaming layer designed to handle large objects enables you to divide the large model into 1M chunks and stream them to the target.\\xa0\\nWith this streaming API, you can transfer models of varying sizes across regions (such as US to India) and diverse cloud providers (such as Azure to AWS). We used a 128-GB object to perform a load test.\\xa0\\nFor more information, see nvflare.fuel.f3.stream_cell module and Large Models.\\nFederated LLM parameter tuning', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='For more information, see nvflare.fuel.f3.stream_cell module and Large Models.\\nFederated LLM parameter tuning\\nThe FLARE 2.4.0 release showcases several LLM examples using NVIDIA NeMo, demonstrating how to perform prompt-tuning, supervised fine-tuning, and parameter-efficient fine-tuning in a federated setting.\\xa0\\nPrompt-tuning\\nPrompt tuning is a technique used in training language models, particularly in fine-tuning them for specific tasks or domains. Instead of training the entire model from scratch, prompt tuning focuses on adjusting the prompts or instructions given to the model during inference or generation.\\nFederated prompt-tuning enables users to conduct prompt-tuning of the model on a local level and then aggregate the parameters globally.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Federated prompt-tuning enables users to conduct prompt-tuning of the model on a local level and then aggregate the parameters globally.\\nIn this example, we used the NeMo prompt learning feature to showcase how to adapt an LLM to a downstream task, such as financial sentiment predictions. The prompt learning technique shown in the example is p-tuning, which adds a small prompt encoder network to the LLM to produce virtual tokens that guide the model toward the desired output of the downstream task.\\nFor more information, see Prompt Learning with NeMo.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Figure 1. P-tuning for LLM adaption\\nFigure 1 shows how the p-tuning works for adaptation of\\xa0 LLMs. It involves freezing the LLM and learning to predict virtual token embeddings that are combined with the original input text.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Figure 2. P-tuning for LLMs in a federated learning environment\\nFigure 2 shows how p-tuning works with LLM in a federated learning setting. LLM parameters stay fixed but prompt encoder parameters are trained, updated, and aggregated on the FLARE server.\\xa0\\nIn this example, we used the NeMo prompt learning feature to showcase how to adapt an LLM to a downstream task, such as financial sentiment predictions. The prompt learning technique shown in the example is p-tuning, which adds a small prompt encoder network to the LLM to produce virtual tokens that guide the model toward the desired output of the downstream task.\\xa0\\nIn our federated implementation, we used a 20B-parameter model. While the LLM parameters stay fixed, the prompt encoder parameters are trained, updated, and averaged on the FL server.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Figure 3. Validation losses of the global and locally trained models\\nSupervised fine-tuning\\nWe also used the NeMo supervised fine-tuning (SFT) feature to showcase how to fine-tune the whole model on supervised data to learn how to follow user-specified instructions. For more information, see Supervised Fine-Tuning.\\nThe example for a three-client 1.3B GPT model experiment can be performed on either three 32 -GB NVIDIA V100 GPUs or one 80-GB NVIDIA A100 GPU.\\xa0\\nDue to the large model size of the LLM, we use the FLARE streaming feature to transfer the model in chunks.\\nParameter-efficient fine-tuning\\nParameter-efficient fine-tuning (PEFT) is a popular technique used to efficiently fine-tune LLMs for use in various downstream tasks.\\xa0\\nWhen fine-tuning with PEFT, the base model weights are frozen, and a few trainable adapter modules are injected into the model, resulting in a small number (typically << 1%) of trainable weights.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='When fine-tuning with PEFT, the base model weights are frozen, and a few trainable adapter modules are injected into the model, resulting in a small number (typically << 1%) of trainable weights.\\xa0\\nWith carefully chosen adapter modules and injection points, PEFT achieves comparable performance to full finetuning at a fraction of the computational and storage costs. We used NeMo PEFT methods to showcase how to adapt an LLM to a downstream task, such as financial sentiment predictions.\\nFor more information, see Parameter-Efficient Fine-Tuning (PEFT) with NeMo.\\nSFT and PEFT\\nWe also demonstrated both SFT and PEFT using the SFT Trainer from HuggingFace and the PEFT library. For more information, see Federated LLM SFT and PEFT with Hugging Face.\\nOur experiments showcasing the functionality of federated SFT and PEFT are based on the Llama-2-7b-hf model, enabling HuggingFace models to be trained and adapted with FLARE.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Our experiments showcasing the functionality of federated SFT and PEFT are based on the Llama-2-7b-hf model, enabling HuggingFace models to be trained and adapted with FLARE.\\xa0\\nIn this example, the model transmission size over the FLARE network is ~27 GB for SFT and ~134 MB for PEFT. The larger model is automatically streamed without having to call the streaming API manually.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Figure 4. PEFT curves for three-epoch centralized training and three-round (one epoch/round) federated learning with one client (red for centralized results, blue for FL training, green for FL training with a fixed global model)\\nTo ensure the correct behavior of FLARE integrating with HuggingFace’s trainer, we performed single-client experiments under three settings (Figure 4):\\xa0\\n\\nLocal training for three epochs (red)\\xa0\\nUsing FLARE for three federation rounds with one epoch per round (blue)\\nUsing FLARE for three federation rounds but with a fixed global model sent back every round (green)', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='As expected, with some training randomness, the two PEFT training loss curves align with each other.\\xa0\\nAs the HuggingFace trainer keeps track of training status of the model, we wanted to make sure that the global model from the server was loaded correctly, rather than re-using the local record). As shown, the correct fixed global model is loaded correctly. The training starts from the same point every round, showing the expected federated learning behavior.\\nExpanding federated learning workflow patterns\\nSome researchers prefer alternative workflow patterns to the FL workflow described earlier. For example, swarm learning is considered a decentralized peer-to-peer collaboration learning pattern alternative to FL. Similarly, split learning and gossip learning are alternative communication patterns to FL.\\xa0\\nAmong other things, here are some key difference between these alternative communication patterns:\\n\\nAn emphasis on decentralized and peer-to-peer communication.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='An emphasis on decentralized and peer-to-peer communication.\\n\\nNo static server for model aggregation.\\xa0\\nClient communication is peer-to-peer communication.\\n\\n\\nAlgorithm workflows differ:\\n\\nAggregator selection\\nClient sampling and distribution (gossip protocol compared to broadcast-to-all)\\xa0\\n\\n\\n\\nWhen you look closer, “no central server” really means “no static aggregator node”.\\xa0 In most cases, the aggregator node is located at the FL server node.\\xa0\\nIn many FL frameworks, the server services two functions:\\n\\nManaging the job lifecycle (health of client sites, monitoring of job status).\\nServing as an aggregator that participates in the training process (task assignment, model initialization, aggregation, and obtaining the distributed final model).', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='By separating these two functions in FLARE and enabling direct peer-to-peer communication, the workflow patterns can support both swarm learning and gossip learning.\\xa0\\nThe aggregator function doesn’t have\\xa0 to be located in the FL server. You can put it into any client node. This essentially decentralizes the aggregation. You only need the FL server for job lifecycle management.\\xa0\\nIn the 2.4.0 release, we introduced client-controlled workflows to enable such capability.\\xa0\\nSecure messaging\\nPeer-to-peer clients exchange messages using TLS encryption where the sender uses the public key of the receiver from certificates received, and encrypts messages with AES256 key. Only the sender and client can view the message.\\xa0\\nIn the case where there is no direct connection between clients and the message is routed via the server, the server is unable to decrypt the message.\\nThe following commonly used types of client-side controlled workflows are provided:', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Cyclic learning: Passes the model from client to client.\\nSwarm learning: Randomly selects clients as client-side aggregators.\\nCross-site evaluation: Enables clients to evaluate other sites’ models.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Figure 5.\\xa0 Swarm learning with FLARE\\nIn Figure 5, the FL server triggers the start of the training job, while monitoring the overall job lifecycle. The communication is peer-to-peer among different clients without the FL server’s involvement.\\xa0\\nSome would like to use the blockchain network as the communication layer for swarm learning, but this is not a\\xa0requirement of swarm learning. The key is to make sure the aggregator is unable to decipher the message if the message is routed through the FL server.\\xa0\\nFederated earning is transforming multiple industry sectors\\nFL has been adopted at an accelerated speed, transforming multiple industry sectors, such as healthcare and BFSI.\\xa0\\nHealthcare\\xa0\\nIn healthcare, FL is used for medical image analysis, predicting clinical outcomes,\\xa0 and many other applications.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Healthcare\\xa0\\nIn healthcare, FL is used for medical image analysis, predicting clinical outcomes,\\xa0 and many other applications.\\xa0\\xa0\\nThe FLIP project from the UK AI Centre for Value Based Healthcare, led by King’s College London, is powered by FLARE. FLIP is being deployed in at least five NHS trusts serving over 10M patients in early 2023. The first projects using FLIP include research into AI that can diagnose strokes from head CT scans, an algorithm that can help radiologists detect and diagnose prostate cancer and software that uses AI to reduce the time of cardiac MRI scans.\\xa0\\nRhino Health, a federated computing company, is powered by FLARE to enable the transformative power of federated computing. For more information, see Federated Learning for Healthcare AI: NVIDIA and Rhino Health Accelerate Research Collaborations (video).', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Roche is a leading pharmaceutical and diagnostics company with a focus on advancing medical science to improve people’s lives.\\xa0 It realizes the power of FL and has been adopting and working with NVIDIA to improve all aspects of FL. For more information, see Preventing Health Data Leaks with Federated Learning Using NVIDIA FLARE.\\nSiemens Healthineers is a prominent medical technology company that specializes in providing advanced solutions for medical imaging, laboratory diagnostics, and in-vitro diagnostics. It has developed its federated learning solution using FLARE and Azure ML.\\nBanking, financial services, and insurance\\nWith each country and region developing new AI strategies, FL becomes a necessity.', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Banking, financial services, and insurance\\nWith each country and region developing new AI strategies, FL becomes a necessity.\\xa0\\nA pivotal application within BFSI involves fraud detection. The model, collectively built, based on the insights derived from varied customer profiles and credit histories across different banks or institutions, all without necessitating the exchange of raw data. This challenge is particularly pronounced for institutions with internal business practices bound by stringent privacy laws or regulations.\\nBased on the recently published State of AI in Financial Services: 2024 Trends, fraud detection is among the top AI use cases in the investing sector and one of the top security challenges in financial service organizations (Figure 6).', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='a) AI use cases for investment\\nb) Cybersecurity challenges for AI\\nFigure 6.\\xa0 Fraud detection survey responses\\nFraud detection stands as one of the paramount applications in financial services. With an overwhelming expectation (51%) that AI technology can effectively combat fraud, the integration of FL with zero-trust confidential computing emerges as a critical approach to addressing these challenges and delivering robust solutions.\\nIn NVFlare 2.4.0, we’ve developed several examples showcasing the use of FL:\\n\\nFraud detection using XGBoost with Kaggle’s Credit Card Fraud Detection dataset\\nFinancial transaction classification employing Graph Neural Networks (GNN)\\n\\nSummary\\nFL is experiencing rapid growth. FLARE has developed a suite of features to help companies adopt this new technology. You can find a lot more features than we had room to discuss in this post.\\xa0\\nThe new FLARE features, in addition to those mentioned earlier:', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Experiment tracking support for MLFlow and Weights & Biases\\nSecure enhancements to enable site-specific customized authentication and authorization\\nMulti-format configuration\\xa0\\nThird-party integration patterns\\nJob CLI and job templates\\nPOC command upgrade\\nStep-by-step series examples\\xa0\\n\\nNVIDIA has made it a lot easier to convert your existing ML/DL to FL, supercharge LLM training, and expand the workflow patterns.\\xa0\\nFor more information, see the following resources:\\n\\nNVIDIA FLARE documentation\\xa0\\nNVIDIA FLARE: Federated Learning from Simulation to Real-World\\nEmpowering Federated Learning for Massive Models with NVIDIA FLARE', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='NVIDIA FLARE documentation\\xa0\\nNVIDIA FLARE: Federated Learning from Simulation to Real-World\\nEmpowering Federated Learning for Massive Models with NVIDIA FLARE\\n\\n\\n\\nRelated resources\\nGTC session: Training Deep Learning Models at Scale: How NCCL Enables Best Performance on AI Data Center NetworksGTC session: Decentralized Collaborative AI With Federated Learning in Trustworthy EnvironmentsGTC session: How to Seamlessly Scale from Open Source to Production-Ready Generative AISDK: NVFLareSDK: NCCLWebinar: Accelerate AI Model Inference at Scale for Financial Services\\n\\n\\n\\n\\n Discuss (0)\\n        \\n\\n\\n  \\n\\n      Like    \\n\\n\\n\\n\\nTags\\n\\n\\nConversational AI | Generative AI / LLMs | Networking | General | FLARE | NeMo | Intermediate Technical | Deep dive | featured | Federated Learning | LLMs \\n\\n\\n\\n\\n\\n                About the Authors\\n          \\n\\n\\n\\n\\n\\n\\n\\n                  About Chester Chen', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='About the Authors\\n          \\n\\n\\n\\n\\n\\n\\n\\n                  About Chester Chen\\n                \\n\\n                \\n                          Chester Chen is a senior manager on the federated learning engineering team at NVIDIA. He has over 20 years of experience in building and managing different types of systems and operations. Before NVIDIA, he spent six years as the director of data science engineering at GoPro, where he was in charge of data lake infrastructure, data engineering, data analytics, and machine learning applications. Before GoPro, he played many different roles, including director of engineering, technical director, and system architect, at many different big companies and small startups in Silicon Valley.\\n            \\n                                                    \\n                          \\n\\n                                            View all posts by Chester Chen\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  About Ziyue Xu', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='View all posts by Chester Chen\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  About Ziyue Xu\\n                \\n\\n                \\n                          Ziyue Xu is a senior scientist at NVIDIA. His research interests are in the area of image analysis and computer vision with applications in biomedical and clinical imaging. He has been working on medical AI since 2007 along with fellow researchers and clinicians. Ziyue received his B.S. from Tsinghua University in 2006, and M.S./Ph.D. from the University of Iowa in 2009/2012. He is an IEEE Senior Member and Associate Editor for the journals IEEE Transactions on Medical Imaging (TMI), Journal of Biomedical and Health Informatics (JBHI), Computerized Medical Imaging and Graphics (CMIG), and Computers in Biology and Medicine (CBM).\\n            \\n                                                    \\n                          \\n\\n                                            View all posts by Ziyue Xu', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='View all posts by Ziyue Xu\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  About Holger Roth\\n                \\n\\n                \\n                          Holger Roth is a principal applied research scientist at NVIDIA focusing on deep learning for medical imaging. He has been working closely with clinicians and academics over the past several years to develop deep learning based medical image computing and computer-aided detection models for radiological applications. He holds a Ph.D. from University College London, UK.\\n            \\n                                                    \\n                          \\n\\n                                            View all posts by Holger Roth\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  About Mona Flores', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content=\"View all posts by Holger Roth\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                  About Mona Flores\\n                \\n\\n                \\n                          Mona G. Flores, MD, is the global head of Medical AI at NVIDIA. She brings a unique perspective with her varied experience in clinical medicine, medical applications and business. She's a board-certified cardiac surgeon and the previous chief medical officer of a digital health company. She holds an MBA in management information systems and has worked on Wall Street. Her ultimate goal is the betterment of medicine through AI.\\n            \\n                                                    \\n                          \\n\\n                                            View all posts by Mona Flores\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated posts\\n\\n\\n\\n\\n\\n\\n\\n\\n          Scalable Federated Learning with NVIDIA FLARE for Enhanced LLM Performance\", metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='Comments\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated posts\\n\\n\\n\\n\\n\\n\\n\\n\\n          Scalable Federated Learning with NVIDIA FLARE for Enhanced LLM Performance\\n        \\n\\n\\n\\nScalable Federated Learning with NVIDIA FLARE for Enhanced LLM Performance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Using Federated Learning to Bridge Data Silos in Financial Services\\n        \\n\\n\\n\\nUsing Federated Learning to Bridge Data Silos in Financial Services\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Transforming AI Healthcare with Federated Learning\\n        \\n\\n\\n\\nTransforming AI Healthcare with Federated Learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Federated Learning powered by NVIDIA Clara\\n        \\n\\n\\n\\nFederated Learning powered by NVIDIA Clara\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          NVIDIA and King’s College London Debut First Privacy-Preserving Federated Learning System for Medical Imaging\\n        \\n\\n\\n\\nNVIDIA and King’s College London Debut First Privacy-Preserving Federated Learning System for Medical Imaging\\n\\n\\n\\n\\n\\nRelated posts', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'}), Document(page_content='NVIDIA and King’s College London Debut First Privacy-Preserving Federated Learning System for Medical Imaging\\n\\n\\n\\n\\n\\nRelated posts\\n\\n\\n\\n\\n\\n\\n\\n\\n          Scalable Federated Learning with NVIDIA FLARE for Enhanced LLM Performance\\n        \\n\\n\\n\\nScalable Federated Learning with NVIDIA FLARE for Enhanced LLM Performance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Video: Build a RAG-Powered Chatbot in Five Minutes\\n        \\n\\n\\n\\nVideo: Build a RAG-Powered Chatbot in Five Minutes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Evaluating Retriever for Enterprise-Grade RAG\\n        \\n\\n\\n\\nEvaluating Retriever for Enterprise-Grade RAG\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Build an LLM-Powered API Agent for Task Execution\\n        \\n\\n\\n\\nBuild an LLM-Powered API Agent for Task Execution\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Build an LLM-Powered Data Agent for Data Analysis\\n        \\n\\n\\n\\nBuild an LLM-Powered Data Agent for Data Analysis\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nL\\nT\\nF\\nR\\nE', metadata={'source': 'https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/', 'title': 'Turning Machine Learning to Federated Learning in Minutes with NVIDIA FLARE 2.4 | NVIDIA Technical Blog', 'description': 'Federated learning (FL) is experiencing accelerated adoption due to its decentralized, privacy-preserving nature. In sectors such as healthcare and financial…', 'language': 'en-US'})]\n",
            "article: Low-Quality Ad Content and Post-Click Experiences\n",
            "article: https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/\n",
            "Splits: [Document(page_content='Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFor Advanced Facebook Marketers\\n\\n\\n\\nBlog\\nAccess\\n\\nMembership Info\\nPHC Login\\nAgencies\\nOne-on-One\\nCustom Event Mastery\\n\\n\\nFree\\n\\nNewsletter\\nDaily Videos\\nBeginners\\nQuiz\\nFoundations\\nSafe Zones\\n\\n\\nVideos\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGeneric selectors\\n\\n\\n\\n\\n\\n\\nExact matches only \\n\\n\\n\\n\\n\\n\\n\\nSearch in title \\n\\n\\n\\n\\n\\n\\n\\nSearch in content \\n\\n\\n\\n\\n\\n\\n\\nPost Type Selectors\\n\\n\\n\\n\\n\\n\\nSearch in posts \\n\\n\\n\\n\\n\\n\\n\\nSearch in pages \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\nSubscribe to **Advanced Meta Ads Tips** with daily video updates\\n\\n\\n\\n\\nFind Out More \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLow-Quality Ad Content and Post-Click Experiences\\n\\nMarch 6, 2024 by Jon Loomer - No Comments\\n\\n\\n\\n\\n\\nShare via:\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n\\n\\n\\n\\nPost\\n\\n\\n\\n\\n\\n\\n\\nEmail', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='Ad quality is an important factor in the Meta ad auctionFacebook uses an ad auction to determine the best ad to show to a person at a given point in time. The winner of the auction is the ad with the highest total value, based on bid, estimated action rates, and ad quality. More. It could be the difference when given the choice of two ads to show.\\nWhile this is something to consider from an ad-to-ad basis, it’s also a potentially much bigger problem if you make a habit of creating low-quality ads. Per Meta:\\nIn certain instances, if you repeatedly post policy-violating or lower quality ads, our systems may start considering all ads from your Page, domain, ad account or other associated entities as lower quality.\\nThis could become a long-term problem. But Meta does say that if you correct course, your ad performance should improve “over time.”', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='This could become a long-term problem. But Meta does say that if you correct course, your ad performance should improve “over time.”\\nWhen considering ad quality, Meta’s systems also look beyond the ad to the post-click experience (like the landing page). Do not ignore the landing page when addressing ad quality. \\nIn this post, you’ll learn some specific examples of the following:', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='Low-quality ad content\\nLow-quality post-click experiences\\nUser signals\\nLow Quality or Disruptive Content advertising policy', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='At the end, I’ll provide recommendations on how to address ad quality.\\nLow-Quality Ad Content\\nFirst, you need to avoid specific uses of copy and language in your ad that will flag it as low quality.\\nThese are things that are generally allowed, but within reason. What you’ll eventually find at the end of this post is that any of these things in excess will be considered an ad policy violation that will get your ads rejected.\\n1. Withholding information.\\nIn other words, “clickbait.” We see organic content like this all the time. There’s some big, shocking news story, but the headline and post leave out important details. If we want to clear up what actually happened, we have to click.', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='As a sports nut, I see this all the time (again, not with ads but organic content). A shared link with a featured image that doesn’t clearly depict a specific player. A headline and maybe primary text about a rumor or transaction related to this unnamed player. If you want to know who it is, you need to click.\\nIt doesn’t mean that everything needs to be in your primary text, featured image, and headline. But if you are clearly omitting important information in an attempt to inspire the click, it will qualify as low quality.\\nHere are a couple of great examples that Meta shared…', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='2. Sensationalized language.\\nAnother form of clickbait, but this form of low-quality ad content is specific to exaggerated text and headlines. Some things actually are shocking. But if the sensationalized text inspires a click and the actual content doesn’t follow through with a shocking story, it can be classified as low-quality ad content.\\nHere’s an example from Meta related to “MIND-BLOWING uses of carrots!”\\n\\n\\n\\n3. Engagement bait.\\nThis would include ads that inspire or request actions (typically comments, shares, likes, and other reactions) in an unnatural way. Once again, we see this often with organic content. You may even benefit from it. But it may work against you when running ads.\\nLIKE if you like baseball, LOVE if you’re a Brewers fan, comment “YES” if you’re both, and SHARE if the Brewers are going to the World Series this season.\\nMaybe that’s over the top. But here are a couple of examples from Meta…', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='Low-Quality Post-Click Experiences\\nSometimes, your ad is fine but it’s your landing page that is the problem. As was the case with low-quality ads, the following post-click experiences are technically allowed, within reason, but they could impact your ad costs. If your use of these things is extreme, it could get your ads rejected.\\nWe’ll get to the similarities between these examples and Meta’s own ad policy at the bottom of this post.\\n1. Lack substantive or original content.\\nMeta doesn’t provide specific examples of this, but I assume this could include a wide variety of problematic content. Maybe you direct to stolen content or the page has basically nothing on it of value.\\nHow quality is measured related to “substantive” is unclear. But if you direct to a very simple landing page, keep this in mind.\\n2. Disproportionate volume of ads relative to content.', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='How quality is measured related to “substantive” is unclear. But if you direct to a very simple landing page, keep this in mind.\\n2. Disproportionate volume of ads relative to content.\\nIt’s not uncommon for websites to monetize themselves with ads, so that isn’t a problem in itself. The problem is when those ads become “disproportionate.”\\nOnce again, Meta doesn’t define this so that we know what percentage of real estate would qualify, but keep it in mind. I know that some advertisers send traffic to their website for the sole purpose of collecting on ad revenue. If you overdo it here, it could increase your costs.\\n3. Pop-up ads or interstitial ads.\\nI have pop-up ads. You may have even seen one while reading this post. That doesn’t make my website unique.\\nLook, I hate pop-ups, too. Unfortunately, they remain very effective. And when I turned them off for a year or two, I felt it.', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='Look, I hate pop-ups, too. Unfortunately, they remain very effective. And when I turned them off for a year or two, I felt it.\\nOnce again, pop-up ads are allowed. Your Meta ads won’t be rejected if you send people to a landing page with a pop-up ad. You may not even see a noticeable difference in costs. But it’s another factor that will contribute to whether the experience is considered low-quality.\\n4. Unexpected content experiences.\\nThe example Meta provided is “spreading an article’s content across multiple pages and requiring someone to click and/or load multiple pages to read through the full article.”\\nThis makes me think of lists and other popular types of content that don’t allow you to read the full piece in one page. The website benefits from clicks, so you’re forced to click multiple times to keep reading.\\nI don’t know if this includes lazy loading pages where only a portion of the page loads and you need to click to keep reading and make the remaining article visible.', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='I don’t know if this includes lazy loading pages where only a portion of the page loads and you need to click to keep reading and make the remaining article visible.\\n5. Misleading experiences.\\nAccording to Meta’s examples, this tends to apply to negative shopping experiences: Landing page content that misrepresents products, shipping times, or other customer support issues.\\nThis one again isn’t all that clear, but it’s ultimately related to a bad customer experience that happens post-click.\\nUser Signals\\nMany of the examples so far may be detected automatically from Meta’s systems. But there are also ways that users can notify Meta of problems related to low-quality ads and post-click experiences.\\n1. Hiding ads.\\nSpecifically, three different actions that users can take:', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='Hide ad\\nHide all ads from this advertiser\\nHide ad due to repetition\\n\\n2. Report ads.\\nYou can report ads for a long list of reasons that would be signals of low quality.\\n\\nI know that some advertisers are probably wary of user reports contributing to Meta’s quality signals, but it’s safe to say that any ad — no matter how innocent — will get negative responses. Some people simply hate all ads and will report or hide them all. They have unreasonable expectations.\\nThe problem will be if Meta receives an abnormal rate of these reports on your ads.\\n3. Landing page activity.\\nSpecifically: \\n\\nLanding page bounce rate\\nLanding page dwell time', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='This makes sense, specifically tied to clickbait and post-click experiences. Maybe the ad inspired an action, but the landing page didn’t follow through. Or maybe the experience on the landing page was so bad (pop-ups, high volume of ads, generally low quality) that you immediately abandon.\\nLow Quality or Disruptive Content advertising policy\\nThe content above is related to low-quality, but allowed, ad content. Too much of it can negatively impact delivery and costs.\\nBut Meta also has an advertising policy regarding restricted Low Quality or Disruptive Content. If you violate any of these policies, your ads may be rejected.\\n1. Examples of restricted low-quality ad content.\\nImages that are excessively cropped to force you to click to view more: This reminds me of what was a popular organic post type that has seemed to mysteriously disappear. It relied on large images that were broken into multiple parts, and you typically could only see one or two of those parts.', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='This wouldn’t just be considered low-quality, it would violate this advertising policy and should get your ad rejected.\\nDeceptive or exaggerated ad text that incentivizes people to click on the ad: Okay, so this is confusing. This sounds like clickbait, which was defined among the low-quality ad examples that are technically allowed, though they will likely impact costs.\\nHere’s an explanation from the low-quality ad content page:', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='My interpretation (the best I can, at least) is that there are varying levels of deception. To a point, it’s allowed but could impact your costs negatively. Once you cross that imaginary line, it could get your ad rejected.\\n2. Examples of restricted destination page content.\\nSome of Meta’s examples are obvious:\\n\\nSexually suggestive or shocking content on the destination page\\nFeaturing malicious or deceptive ads on destination pages\\n\\nBut the rest just sound like extreme examples of low-quality post-click experiences:\\n\\nA high ratio of ads relative to content on the destination page\\nDesigning destination pages for the primary purpose of showing ads\\nUsing excessive popup ads, interstitial ads or poor ad formatting on destination pages', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='So, again, avoid sending people to pages with a high density of ads. You can use pop-ups, but they shouldn’t be “excessive.”\\nRecommendations\\nAs you can see, these guidelines aren’t always crystal clear and the levels of severity are open to interpretation. Depending on the low-quality infraction, it may result in higher ad costs or get your ad rejected. Repeat violations may flag your page or account, and it could take time to recover.\\nIt’s always recommended that you avoid toeing these lines of gray area. You might even see some benefits (at least organically) by doing some of these things — though those benefits may not last forever.\\nBottom line: While it’s not easy to define what is and isn’t allowed, it’s ultimately not that complicated.\\n1. Don’t create clickbait.\\n2. Don’t create engage bait.\\n3. Don’t create landing pages that are filled with ads.\\n4. Don’t create bad user experiences.\\nHere are Meta’s three primary tips for complying with these policies:', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='2. Don’t create engage bait.\\n3. Don’t create landing pages that are filled with ads.\\n4. Don’t create bad user experiences.\\nHere are Meta’s three primary tips for complying with these policies:\\n1. Link to landing pages that include a significant amount of original content relevant to the ad\\n2. Minimize the amount of content that blocks or prevents people from viewing the original text on the landing page\\n3. Display the entire article on the primary landing page\\nThese are very reasonable expectations.\\nYour Turn\\nWhat are your experiences with low-quality ad experiences?\\nLet me know in the comments below!', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='Share via:\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n\\n\\n\\n\\nPost\\n\\n\\n\\n\\n\\n\\n\\nEmail\\n\\n\\n\\n\\n\\n \\n\\nfiled under: Meta Marketing Tutorials\\nTags: Meta Ads How To, Meta Advertising\\n\\n\\n\\n\\nSign up for my NewsletterJoin more than 100,000 marketers and subscribe to my mailing list to keep pace in the world of Facebook advertising!     First Name *   Email *      Yes, I would like to receive emails from Jon Loomer *   Sign Up Today     Click here to view our privacy policy. PHCPower Hitters Club\\n\\n\\nJon Loomer', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='BOOST your Facebook Marketing Skills\\nThe PHC provides members with access to hundreds of advertisers who have done what you’re trying to do, have worked in your industry and who can pull from valuable experience.\\nClick here One-on-OneOne-on-One TrainingSchedule one-on-one time with Jon to discuss your Facebook advertising struggles, obstacles, and strategies.\\nClick Here Custom Event MasteryCustom Event MasteryLearn how to leverage custom events for enhanced Meta ads reporting, optimization, and targeting in this comprehensive course.\\nSign Up Meta Ads for Beginners: FREEMeta Ads for Beginners: FREEMeta Ads for Beginners is a free subscription to daily emails meant to grow your knowledge and confidence in Meta advertising.\\nSubscribe Short-Form Video BlueprintShort-Form Video BlueprintGain the confidence and knowledge needed to create engaging and effective short-form videos in this self-paced training (37 lessons).', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content='Subscribe Short-Form Video BlueprintShort-Form Video BlueprintGain the confidence and knowledge needed to create engaging and effective short-form videos in this self-paced training (37 lessons).\\nSign Up Advertising Foundations: 8-Part Series [FREE]Advertising Foundations: 8-Part Series [FREE]There are 8 primary characteristics of successful Meta advertisers that separate them from the rest. Subscribe to get this free 8-part series emailed to your inbox.\\nSubscribe', metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content=\"Subscribe to Jon's Newsletter\\nFeel like you're always one step behind? Jon will keep you updated on everything you need to know about the latest updates related to Facebook advertising.\\n\\n\\nSubscribe \\n\\n\\n\\n\\n\\n\\n\\nConnect with me:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToolsFacebook Ads FAQ\\nMeta Ads Glossary\\nFacebook Pixel Event Generator\\nSocial Media Search Activity\\nMeta’s Earnings Reports\\nPrivacy Policy\\nServicesPower Hitters Club\\nOne-on-One Consulting\\nAgencies\\n \\n\\nQuick LinksAbout Me\\nWhere Should I Start?\\nThe Pubcast\\nPodcast Appearances\\nBlog\\nWhere You Can Find Jon\\nJon’s Advertising Philosophies\\nJonBot\\nCustom Event Mastery\\n \\n\\nFor Advanced Facebook Marketers\\n\\n\\n\\n\\n\\n\\n\\n\\nEmail: [email\\xa0protected]\\n\\n\\n© 2024 Jon Loomer Digital\\nWebsite by Glass Mountains\", metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'}), Document(page_content=\"For Advanced Facebook Marketers\\n\\n\\n\\n\\n\\n\\n\\n\\nEmail: [email\\xa0protected]\\n\\n\\n© 2024 Jon Loomer Digital\\nWebsite by Glass Mountains\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nBlogAccess▼Membership InfoPHC LoginAgenciesOne-on-OneCustom Event MasteryFree▼NewsletterDaily VideosBeginnersQuizFoundationsSafe ZonesVideos \\nWARNING: We have detected that you currently have Javascript disabled. This website requires the use of Javascript, for the best possible viewing experience we highly recommend that you enable Javascript via your browser's options.\", metadata={'source': 'https://www.jonloomer.com/low-quality-ad-content-and-post-click-experiences/', 'title': 'Low-Quality Ad Content and Post-Click Experiences - Jon Loomer Digital', 'description': 'Low-quality ad content and post-click experiences can increase your costs or get your ads rejected. They can impact your account long-term.', 'language': 'en-US'})]\n",
            "article: Police feared 'brummie' accent bias in new call bot\n",
            "article: https://www.bbc.co.uk/news/technology-68466369\n",
            "Splits: [Document(page_content='Police worried 101 call bot would struggle with \\'Brummie\\' accents - BBC NewsBBC HomepageSkip to contentAccessibility HelpYour accountHomeNewsSportEarthReelWorklifeTravelMore menuMore menuSearch BBCHomeNewsSportEarthReelWorklifeTravelCultureFutureMusicTVWeatherSoundsClose menuBBC NewsMenuHomeIsrael-Gaza warWar in UkraineClimateVideoWorldUKBusinessTechScienceMoreEntertainment & ArtsHealthWorld News TVIn PicturesBBC VerifyNewsbeatTechPolice worried 101 call bot would struggle with \\'Brummie\\' accentsPublished1 day agoShareclose panelShare pageCopy linkAbout sharingImage source, Getty ImagesImage caption, Birmingham\\'s skylineBy Chris VallanceTechnology reporterWest Midlands Police trialled a voice assistant powered by artificial intelligence (AI) in a bid to deal with rising volumes of non-emergency calls.Sensitive technical details of the plan were erroneously published online in a document seen by the BBC. It set out potential risks of the AI, including whether the system, dubbed \"Amy101\",', metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'}), Document(page_content='calls.Sensitive technical details of the plan were erroneously published online in a document seen by the BBC. It set out potential risks of the AI, including whether the system, dubbed \"Amy101\", would understand local \"Brummie\" accents.West Midlands Police has insisted \"robust safeguards\" were in place.Based on the tech behind Amazon\\'s popular voice assistant, Alexa, the trial explored how AI could help the force cope with increasing volumes of calls, and potentially offer new services such as responses in different languages. A document detailing the plan was mistakenly posted online by the office of the West Midlands Police and Crime Commissioner (PCC). The document, marked \"official sensitive\" and with warnings that it was \"not to be publicly disclosed\", has since been removed.Amy101 was designed to speak or text-chat in order to deal with callers\\' inquiries and was expected to handle about 200 calls per day.The project, a two month proof-of-concept trial, was nationally funded.It', metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'}), Document(page_content='designed to speak or text-chat in order to deal with callers\\' inquiries and was expected to handle about 200 calls per day.The project, a two month proof-of-concept trial, was nationally funded.It was - the document suggested - the first such project where an AI-powered tool would speak to callers, though other forces were also exploring uses of the tech.Amy101 had the ability to prioritise vulnerable callers, by looking out for certain keywords - such as those referencing domestic violence - and ensuring they were next-in-line to be dealt with by a human call operator, the document says. Through speech or text chat it could direct calls, provide advice on issues such as reporting criminal damage, or requesting a crime update.West Midlands Police told the BBC the trial began on 19 December 2023 and had now concluded.Its director of commercial services, Peter Gillett, said - by the time the trial started - the force had already improved and was now \"one of the top-performing police', metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'}), Document(page_content='2023 and had now concluded.Its director of commercial services, Peter Gillett, said - by the time the trial started - the force had already improved and was now \"one of the top-performing police forces for managing emergency and non-emergency calls\".\\'Brummie\\' biasThe document - prepared for an ethical oversight committee that advises the PCC and Chief Constable - reveals the potential problems that might arise with Amy101, including whether the tech could cope with the local accent.\"Bias will naturally occur within the \"Amy\" system based on accents/localisation - for example can she understand \"Brummie\" accents? And are they treated with equal weighting to different accents in English?\" the document asks.Because Alexa is used globally - coping with a range of accents and languages - it was hoped that this type of bias had been removed. And if calls were not understood they would be transferred to the queue for a human operator.Mr Gillett said the force recognised that technologies', metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'}), Document(page_content='was hoped that this type of bias had been removed. And if calls were not understood they would be transferred to the queue for a human operator.Mr Gillett said the force recognised that technologies capable of understanding ordinary language were \"not flawless\", and therefore may struggle with accents.  As a result the force used a \"large-scale\" system \"to mitigate this bias\". Potential issues around safeguarding data were also flagged, including the risk calls would be used to help train the Amazon AI system, called Lex V2, behind Amy101. Some calls could include personally identifiable information. The document provides the example, \"My name is Marc and I want to report my house was broken into…..\".The police can, however, opt-out of this kind of training and will do this \"where viable\", the document says.The ethics committee also had a number of questions, recorded in its minutes, about Amy101, such as the voice and \"gendered name\" of the tool. The force responded arguing', metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'}), Document(page_content='viable\", the document says.The ethics committee also had a number of questions, recorded in its minutes, about Amy101, such as the voice and \"gendered name\" of the tool. The force responded arguing \"humanisation\" was needed.It also suggested officers requested further analysis from Amazon on potential issues \"such as regional accent recognition and bias testing\".It is not clear whether the concerns raised in the document ever materialised, though police struck a positive note about the outcome of the trial:\"AI (Artificial Intelligence) does present some potential opportunities for providing a more efficient and robust service\", Mr Gillett said.Now the \"proof-of-concept\" trial is over, the force would be \"sharing the results and outcomes at a national scale\", he added.According to the document the government was also interested in the trial - it said a Home Office team was \"keeping a close eye\" on it with a view to wider uses.Related TopicsPolicingArtificial intelligenceBirminghamWest', metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'}), Document(page_content='the government was also interested in the trial - it said a Home Office team was \"keeping a close eye\" on it with a view to wider uses.Related TopicsPolicingArtificial intelligenceBirminghamWest Midlands PoliceAccentsMore on this storyShould AI play an ever-growing role in tackling crime?Published26 JanuaryPolice use AI to save hours on admin dutiesPublished14 December 2023Lincolnshire PCC wants more AI to fight crimePublished9 FebruaryTop StoriesLive.\\xa0Democrats cheer Biden as he arrives for State of the UnionUS to set up temporary port on Gaza coast for aid deliveryPublished1 hour agoMore than 280 pupils abducted by Nigeria gunmenPublished1 hour agoFeatures\\'We know what\\'s coming\\': East Ukraine braces for Russian advanceNew Blanchett film tackles dark chapter for AustraliaHow the Alec Baldwin fatal film set shooting unfoldedGhana\\'s LGBT terror: \\'We live in fear of snitches\\'Is Hugh right about Oscar films being \\'frankly too long\\'?The world\\'s largest robots are setting sailSaltburn\\'s', metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'}), Document(page_content=\"fatal film set shooting unfoldedGhana's LGBT terror: 'We live in fear of snitches'Is Hugh right about Oscar films being 'frankly too long'?The world's largest robots are setting sailSaltburn's 'tacky rich-kid' noughties look is everywhereEight of the world's most remarkable homesCan the Panama Canal save itself?Elsewhere on the BBCThe 'golden handcuffs' of high-earning jobsEight of the world's most remarkable homesThe quest to depave the world's citiesMost Read1Media tycoon Rupert Murdoch engaged for sixth time2MH370: The families haunted by one of aviation's greatest mysteries3The far-right former football pundit running for PM4New Yorkers lukewarm on troop deployment in subway5More than 280 pupils abducted by Nigeria gunmen6US to set up temporary port on Gaza coast for aid delivery7Sweden formally joins Nato military alliance8Images show N Korea sealing its border with China9Mother charged over missing South African girl, 610Jury in first Trump criminal trial to be anonymousBBC News\", metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'}), Document(page_content='formally joins Nato military alliance8Images show N Korea sealing its border with China9Mother charged over missing South African girl, 610Jury in first Trump criminal trial to be anonymousBBC News ServicesOn your mobileOn smart speakersGet news alertsContact BBC NewsHomeNewsSportEarthReelWorklifeTravelCultureFutureMusicTVWeatherSoundsTerms of UseAbout the BBCPrivacy PolicyCookiesAccessibility HelpParental GuidanceContact the BBCGet Personalised NewslettersWhy you can trust the BBCAdvertise with us© 2024 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.', metadata={'source': 'https://www.bbc.co.uk/news/technology-68466369', 'title': \"Police worried 101 call bot would struggle with 'Brummie' accents - BBC News\", 'description': 'West Midlands Police trialled the non-emergency call-answering AI voice assistant for two months.', 'language': 'en-GB'})]\n",
            "article: Google Gemini is ‘the tip of the iceberg’: AI bias can have ‘devastating impact’ on humanity, say experts\n",
            "article: https://biztoc.com/x/770738114145a5a2\n",
            "Splits: [Document(page_content='Google Gemini is ‘the tip of the iceberg’: AI bias can have ‘devastating impact’ on humanity, say experts\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBizToc\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMENU\\n\\n Login / Sign Up\\n Home\\n Crypto News\\n Media News\\n Hot\\n Live\\n Light Mode\\n Imagery\\n Search\\n Settings & Dark Mode\\n Customize News Grid\\n\\n iOS App\\n GPT Plugin\\n\\n Facebook\\nTwitter\\n\\n\\nRSS Feed\\n\\n\\n\\n\\n\\n\\nGoogle Gemini is ‘the tip of the iceberg’: AI bias can have ‘devastating impact’ on humanity, say experts\\n\\n\\nfoxbusiness.com/media/google-gemini-tip-iceberg-ai-bias-devastating-impact-humanity-experts\\n\\n\\n\\n\\n        Substantial backlash against Google\\'s Gemini artificial intelligence (AI) chatbot has elevated concern about bias in large language models (LLMs), but experts warn that these issues are just the \"tip of the iceberg\" when it comes to the potential impact of this tech across industries.The rapid advancement of AI has led to significant advancements in various fields. It can…', metadata={'source': 'https://biztoc.com/x/770738114145a5a2', 'title': 'Google Gemini is ‘the tip of the iceberg’: AI bias can have ‘devastating impact’ on humanity, say experts', 'description': \"Substantial backlash against Google's Gemini artificial intelligence (AI) chatbot has elevated concern about bias in large language models (LLMs), but experts…\", 'language': 'en'}), Document(page_content='#google#gemini#adnanmasood#mvp#ust#mit#foxnewsdigital#masood \\n\\n        This story appeared on foxbusiness.com, .\\n    \\n\\n\\n\\n\\n\\n\\n\\nFacebook\\nTwitter\\n\\n\\nRSS Feed\\n\\n\\n\\n\\nAbout \\xa0⁞\\xa0\\n                    Contact \\xa0⁞\\xa0\\n                    Legal \\xa0⁞\\xa0\\n                    Status\\n\\n\\n\\n\\n\\nThe Entire Business World on a Single Page. Free\\xa0to\\xa0Use\\xa0→', metadata={'source': 'https://biztoc.com/x/770738114145a5a2', 'title': 'Google Gemini is ‘the tip of the iceberg’: AI bias can have ‘devastating impact’ on humanity, say experts', 'description': \"Substantial backlash against Google's Gemini artificial intelligence (AI) chatbot has elevated concern about bias in large language models (LLMs), but experts…\", 'language': 'en'})]\n",
            "article: Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation\n",
            "article: https://www.investorsobserver.com/news/qm-pr/5014697262019548\n",
            "Splits: [Document(page_content='Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStocks\\nCrypto\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat We Do\\nReviews\\nAbout Us\\nPricing\\nSign Up\\nLogin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign Up\\nLogin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\nMy Portfolio\\n\\nStocks\\n\\nStocks Dashboard\\nTop 5 Stocks\\nStock Screener\\nSector & Industry\\n\\n\\n\\nOptions\\n\\nOptions Dashboard\\nOptions Portfolios\\nOptions Screener\\n\\n\\nCrypto\\n\\nCalendars\\n\\nEarnings Calendar\\nFDA Calendar\\n\\n\\nCompare\\nNews\\nHelp Center\\n\\n\\n\\n\\n×\\n\\n\\nHome\\nMy Portfolio\\n\\nStocks\\n\\nStocks Dashboard\\nTop 5 Stocks\\nStock Screener\\nSector & Industry\\n\\n\\n\\nOptions\\n\\nOptions Dashboard\\nOptions Portfolios\\nOptions Screener\\n\\n\\nCrypto\\n\\nCalendars\\n\\nEarnings Calendar\\nFDA Calendar\\n\\n\\nCompare\\nNews\\nHelp Center\\nPricing\\nWhat We Do\\nReviews\\nAbout Us\\nLogin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNews Home\\n\\nCognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation\\n\\nThursday, March 07, 2024 12:01 AM | PR Newswire via QuoteMedia', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='News Home\\n\\nCognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation\\n\\nThursday, March 07, 2024 12:01 AM | PR Newswire via QuoteMedia\\n\\n\\n\\nMentioned in this article\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                                CTSH\\n                                            \\n\\n1.00%\\n                                                                                                            \\n\\n\\n\\n\\n\\n 69\\n                                            \\n\\n\\n\\n\\n\\n\\n                                            See CTSH Report\\n                                        \\n\\n\\n\\n\\n\\n\\nCognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation\\n\\n\\n\\n   Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation\\n  \\n\\n\\n\\n\\n\\n    PR Newswire', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation\\n  \\n\\n\\n\\n\\n\\n    PR Newswire\\n   \\n\\n\\n\\n\\n     With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will be on research, innovation and production of cutting-edge AI systems\\n    \\n\\n\\n\\n\\n      TEANECK, N.J.\\n     \\n\\n    ,\\n    \\n\\n      March 7, 2024\\n     \\n\\n    /PRNewswire/ --\\n    \\n\\n      Cognizant', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='TEANECK, N.J.\\n     \\n\\n    ,\\n    \\n\\n      March 7, 2024\\n     \\n\\n    /PRNewswire/ --\\n    \\n\\n      Cognizant\\n     \\n\\n    (Nasdaq:\\xa0CTSH), a leading global technology company, today announced the launch of an Advanced Artificial Intelligence (AI) Lab. The lab, based in\\n    \\n     San Francisco\\n    \\n    , will focus on advancing the science and practice of AI through innovation and development of intellectual property and AI-enablement technologies. Staffed by a team of researchers and developers, including AI pioneers and PhDs, the lab will collaborate with research institutions, customers, and startups and already has 75 issued and pending patents that provide a differentiated foundation on which to build cutting edge AI solutions. The lab is part of the commitment Cognizant announced last year to invest\\n    \\n     $1 billion\\n    \\n    in generative AI (gen AI) over the next three years.', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content=\"The launch of Cognizant's Advanced AI Lab comes at a time when enterprises are rapidly working to understand the impact of AI and meet expanding expectations around its promise. Recent\\n    \\n     research\\n    \\n    has shown more than half (66 percent) of executives are ambivalent or dissatisfied with their company's progress on AI and gen AI, and most executives (85 percent) plan to increase spending on AI and gen AI in 2024. Longer term, Cognizant and Oxford Economics' recent\\n    \\n     study\\n    \\n    found gen AI could inject up to\\n    \\n     $1 trillion\\n    \\n    to the U.S. economy by 2032.\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='\"As AI rapidly evolves into mainstream use, Cognizant is continually pushing boundaries through strategic partnerships, training programs and platform investments to be an AI-first company,\" said Cognizant CEO\\n    \\n     Ravi Kumar S\\n    \\n    . \"With the launch of Cognizant\\'s Advanced AI Lab, we\\'re progressing this effort by investing in state-of-the-art core AI research that establishes our position at the forefront of innovation and our industry. Because we own the client solutioning relationship from end to end, we have a unique line of sight into businesses, industries, and their AI needs. We\\'re putting dedicated focus on AI research and development to lay the groundwork for better business outcomes and a better future.\"', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='\"Cognizant\\'s Advanced AI Lab is an important partner for us in the research community, and we\\'ve been fast at work with them already working on simulating brain dynamics in healthy and patient populations,\" said Dr.\\n    \\n     Manish Saggar\\n    \\n    , Assistant Professor and Director of Brain Dynamics Lab at\\n    \\n     Stanford University\\n    \\n    School of Medicine. \"I\\'m excited about the progress we\\'re making together, as well as its potential impact on not only advancing science but also for developing novel interventions for mental health disorders.\"\\n   \\n\\n    Specifically, Cognizant\\'s Advanced AI Lab will focus on the following areas:\\n   \\n\\n\\n     Researching, designing, evaluating, building, and showcasing innovative AI solutions for business productivity and decision making across various domains\\n    \\n\\n     Collaborating with external stakeholders, including research institutions, customers, and startups, and engaging in AI-for-good research projects', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content=\"Collaborating with external stakeholders, including research institutions, customers, and startups, and engaging in AI-for-good research projects\\n    \\n\\n     Evangelizing gen AI-enabled decision-making solutions globally, and strengthening Cognizant as a knowledge hub for published, peer-reviewed research on AI\\n    \\n\\n     Partnering across Cognizant's business lines and practices to train and upskill associates on new AI solutions as they become available through the Cognizant Neuro™ AI platform\\n    \\n\\n     Fostering an environment of continuous learning, innovation, and knowledge sharing\\n    \\n\\n\\n    The lab will be led by AI entrepreneur and inventor,\\n    \\n\\n      Babak Hodjat\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='Fostering an environment of continuous learning, innovation, and knowledge sharing\\n    \\n\\n\\n    The lab will be led by AI entrepreneur and inventor,\\n    \\n\\n      Babak Hodjat\\n     \\n\\n    , with AI research activities under the supervision of\\n    \\n     University of Texas at Austin\\n    \\n    AI Professor and neuroevolution pioneer,\\n    \\n     Risto Miikkulainen\\n    \\n    . In just the last year, their team of researchers and developers have already\\n    \\n     published 14 papers\\n    \\n    in academic venues, and they received the Best Pathway to Impact Award at the NeurIPS 2023 Climate Change Workshop for the paper,\\n    \\n     Discovering Effective Policies for Land-Use Planning\\n    \\n    .', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content=\"In addition to the launch of Cognizant's Advanced AI Lab, Cognizant is supporting enterprise AI adoption through its AI Innovation Studios in\\n    \\n     London\\n    \\n    ,\\n    \\n     New York\\n    \\n    ,\\n    \\n     San Francisco\\n    \\n    ,\\n    \\n     Dallas\\n    \\n    , and Bengaluru. These studios serve as inspiration and co-innovation spaces that bring clients and associates together to identify and collaborate on new business solutions.\\n   \\n\\n    Cognizant is dedicated to maintaining the highest standards for responsible and ethical AI, focusing on safety, security, privacy, transparency, and inclusion. For additional details on Cognizant's approach to gen AI and the company's commitment to responsible AI, visit\\n    \\n\\n      here\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='here\\n     \\n\\n    . Cognizant also develops research and insights that help leaders make informed decisions to fuel their companies\\' success. In partnership with Oxford Economics, Cognizant recently published a study on the economic impact of AI, \"\\n    \\n     New World, New Work\\n    \\n    ,\" and intends to release further research on AI\\'s impact on productivity, tasks, skills, jobs and occupations.\\n   \\n\\n\\n     About Cognizant\\n     \\n\\n    Cognizant (Nasdaq: CTSH) engineers modern businesses. We help our clients modernize technology, reimagine processes and transform experiences so they can stay ahead in our fast-changing world. Together, we\\'re improving everyday life. See how at\\n    \\n     www.cognizant.com\\n    \\n    or @cognizant.\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    View original content to download multimedia:\\n    \\n     https://www.prnewswire.com/news-releases/cognizant-unveils-advanced-artificial-intelligence-lab-to-accelerate-ai-research-and-innovation-302082098.html', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content=\"SOURCE  Cognizant\\n   \\n\\n\\n\\n\\nPR NewswireMarch 6, 2024 - 9:01 PM PSTNews by QuoteMediawww.quotemedia.com\\n\\n\\nShare this article:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStay In The Know\\nSubscribe to our daily morning update newsletter and never miss out on the need-to-know market news, movements, and more.\\n\\n\\n\\nYour Name\\n\\n\\n\\nEmail Address\\n\\n\\n\\nGet Newsletter\\n\\n\\n\\n\\n\\n\\n\\nThank you for signing up! You're all set to receive the Morning Update newsletter\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated Articles\\n\\n\\n\\nRadNet Announces Pricing of Public Offering of Common Stock\\n\\n\\n                    Thursday, March 07, 2024 09:54 PM | GlobeNewswire via QuoteMedia\\n                \\n\\n\\n\\nLiaoning set to play bigger role as key trade hub\\n\\n\\n                    Thursday, March 07, 2024 09:32 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nNayax Announces Pricing of Public Offering\\n\\n\\n                    Thursday, March 07, 2024 09:26 PM | GlobeNewswire via QuoteMedia\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content=\"Nayax Announces Pricing of Public Offering\\n\\n\\n                    Thursday, March 07, 2024 09:26 PM | GlobeNewswire via QuoteMedia\\n                \\n\\n\\n\\nCrackdown on telecom fraud bears fruit, says chief of top procuratorate\\n\\n\\n                    Thursday, March 07, 2024 09:20 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nShareholders of The Children's Place, Inc. Should Contact Levi & Korsinsky Before April 29, 2024 to Discuss Your Rights - PLCE\\n\\n\\n                    Thursday, March 07, 2024 09:15 PM | ACCESSWIRE via QuoteMedia\\n                \\n\\n\\n\\nCLE? DE PEAU BEAUTE? ANNOUNCES RESHMA SAUJANI AS RECIPIENT OF THE POWER OF RADIANCE AWARDS 2024\\n\\n\\n                    Thursday, March 07, 2024 09:00 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\n\\n\\n\\nRelated Companies\\n\\n\\nCTSH\\n\\n\\n\\n\\nYou May Also Like\\n\\n\\n\\n\\n\\n\\nRelated Articles\\n\\n\\n\\nRadNet Announces Pricing of Public Offering of Common Stock\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content=\"Related Companies\\n\\n\\nCTSH\\n\\n\\n\\n\\nYou May Also Like\\n\\n\\n\\n\\n\\n\\nRelated Articles\\n\\n\\n\\nRadNet Announces Pricing of Public Offering of Common Stock\\n\\n\\n                    Thursday, March 07, 2024 09:54 PM | GlobeNewswire via QuoteMedia\\n                \\n\\n\\n\\nLiaoning set to play bigger role as key trade hub\\n\\n\\n                    Thursday, March 07, 2024 09:32 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nNayax Announces Pricing of Public Offering\\n\\n\\n                    Thursday, March 07, 2024 09:26 PM | GlobeNewswire via QuoteMedia\\n                \\n\\n\\n\\nCrackdown on telecom fraud bears fruit, says chief of top procuratorate\\n\\n\\n                    Thursday, March 07, 2024 09:20 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\nShareholders of The Children's Place, Inc. Should Contact Levi & Korsinsky Before April 29, 2024 to Discuss Your Rights - PLCE\\n\\n\\n                    Thursday, March 07, 2024 09:15 PM | ACCESSWIRE via QuoteMedia\", metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='Thursday, March 07, 2024 09:15 PM | ACCESSWIRE via QuoteMedia\\n                \\n\\n\\n\\nCLE? DE PEAU BEAUTE? ANNOUNCES RESHMA SAUJANI AS RECIPIENT OF THE POWER OF RADIANCE AWARDS 2024\\n\\n\\n                    Thursday, March 07, 2024 09:00 PM | PR Newswire via QuoteMedia\\n                \\n\\n\\n\\n\\n\\n\\nRelated Companies\\n\\n\\nCTSH\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDownload the app\\n\\n\\n\\n\\n\\n\\n\\nContact\\n\\n435 Merchant Walk Square, Suite 300-145\\nCharlottesville, VA 22902\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStocks\\n\\n\\nStocks Dashboard\\nTop 5 Stocks\\nStock Screener\\n\\nOptions\\n\\nOptions Dashboard\\nOptions Portfolios\\nOptions Trade Screener\\n\\nCrypto\\n\\nCrypto Dashboard\\n\\n\\n\\nAccount and Support\\n\\nMy Account\\nAbout Us\\nNewsletters\\nContact Us\\nHelp Center\\nReviews\\nEmail Whitelist Instructions', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'}), Document(page_content='Crypto\\n\\nCrypto Dashboard\\n\\n\\n\\nAccount and Support\\n\\nMy Account\\nAbout Us\\nNewsletters\\nContact Us\\nHelp Center\\nReviews\\nEmail Whitelist Instructions\\n\\n\\n\\n\\nStock Price data may be delayed up to 15 minutes.\\nCopyright Â© 2024. Portions of this content may be copyrighted by Fresh Brewed Media, Investors Observer, and/or O2 Media LLC. All Rights Reserved. Portions of this content protected by US Patent numbers 7,865,496, 7,856,390, and 7,716,116. Investing in stocks, bonds, option and other financial instruments involve risks and may not be suitable for everyone. Portfolio results are unaudited and based on varying investment expiration dates. Terms of Service | Privacy Policy\\n\\n\\n\\n\\n\\n\\nGet the InvestorsObserver App', metadata={'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation', 'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en'})]\n",
            "article: Introduction to Modern AI 2024 Edition: Part 1\n",
            "article: https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/\n",
            "Splits: [Document(page_content='» Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\nJoin\\nBlog\\nMore +\\n                    \\nWhat We Do\\nHow We Do It\\nWho We Are\\nContact Us\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSolution Street Blog\\n\\n\\n\\n\\n\\n\\nIntroduction to Modern AI 2024 Edition – Part 1\\n\\n\\t\\t\\t\\t\\tJanuary 29th, 2024', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='It is hard to believe it has been almost six years since I wrote my last article on Artificial Intelligence (AI), titled Practical Artificial Intelligence. In that article I gave an overview of the state of AI and Machine Learning (ML) and some popular usage and tools at the time. Since then, things have gotten crazy in the AI world and everyone is talking about tools like ChatGPT, but most people really don’t understand all the terminology, tools and what they are best suited for. In this article (Part 1 of 2), I will attempt to give you an updated look at this ecosystem and try to explain things in “Joel” terms.\\nSo let’s start off by defining all the key terms and look at some examples of each.\\nKey Terms\\nArtificial Intelligence (AI) is human intelligence exhibited by machines. Examples of AI include: facial recognition, help desk chat bots, smart thermostats and speech to text.\\xa0\\nFacial RecognitionHelpdesk ChatbotSmart ThermostatSpeech to text', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Facial RecognitionHelpdesk ChatbotSmart ThermostatSpeech to text\\nAs developers, we have been writing AI into our code since the beginning. Below is an early example of playing a game of tic tac toe – the code is simulating another human’s intelligence to play against you. Note, there is nothing fancy or magic about this code, in fact it’s just a series of IF statements; and, yes, this does qualify as AI!', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Machine Learning (ML) is a subset of AI where we use algorithms to parse data, learn from it and then decide to do something. All machine learning counts as AI, but not all AI counts as machine learning. For example, symbolic logic – rules engines, expert systems and knowledge graphs – could all be described as AI, and none of them are machine learning.\\nProduct RecommendationsImage ClassificationSpam Classification\\nIf you go to Amazon to shop for some shoes maybe it’ll suggest a shirt to match your shoes.\\xa0 Amazon also uses tools like image classification to decide what an image is to prevent false advertising. Lastly, the big email providers such as Google and Yahoo use spam classification to decide whether an email is spam. How well they do this impacts us every day!', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Generative AI is artificial intelligence capable of generating text, images, or other media, using predictive models. Probably the most well-known generative AI today is Dall-E. Many people are using it to generate images. Also, ChatGPT is being used to generate articles/content.\\nMost of us never coded generative AI in the early days, but there was plenty of work going on even back to 1970; some of the early examples included speech synthesis.\\n\\nGPT – Generative Pre-trained Transformer – ChatGPT being the most popular (Chat Generative Pre-trained Transformer) is a large language model-based chatbot developed by OpenAI (multiple competitors here like Bard, Claude).', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Retrieval Augmented Generation (RAG) is a powerful technique that combines the strengths of pre-trained language models with the benefits of information retrieval systems. The primary purpose of RAG is to enhance the capabilities of large language models (LLMs), particularly in tasks that require a deep understanding and generation of contextually relevant responses.\\nSince most developers didn’t code LLMs back in the day, most also didn’t implement RAG.\\nAn example of RAG is taking some information not already contained in a standard model and augmenting it to make the model more powerful for that specific usage. An example includes\\xa0 taking my company handbook and augmenting it with an existing GPT/LLM by using a technique called embeddings. Once I have done this I can ask the GPT questions about my company policies and it should be able to make deductions about it, even though the original LLM knows nothing about my company.\\nBusiness Use', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Business Use\\nNow that we have the basic vocabulary down and have some good examples of how all this stuff works, let’s talk about 2024, how we should do things and how we can leverage all the great tools folks have built to do awesome AI and ML!\\nMy company, Solution Street, uses software to solve business problems for our customers. This is what we have always done, so I like to approach AI and ML not from a technology approach, but more from “what business problems can we solve?”\\nTraditionally we have used AI and ML to solve the following problems:', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Taking documents and turning them into something searchable and usable – traditionally we have used\\xa0 Natural Language Processing (NLP) to understand the meaning and sentiment of text, to make it searchable and also automating document processing to turn images into text and classify and segment them. Most of this work revolved around taking legacy PDF documents and making better use of them.\\n\\n\\nPredicting sales results – taking data our customers have and building models to\\xa0 produce sales predictions for our customers.\\n\\n\\nBuilding faster, less error prone software – for the last few years, we have been leveraging code-assist tools like GitHub Copilot and Amazon CodeWhisperer to help developers write code faster at a higher quality.', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Today, we can solve these same problems with higher accuracy and less work using the latest and greatest tools (we will talk about a few of these shortly). We can also more easily solve other typical business problems more easily with new tools.\\xa0\\nSome problems that are easier to solve now are:\\n\\nAutomating simple customer service interactions – building a custom chatbot to solve your customers’ most common problems is now fairly easy to do.\\nAutomating tasks that were historically done manually, like combining files, filtering files, summarizing files, etc. by using ChatGPT-type tools to assist you.\\nIncorporating features like facial recognition and speech to text/text to speech into our systems.\\n\\nTools & Frameworks\\nUntil recently, if you wanted to build a machine learning model, the only option you had was to\\xa0 write some code. Most developers choose from one of a few options:', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Tools & Frameworks\\nUntil recently, if you wanted to build a machine learning model, the only option you had was to\\xa0 write some code. Most developers choose from one of a few options:\\xa0\\n\\nScikit-learn – easy to learn, where most people start\\xa0\\nTensorFlow – from Google, more powerful, but complex (some folks use Keras on top)\\xa0\\nPytorch – from Meta, more powerful and easier to use than TensorFlow\\n\\nNow the major cloud providers each have their own set of tools targeted at each area:\\n\\nMicrosoft: Azure OpenAI (GPT), Vision/Speech/Translation, ML Studio, Automated ML, Pretrained Models\\nAWS: Sagemaker (traditional), Bedrock – multiple model options,\\xa0 Sagemaker has Canvas and Autopilot for Automated ML, AmazonQ (GPT)\\nGoogle: VertexAI (Gemini model), Bard (GPT), TensorFlow\\n\\nHigher level tools have also come upon the scene recently that allow you to build models quickly without writing any code:', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'}), Document(page_content='Higher level tools have also come upon the scene recently that allow you to build models quickly without writing any code:\\n\\nNyckel – lets you upload a CSV and go!\\nSimpleML for Google sheets – see my business partner Arthur’s blog article\\nAutoML (AWS, Azure, GCP), from cloud providers (on previous page)\\nUsing ChatGPT to do your ML for you! (used to be called Advanced Data Analysis)\\n\\nSummary\\nIn this article (Part 1), we summarized all the latest terminology around artificial intelligence and machine learning along with many examples of them. We also showed typical business problems that can be solved with the latest tools. Lastly, we talked about the popular tools in this space today. Stay tuned for Part 2 of this article where we will walk you through a real life example using one of these tools to solve a business problem!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBlog Search\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nHome\\nJoin\\nContact Us\\n\\n© 2024 Solution Street LLC. All rights reserved.', metadata={'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog', 'language': 'en-US'})]\n",
            "article: Tweag I/O: Extending destination-passing style programming to arbitrary data types in Linear Haskell\n",
            "article: https://tweag.io/blog/2024-03-07-dps-haskell/\n",
            "Splits: [Document(page_content='Extending destination-passing style programming to arbitrary data types in Linear Haskell - TweagTechnical groupsOpen sourceCareersResearchBlogContactConsulting Platform Global consulting partnerEuropean product partnerGlobal Atlassian transformation leader Extending destination-passing style programming to arbitrary data types in Linear Haskell7 March 2024 ‚Äî by Thomas BagrelÓ§µlinear-typesÓ§µhaskellThree years ago, a blog post introduced destination-passing style (DPS) programming in Haskell, focusing on array processing, for which the API was made safe thanks to Linear Haskell. Today, I‚Äôll present a slightly different API to manipulate arbitrary data types in a DPS fashion, and show why it can be useful for some parts of your programs.\\nThe present blog post is mostly based on my recent paper Destination-passing style programming: a Haskell implementation, published at JFLA 2024. It assumes basic knowledge of Linear Haskell and intermediate fluency in Haskell.\\nTail Modulo Cons', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='Tail Modulo Cons\\nHaskell is a lazy language by default, but a lot of algorithms are in fact more efficient in a strict setting. That‚Äôs one reason why Haskell has been extending support for opt-in strictness, via strict field annotation for example.\\nNon-tail recursive functions such as map are decently efficient in a lazy setting. On strict data structures, however, non-tail recursive consume stack space. That‚Äôs why the quest for tail-recursive implementations is even more central in strict languages such as OCaml than in Haskell.\\nIf any function can be made tail-recursive using a CPS transformation, this transformation trades stack space for heap space (where the built continuations are allocated), which is rarely a win performance-wise. We actually want to focus on tail-recursive implementations which don‚Äôt resort to continuations, and unfortunately, some functions don‚Äôt have one in a purely functional setting.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='For example, some functions are almost tail-recursive, in the sense that the recursive call is the penultimate computation in the returned value, and the last one is just a constructor application. This is actually the case for map:\\nmap :: (a -> b) -> [a] -> [b]\\nmap f [] = []\\nmap f (x : xs) = (f x) : map f xs\\nOne could argue that a tail-recursive version of map could be written using an accumulator to store the result list, and then reverse it at the end. But that incurs an extra linear operation (reversing the accumulator) that isn‚Äôt present in the naive version.\\nActually, Bour et al. found in 2021 that whenever a function is of this particular shape ‚Äî with just a constructor application over the recursive call ‚Äî named tail-recursive modulo constructor, this function can be easily and automatically converted into an equivalent tail-recursive one in destination-passing style (DPS).', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content=\"In OCaml1, this transformation happens entirely in the compiler. In this blog post, on the other hand, I‚Äôll show how to do it in user-land in Haskell thanks to linear types, which make the API safe.\\nFor map, here‚Äôs the translation to DPS Haskell, although we will come back to it later:\\nmapDPS :: (a -> b) -> [a] -> Dest [b] %1 -> ()\\nmapDPS f [] d = fill @'[] d\\nmapDPS f (x : xs) = let !(dh :: Dest b, dt :: Dest [b]) = fill @'(:) d\\n                     in fillLeaf (f x) dh `lseq` mapDPS f xs dt\\nIt‚Äôs time to see what DPS means and what it offers.\\nWhat is Destination-passing style programming?\", metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='in fillLeaf (f x) dh `lseq` mapDPS f xs dt\\nIt‚Äôs time to see what DPS means and what it offers.\\nWhat is Destination-passing style programming?\\nDestination-passing style (DPS) is a programming idiom in which functions don‚Äôt return a result, but rather write their result directly to a memory location they receive as a parameter. This gives more control over memory to the caller of a function, instead of that control lying exclusively in the hands of the callee. In non-GC languages, or for array processing (as in the aforementioned blog post), it allows the allocation of a big chunk of memory at once, and then gives each piece of the program the responsibility to fill a small part of that chunk (represented by a glorified pointer, aka. destination), giving mostly alloc-free code. In early imperative languages such as C, this is actually quite common: memcpy and strcpy both receive a destination as a parameter.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='In the context of a functional, immutable, GC-based language, we cannot circumvent the allocation of heap objects to obtain alloc-free code. Instead, we get one interesting feature: being able to build functional structures in the reverse order compared to the regular constructor-based approach. This goes hand-in-hand with the ability to create and manipulate incomplete data structures (containing unspecified fields, aka. holes) safely. This is exactly what we will focus on in this blog post.\\nIncomplete structures, you say?\\nAn incomplete structure can be seen as a tree of constructor objects, much like a regular data structure. However, some of the constructor‚Äôs fields might not be specified, leaving holes in the structure.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='Having incomplete structures is very different from having optional fields in a structure represented by the Maybe a type. For so-called incomplete structures, we do not indicate the absence of value (or presence of a hole) through a different type for the leaf itself, but instead we forbid any read on the whole structure as long as (at least) one hole exists somewhere. That way, the field‚Äôs value can (in fact, must) be updated later without allocating the whole structure a second time.\\nTo update a yet-unfilled field of an incomplete structure, we use a destination. A destination is a unique pointer to a hole inside an incomplete structure, that is no longer usable as soon as the hole has been filled. Those pointers are carried alongside the structure until they get consumed. As a result, destinations are also a way to know whether or not a structure has any remaining holes. When an incomplete structure no longer has any accompanying destinations, it can be read safely.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='At this point, incomplete structures could be seen as the nemesis of Haskell, as they bring a form of mutability and a range of memory errors if not handled properly. However, with a proper linear API, which is the real novelty in this blog post, they are both powerful and safe to use. In particular, a linear discipline on destinations guarantees that:', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='when a structure no longer has accompanying destinations, it‚Äôs a complete structure (that is, it has no holes remaining);\\nonce a hole has been filled with a value, that value cannot be changed anymore (i.e. holes are write-once).', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='Implementation of Incomplete structures\\nAs teased before, I introduce an opaque data Incomplete a b to represent incomplete objects. The a part is the structure being built that may contain holes, and the b part carries the destinations pointing to these holes. Destinations are raw pointers under the hood, put in a pretty box: data Dest a represents a pointer to a hole of type a.\\nWhat can we do with an Incomplete a b? We cannot read the structure on the a side (yet) as long as the b side still contains destinations (as they indicate the presence of holes in the a side). The b side is what must be linearly consumed to make the structure readable. What we can do is map over the b side, to consume the destinations little-by-little until there are none left. This is exposed through a (linear) Functor instance:\\ninstance Control.Functor (Incomplete a) where\\n  fmap :: (b %1 -> c) %1 -> Incomplete a b %1 -> Incomplete a c', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='instance Control.Functor (Incomplete a) where\\n  fmap :: (b %1 -> c) %1 -> Incomplete a b %1 -> Incomplete a c\\n  (<&>) :: Incomplete a b %1 -> (b %1 -> c) %1 -> Incomplete a c  -- flipped arguments\\nThis Functor instance lets us access destinations of an incomplete object through a linear continuation of type b %1 -> c.\\nLet‚Äôs take a step back and look at our previous example. mapDPS has signature (a -> b) -> [a] -> Dest [b] %1 -> (). This means that mapDPS f list is in fact a linear continuation of type Dest [b] %1 -> ().\\nIn other terms, given an incomplete structure having a hole of type [b], i.e. i :: Incomplete u (Dest [b]), we can write the result of f mapped to list to this hole, using i <&> mapDPS f list. The resulting structure will have type Incomplete u () (no more destinations), and can be made readable as we‚Äôll see in a moment.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content=\"Here we can see the essence of DPS: functions get less responsibility as they don‚Äôt get to choose where they write their result; instead, the output location is now passed as an explicit parameter to the function. Moreover, inside a function such as mapDPS, we can, and in fact we have no choice but to forget about the global structure we are building ‚Äî it becomes implicit ‚Äî and only focus on the handling of destinations. The Functor instance is thus the glue that lets us assign a location to a producer of data like mapDPS for it to write its output.\\nOperating on Dests\\nLet‚Äôs take a closer look at the mapDPS implementation:\\nmapDPS f [] d = fill @'[] d\\nmapDPS f (x : xs) = let !(dh :: Dest b, dt :: Dest [b]) = fill @'(:) d\\n                     in fillLeaf (f x) dh `lseq` mapDPS f xs dt\", metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content=\"mapDPS f [] d = fill @'[] d\\nmapDPS f (x : xs) = let !(dh :: Dest b, dt :: Dest [b]) = fill @'(:) d\\n                     in fillLeaf (f x) dh `lseq` mapDPS f xs dt\\nIn the base case, there is no element left in the input list, but we still receive a destination d :: Dest [b] that needs to be dealt with linearly. The only meaningful operation here is to write the empty list to the hole represented by d, which is what fill @'[] d does.\\nThe recursive case is more interesting:\", metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='one cons cell should be added to the list, carrying the value f x :: b;\\nwe somehow need to create another destination of type Dest [b] to pass to the recursive call.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content=\"All of that is done in two steps, using fill @'(:) and then fillLeaf.\\nfill @'(:) d is first used to add a new hollow cons cell (:) _h _t :: [b] at the end of the linked list, that is to say, a cons cell with unspecified fields (both the head _h and tail _t are holes). Under the hood, it allocates the new hollow cons cell, writes its address into the destination d :: Dest [b], and returns one destination dh :: Dest b pointing to the hole _h, and one destination dt :: Dest [b] pointing to the hole _t. This gives the signature fill @'(:) :: Dest [b] %1 -> (Dest b, Dest [b]).\\nThen, fillLeaf is used to fill the destination dh :: Dest b (representing the ‚Äúvalue part‚Äù of the newly added cons cell) with the result of f x :: b. fillLeaf :: a -> Dest a %1 -> () is in fact pretty simple. It takes a value, a destination, and writes the value address to the hole represented by the destination. The destination is linearly consumed in the process.\", metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content=\"After doing that, only one destination remains unconsumed: dt :: Dest [b]. This is exactly the destination that will be passed to the recursive call! It corresponds to the new ‚Äúend‚Äù of the linked list.\\nWe directly see here how fill @'(:) extends an (incomplete) list by adding one new ‚Äúslot‚Äù at the end; whereas cons (:) is usually used to extend a normal linked list from the front. This is what I meant in the introduction by building functional structures in the reverse order.\\nWhat I just presented is not, in fact, restricted to lists. It can be used to build any kind of structure, as long as it implements Generic. This is mostly the only constraint fill has; it can be used for all sorts of constructors. For example, we can build a binary tree in a similar way, starting with the root, and extending it progressively in a top-down fashion, using fill @'Leaf and fill @'Node (assuming data Tree a = Leaf | Node a (Tree a) (Tree a) deriving Generic).\", metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='Creating and disposing of Incompletes\\nOne can create a new, empty Incomplete using alloc :: Linearly %1 -> Incomplete a (Dest a). This function exchanges a Linearly token (see below) for an Incomplete of the chosen type a. The resulting Incomplete has a single destination that points to its root of type a. In other terms, even the root of the new structure is a hole at the moment, that will be specified later with the first use of fill or fillLeaf.\\nConversely, as soon as we have an Incomplete with only unit () on the b side, the absence of destination indicates that the structure on the a side is complete. So we can make it readable by getting out of the Incomplete wrapper using fromIncomplete :: Incomplete a () %1 -> Ur a.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='It is valid to use the built structure in a non-linear fashion (justifying why it is wrapped in Ur in return position of fromIncomplete) because it has been made of non-linear elements only: fillLeaf is non-linear in its first argument, and the spine of the structure can be duplicated without breaking linearity.\\nThe last missing piece of this API is linearly :: (Linearly %1 -> Ur b) %1 -> Ur b, whose definition is shared with the one from a previous blog post about linear scopes. linearly delimits a scope in which linear objects can be used. Only non-linear objects can escape this scope (because of the Ur restriction on the return type as before), such as complete structures finalized with a call to fromIncomplete.\\nThe Linearly type, of which an instance is supplied by linearly, is a linear token which can be duplicated to give birth to any number of Incompletes, but each of them will still have to be managed linearly.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='With these final ingredients, we can complete our definition of a tail-recursive map:\\nmap :: (a -> b) -> [a] -> [b]\\nmap f l =\\n  unur $ linearly $ \\\\token ->\\n    fromIncomplete $ alloc token <$> \\\\d ->\\n      mapDPS f l d\\nPerformance\\nThe current implementation behind the API is based on compact regions as they make it easy to operate on memory without too much tension with the garbage collector. However, they incur extra copying in some contexts, which makes it hard sometimes to compete with optimized lazy Haskell code.\\nAt the moment, the mapDPS implementation is slightly more efficient memory-wise than the optimized lazy one for large lists (and less efficient for smaller lists). The same kind of results are obtained for the different use-cases we benchmarked in Section 6 of the associated paper. I expect a next implementation without compact regions, taking place directly in the GC heap, to have better performance.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='In addition, the DPS techniques detailed here are proven to be really efficient in strict languages. This work might thus inspire performance and expressiveness improvements in languages other than Haskell.\\nConclusion\\nThe API presented in this blog post defines a small set of tooling sufficient to create and operate safely on incomplete data structures in Haskell through destination-passing style programming. It is more general than the constructor-based building approach usually used in functional programming languages, and also more general than DPS tooling introduced by Tail Modulo Cons in OCaml. It is also a nice example of how linear types can be used to enforce a write-once memory model in Haskell.\\nThe full prototype API is available here. It currently requires a custom GHC version to work, but I hope I will be able to merge the few primops required for DPS programming into GHC in the future.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content='The full prototype API is available here. It currently requires a custom GHC version to work, but I hope I will be able to merge the few primops required for DPS programming into GHC in the future.\\nI would like to thank Arnaud Spiwack for his solid support and feedback on all pieces of this work.', metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'}), Document(page_content=\"OCaml has had experimental support for Tail-recursion Modulo Constructor since version 4.14.0.‚Ü©\\n\\nAbout the authorsThomas BagrelThomas is a CS engineer, and PhD student working on linear types and memory management. He applies functional programming principles to build reliable and maintainable software wherever it's possible, but can also jump back to imperative programming languages when the situation requires it. He is also a contributor on linear-base, the linear type library for Haskell.\\nIf you enjoyed this article, you might be interested in  joining the Tweag team.This article is licensed under a Creative Commons Attribution 4.0 International license.‚Üê Bazel remote execution with rules_nixpkgsCompanyAboutOpen SourceCareersContact UsWhat we doStrategyProduct DevelopmentPlatform ModernizationDigital OperationsTeamwork with AtlassianWorkInsightsModus BlogTweag BlogTeamwork BlogResearchInnovation podcastConnect with us¬© 2023 Modus Create, LLCPrivacy PolicySitemap\", metadata={'source': 'https://tweag.io/blog/2024-03-07-dps-haskell/', 'title': 'Extending destination-passing style programming to arbitrary data types in Linear Haskell - Tweag', 'description': 'This blog post presents a safe API for destination-passing style programming using Linear Haskell against arbitrary functional data types.', 'language': 'en'})]\n",
            "article: The power of pace in technology\n",
            "article: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology\n",
            "Splits: [Document(page_content='The power of pace in technology | McKinsey', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Skip to main contentThe power of pace in technologyMarch 7, 2024 | Interview Thomas DelaetThe CEO of Hivemind Technologies explains what steps matter in speeding software development for transformations.\\nDespite the old adage of the tortoise and the hare, when it comes to digital transformations, slow and steady does not win the race, according to Erik Schmiegelow, CEO of Hivemind Technologies, a Berlin-based software engineering business. Hivemind’s approach focuses on fast software delivery via small, incremental releases to validate assumptions and derisk the process. During a discussion with McKinsey partner Thomas Delaet, Schmiegelow explains Hivemind’s approach to speed as a key criterion in transformations to reduce risk, the pros and cons of public cloud, and the impact of generative AI (gen AI) on developer productivity. What follows are edited highlights from that conversation.\\nDelivering value via speed', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Delivering value via speed\\nThomas Delaet: Why do you see speed as the main value driver for transformations?\\nErik Schmiegelow: Speed is of the essence, especially when you’re operating in a very complex environment. On the flip side, if you’re looking at a greenfield project, it’s very simple. You have a clean slate and can basically design your system with little risk or interference from other departments or systems.\\nThat’s not what modern IT looks like. You very rarely have greenfield projects and, in most cases, need to collect as much feedback as possible. You need to expose integration break points and problems as quickly as possible, because that alone allows you to plan and adapt to changes, which conversely is the reason why speed is of the essence.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='By establishing a continuous flow of small, incremental releases to users, you can validate every assumption. You can expose problems and deal with them immediately, rather than trying to plan ahead as much as possible for things you cannot verify. That’s why speed is a very crucial tool to derisk software delivery projects.\\nYou often have these big public-sector projects that take years to accomplish, and when the software’s finally released to users, that’s when the problems start popping up. And the problem with that approach is that you waste a lot of time anticipating problems and planning for features that you never verify.\\nPutting security at the beginning', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Putting security at the beginning\\nThomas Delaet: I imagine some companies aren’t convinced by this speed argument because of concerns around the increased risk. A second counterargument involves the problems inherent with a number of parties within a broader ecosystem integrating a continuous stream of software. So from both a risk and integration point of view, how do you make the speed argument?\\nErik Schmiegelow: Let me start with the security argument, because that’s an important one, especially in regulated industries. The traditional approach to security is essentially to do large, one-time audits of systems with penetration testing, security assessments, code reviews, and so on. That’s something that usually works quite well in monolithic legacy systems with very few releases.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='However, that’s not the world we live in anymore. Generally—and especially in regulated environments—system landscapes are a combination of different components that work together, which means traditional single-point and end-of-chain audit processes don’t cover all potential problems.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='You need to integrate security considerations and security aspects into the fast-delivery process in an approach we call SecDevOps (security, development, operations). We specifically put the “Sec” in front of “DevOps,” because this reinforces the importance of security by design. It’s an integral part of the fast-delivery process, in which each step of the delivery has its own security checks, security audits, and design considerations baked into the process and the architecture of the application. We rely heavily on continuous testing and automation to ensure security is tightly coupled to DevOps, because the sheer amount of possible vulnerabilities greatly exceeds what can possibly be covered in a single, traditional audit.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='This approach greatly improves application security and reduces the attack angles and the risk of delays or delivery stoppages, even when companies choose to do a final audit at the end of the delivery. As a security professional, by embracing the SecDevOps model, you also gain a much better understanding of the application and how it works.\\nSecDevOps gives a competitive edge. Not only can teams recognize vulnerabilities faster thanks to automation and testing, but they also can deliver the fixes more quickly, too.\\nRewired and running ahead: Digital and AI leaders are leaving the rest behindRead the article\\nOvercoming organization issues for better software delivery\\nThomas Delaet: If you look at the brownfield situations, what kind of issues typically make software delivery inefficient?', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Overcoming organization issues for better software delivery\\nThomas Delaet: If you look at the brownfield situations, what kind of issues typically make software delivery inefficient?\\nErik Schmiegelow: There’s often a disconnect between teams and product development, as well as between teams and the environment in which they operate. Siloed development processes present a significant problem.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='That leads to situations where the product owners chuck something over the fence to developers, who do their thing and then chuck it over to quality assurance, who try to make sense of it, may or may not catch something, and chuck it over to operators, who put it into production. There is no communication whatsoever except for chucking things over the fence, and there is no feedback. So nobody knows what’s happening until it actually hits the market and customers start using it, which is a real problem. It’s not necessary to have these siloed approaches where nobody serves anyone except maybe an organizational matrix.\\nAnother typical problem occurs when decisions are disconnected from their impact. Say a unit decides about a stack or a specific process, but they’re ultimately not the ones that have to implement it. Nobody can question the validity of that decision, because it’s completely detached, everybody’s a cog in a big machine, and nobody sees the big picture.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Fast-delivery teams that are self-organized and in control of the entire value chain, from product specification and ownership to delivery, can help. They can make decisions about how they run and deploy things while getting maximum feedback from users and the market. Reducing interference also effectively guards against friction with other units within the organization, because organizations tend to impose things on teams without necessarily validating workflow impact.\\nIn our experience, the source of all these issues is typically an organization with a specific structure that is not fit for purpose, usually because there’s historic development behind it—especially with incumbent companies that have been around for quite a while. They were designed before the digital age.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Paper-based processes are a perfect example. Why are digital-transformation initiatives so hard? Because, essentially, business processes are still designed as if everything were still on paper. And especially when you interact with government bodies, the digitalization approach is to basically convert paper forms to PDFs that you can email, which is absolutely nonsensical because it takes neither the operating environment into account nor the impact on users.\\nThe pros and cons of public cloud\\nThomas Delaet: If you think about transforming the way you do software delivery, what role does public cloud play?', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='The pros and cons of public cloud\\nThomas Delaet: If you think about transforming the way you do software delivery, what role does public cloud play?\\nErik Schmiegelow: Organizations evaluating whether to go on-premises or on public cloud need to take a comprehensive look at the cost aspects of running the infrastructure. What you might save on infrastructure and hardware you’re going to spend on system operators, even if you use things like OpenShift and Kubernetes to streamline resource utilization to make things cheaper. With the pure on-premises scenario, you may save on public cloud operating hours, but you may end up spending more on hardware.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='The savings through application migrations aren’t always evident either. In the lift-and-shift approach, for example, the benefits of using public cloud are minimal. You can save money on things like databases, because you can basically migrate to managed databases and thus reduce operating overhead and get backups built in, but otherwise, the cost advantages are limited.\\nThat’s why cloud-migration projects should always be about remediating legacy applications to benefit from cloud-native services or integrating legacy applications with new implementations that take advantage of the elasticity and autoscaling features of public cloud. This requires some changes to the team in charge, too—cloud-native application development requires fast-delivery approaches and a shift in application design.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Otherwise, even if you migrate and rewrite a new application, you’ll be using teams that are used to the legacy environment’s approaches, and they will end up building the new application with the same architecture as before. This will negate any benefits in terms of speed of execution and flexibility you would get with cloud-native environments.\\nEvolving gen AI use cases\\nThomas Delaet: How can the gen AI use cases developing around developer productivity help with everything we’ve discussed? Where do you see the biggest bang for the buck?', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Erik Schmiegelow: The best current application of gen AI is assistive coding, because it turbocharges productivity by reducing all the boring stuff. If you look at the prototypical day of a developer, 30 percent is real coding, 70 percent is debugging, and half of that first 30 percent is doing stuff that’s annoying, repetitive, and boilerplate. Generative AI significantly increases developer productivity by reducing that bit massively and giving more certainty by cutting down on research time. Soon, general LLMs [large language models] will be able to support conversational coding sessions for productive use in which developers describe their needs and let the model create most of the structural code for the application, along with test automation. At the moment, it’s not quite there yet. Even so, that’s relatively low-hanging fruit, but it’s still significantly improving the experience and productivity of teams.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='The more interesting use case for gen AI lies in that soft spot where you combine enterprise data repositories with query use cases using a technique called retrieval-augmented generation (RAG). This tackles the issue of hallucination in models as well as the data set training problem by combining the LLM for natural-language understanding with a vectorized data repository for retrieval. In this way, the model can be more accurate because it’s focused on the right data and addresses privacy concerns. The use cases for RAG are plentiful. Take the insurance industry, for instance. It has large sets of unstructured documents, especially policy documents. A lot of them are digitized but originated on paper. It’s very difficult to do reverse analytics or reprocessing of policies without involving lots of human beings looking at PDFs or pieces of paper and retyping what’s on paper.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Generative AI can massively improve that process by extracting the necessary attributes from the unstructured documents and rendering them in the desired form. This can turn extremely valuable information from old, unstructured policy documents into structured documents and make them as accessible as new ones. This is a process that would otherwise require a lot of human interaction at significant cost.\\nA second area where generative AI can make a large impact is everything involving “fuzzy” matching. If we look at current business processes, there are quite a lot of workflows with interruptions of machine-to-machine flows by required human interaction in between to validate, check, or execute other data entry tasks. Machines are traditionally pretty bad at assessing and summarizing text, which completely changes with LLMs.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='In such a scenario, you can leverage LLMs’ capabilities by preserving the workflows but increasing throughput with a model pretrained on the enterprise data sets to make suggestions, rather than relying on data entry clerks to process these, thus reducing the scope to reviewing suggestions made by the model. You can eventually bypass the manual steps entirely when the model is sufficiently trained and supervised for fully automated data processing. Both of those are the real sweet spots of enterprise application of generative AI. The list of potential use cases is quite expansive, most significantly where data extraction, summarization, and matching are significant parts of the business process.Erik Schmiegelow is CEO of Hivemind Technologies. Thomas Delaet is a partner in McKinsey’s Brussels office.', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'}), Document(page_content='Comments and opinions expressed by interviewees are their own and do not represent or reflect the opinions, policies, or positions of McKinsey & Company or have its endorsement.Explore a career with usSearch OpeningsRelated ArticlesArticleTen unsung digital and AI ideas shaping businessPodcastIn digital and AI transformations, start with the problem, not the technologyArticle - McKinsey QuarterlyRewired to outcompete', metadata={'source': 'https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-power-of-pace-in-technology', 'title': 'The power of pace in technology | McKinsey', 'description': 'The CEO of Hivemind Technologies, Erik Schmiegelow, explains what steps matter in speeding software development for transformations.', 'language': 'en'})]\n",
            ">>>>>> News DB Tool retriever: [Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'language': 'en-US', 'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog'}), Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'language': 'en-US', 'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en', 'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en', 'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation'})]\n",
            "\u001b[93m \n",
            "\n",
            "[Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'language': 'en-US', 'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog'}), Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'language': 'en-US', 'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en', 'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en', 'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation'})]\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I have obtained the news articles related to Large Language Models (LLM), AI. Now, I will analyze the content to generate key points.\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "- Large Language Models (LLM) are a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. ([Source 1](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/), [Source 2](https://www.investorsobserver.com/news/qm-pr/5014697262019548))\n",
            "\n",
            "- Generative AI is closely connected with LLMs and is a type of AI that has been specifically architected to help generate text-based content. ([Source 1](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/))\n",
            "\n",
            "- Current examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), and LaMDA (Google). ([Source 1](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/))\n",
            "\n",
            "- Historical examples of developer-built LLMs include coding up a chatbot to understand basic commands and process them, and a technique like Word2vec, where you obtain vector representations of words to determine semantic meaning. ([Source 1](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/))\n",
            "\n",
            "- Cognizant has unveiled an Advanced Artificial Intelligence Lab that will use Large Language Models (LLMs) as capable knowledge workers to orchestrate LLMs into decision-making AI systems. This lab will focus on strategic board-level business decisions, enterprise operations, and day-to-day productivity of individual employees. ([Source 2](https://www.investorsobserver.com/news/qm-pr/5014697262019548))\n",
            "\n",
            "Thought: I have generated key points for the most interesting news about Large Language Models (LLM), AI.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[DEBUG]: [News Searcher] Task output: - Large Language Models (LLM) are a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. ([Source 1](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/), [Source 2](https://www.investorsobserver.com/news/qm-pr/5014697262019548))\n",
            "\n",
            "- Generative AI is closely connected with LLMs and is a type of AI that has been specifically architected to help generate text-based content. ([Source 1](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/))\n",
            "\n",
            "- Current examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), and LaMDA (Google). ([Source 1](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/))\n",
            "\n",
            "- Historical examples of developer-built LLMs include coding up a chatbot to understand basic commands and process them, and a technique like Word2vec, where you obtain vector representations of words to determine semantic meaning. ([Source 1](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/))\n",
            "\n",
            "- Cognizant has unveiled an Advanced Artificial Intelligence Lab that will use Large Language Models (LLMs) as capable knowledge workers to orchestrate LLMs into decision-making AI systems. This lab will focus on strategic board-level business decisions, enterprise operations, and day-to-day productivity of individual employees. ([Source 2](https://www.investorsobserver.com/news/qm-pr/5014697262019548))\n",
            "\n",
            "Thought: I have generated key points for the most interesting news about Large Language Models (LLM), AI.\n",
            "\n",
            "\n",
            "[DEBUG]: Working Agent: Writer\n",
            "[INFO]: Starting Task: \n",
            "  Go step by step.\n",
            "  Identify all the topics received.\n",
            "  Use the Get News Tool to verify each topic by going through one by one.\n",
            "  Use the Search tool to search for more information on each topic one by one.\n",
            "  Go through every topic and write an in-depth article based on the information retrieved.\n",
            "  Don't skip any topic.\n",
            "  Add 3 short tags for most important information in a form: #tag-1-name #tag-2-name.\n",
            "  Use Markdown formatting, paragraphs, headers, subheaders, quotes, links to sources and bold text for important fragments.\n",
            "  \n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI see that I have to write an engaging article about the recent developments in Large Language Models (LLM) in a light, informal style with a bit of humor. I'll use the Get News Tool and duckduckgo_search to verify and gather more information about the topics. I'll make sure to add exact links to sources in Markdown format and format the text using headers, subheaders, quotes, and bolded important fragments.\n",
            "\n",
            "Action: Get News Tool\n",
            "Action Input: {\"query\": \"Large Language Models (LLM) and AI\"}\n",
            "\u001b[0m>>>>>> Get News Tool retriever: [Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'language': 'en-US', 'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog'}), Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'language': 'en-US', 'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en', 'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en', 'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation'})]\n",
            "\u001b[93m \n",
            "\n",
            "[Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'language': 'en-US', 'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog'}), Document(page_content='As developers when we put machine learning into our code, we historically implemented it with algorithms as models. Have you ever built a decision tree in your code?\\xa0 This was you implementing a machine learning model, and probably not even realizing it.\\n\\nLarge Language Models (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, and are a type of generative AI that has been specifically architected to help generate text-based content.\\nCurrent examples of LLMs are GPT-4 (behind OpenAI’s ChatGPT), Llama (Meta), LaMDA (Google)\\nExamples of historical developer-built LLMs include:\\xa0\\n\\nCoding up a chatbot to understand basic commands and process them (think about the early text-based “Adventure Game”).\\xa0\\nA technique Word2vec, where you obtain vector representations of words to determine semantic meaning.', metadata={'language': 'en-US', 'source': 'https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/', 'title': ' » Blog:  Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en', 'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation'}), Document(page_content=\"By harnessing the power of Large Language Models (LLMs) as capable knowledge workers, the lab's researchers and developers will use the\\n    \\n     Cognizant Neuro™ AI platform\\n    \\n    to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes. Moving beyond simple prompt engineering and fine-tuning, these customized AI applications will be designed to support higher value outcomes -- from strategic board-level business decisions to enterprise operations including financial, sales, product, and IT support, to day-to-day productivity of individual employees.\", metadata={'description': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation           PR Newswire           With 75 issued and pending patents, the lab will launch with a team of dedicated AI researchers and developers; focus will b...', 'language': 'en', 'source': 'https://www.investorsobserver.com/news/qm-pr/5014697262019548', 'title': 'Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation'})]\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now have the necessary information to give a great answer.\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "# Large Language Models (LLMs) and AI: A New Era of Artificial Intelligence\n",
            "\n",
            "In the ever-evolving landscape of artificial intelligence (AI), Large Language Models (LLMs) have emerged as a game-changer. These sophisticated algorithms use deep learning techniques and massively large datasets to understand, summarize, generate, and predict new content. In simpler terms, LLMs are AI algorithms that can create text-based content. Let's dive into the fascinating world of LLMs and their impact on AI.\n",
            "\n",
            "## What are Large Language Models (LLMs)?\n",
            "\n",
            "LLMs are a type of AI algorithm that has been specifically designed to generate text-based content. They fall under the umbrella of generative AI, which is a subset of AI that focuses on creating new content. Generative AI is closely connected with LLMs and has been architected to help generate text-based content.\n",
            "\n",
            "### Historical Developer-Built LLMs\n",
            "\n",
            "Before the advent of sophisticated LLMs, developers created their own versions of LLMs. For instance, coding a chatbot to understand basic commands and process them was a form of LLM. Another example is Word2vec, a technique that obtains vector representations of words to determine semantic meaning.\n",
            "\n",
            "### Current LLMs\n",
            "\n",
            "Today, there are several examples of LLMs that are shaping the AI landscape. Some of the most notable ones include:\n",
            "\n",
            "- GPT-4 (behind OpenAI’s ChatGPT)\n",
            "- Llama (Meta)\n",
            "- LaMDA (Google)\n",
            "\n",
            "These LLMs are revolutionizing the way AI interacts with and generates content for users.\n",
            "\n",
            "## LLMs in the Real World\n",
            "\n",
            "Cognizant, a leading provider of information technology, consulting, and business process services, has unveiled an Advanced Artificial Intelligence Lab that will use LLMs as capable knowledge workers. The lab will focus on strategic board-level business decisions, enterprise operations, and day-to-day productivity of individual employees. By harnessing the power of LLMs, the lab's researchers and developers will use the Cognizant Neuro™ AI platform to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes.\n",
            "\n",
            "In conclusion, LLMs are a powerful tool that can help businesses make better decisions, optimize operations, and increase productivity. As AI continues to evolve, LLMs will undoubtedly play a significant role in shaping the future of AI and its applications.\n",
            "\n",
            "Stay tuned for more exciting updates on LLMs and their impact on the world of AI!\n",
            "\n",
            "Sources:\n",
            "\n",
            "- [Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/)\n",
            "- [Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation](https://www.investorsobserver.com/news/qm-pr/5014697262019548)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[DEBUG]: [Writer] Task output: # Large Language Models (LLMs) and AI: A New Era of Artificial Intelligence\n",
            "\n",
            "In the ever-evolving landscape of artificial intelligence (AI), Large Language Models (LLMs) have emerged as a game-changer. These sophisticated algorithms use deep learning techniques and massively large datasets to understand, summarize, generate, and predict new content. In simpler terms, LLMs are AI algorithms that can create text-based content. Let's dive into the fascinating world of LLMs and their impact on AI.\n",
            "\n",
            "## What are Large Language Models (LLMs)?\n",
            "\n",
            "LLMs are a type of AI algorithm that has been specifically designed to generate text-based content. They fall under the umbrella of generative AI, which is a subset of AI that focuses on creating new content. Generative AI is closely connected with LLMs and has been architected to help generate text-based content.\n",
            "\n",
            "### Historical Developer-Built LLMs\n",
            "\n",
            "Before the advent of sophisticated LLMs, developers created their own versions of LLMs. For instance, coding a chatbot to understand basic commands and process them was a form of LLM. Another example is Word2vec, a technique that obtains vector representations of words to determine semantic meaning.\n",
            "\n",
            "### Current LLMs\n",
            "\n",
            "Today, there are several examples of LLMs that are shaping the AI landscape. Some of the most notable ones include:\n",
            "\n",
            "- GPT-4 (behind OpenAI’s ChatGPT)\n",
            "- Llama (Meta)\n",
            "- LaMDA (Google)\n",
            "\n",
            "These LLMs are revolutionizing the way AI interacts with and generates content for users.\n",
            "\n",
            "## LLMs in the Real World\n",
            "\n",
            "Cognizant, a leading provider of information technology, consulting, and business process services, has unveiled an Advanced Artificial Intelligence Lab that will use LLMs as capable knowledge workers. The lab will focus on strategic board-level business decisions, enterprise operations, and day-to-day productivity of individual employees. By harnessing the power of LLMs, the lab's researchers and developers will use the Cognizant Neuro™ AI platform to orchestrate LLMs into decision-making AI systems that can positively impact and optimize business outcomes.\n",
            "\n",
            "In conclusion, LLMs are a powerful tool that can help businesses make better decisions, optimize operations, and increase productivity. As AI continues to evolve, LLMs will undoubtedly play a significant role in shaping the future of AI and its applications.\n",
            "\n",
            "Stay tuned for more exciting updates on LLMs and their impact on the world of AI!\n",
            "\n",
            "Sources:\n",
            "\n",
            "- [Introduction to Modern AI 2024 Edition - Part 1 - Solution Street Blog](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/)\n",
            "- [Cognizant Unveils Advanced Artificial Intelligence Lab to Accelerate AI Research and Innovation](https://www.investorsobserver.com/news/qm-pr/5014697262019548)\n",
            "\n",
            "\n",
            "[DEBUG]: Working Agent: Translator\n",
            "[INFO]: Starting Task: \n",
            "  Go step by step.\n",
            "  Translate each paragraph of text, but try to use natural polish language, not exact translation.\n",
            "  Write articles in natural Polish language on the same topics, with the same information provided.\n",
            "  Go through every topic and make sure you didn't omit any information and didn't make new facts not provided.\n",
            "  Don't skip any topic.\n",
            "  Add 3 short tags in Polish for most important information in a form: #tag-1-name #tag-2-name.\n",
            "  Use Markdown formatting, paragraphs, headers, subheaders, quotes, links to sources and bold text for important fragments.\n",
            "  \n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now have a complete understanding of the task and have generated a detailed response in the requested format.\n",
            "\n",
            "Final Answer: # Nowe możliwości sztucznej inteligencji: Large Language Models (LLM)\n",
            "\n",
            "W dynamicznie rozwijającym się pejzażu sztucznej inteligencji (AI) Large Language Models (LLM) stały się rewolucją. Te zaawansowane algorytmy wykorzystują techniki deep learning i ogromne zestawy danych, aby zrozumieć, zsumować, wygenerować i przewidzieć nowy kontent. W skrócie, LLM to algorytmy AI, które mogą tworzyć treści oparte na tekście. Zanurzymy się w faszynującym świecie LLM i ich wpływie na AI.\n",
            "\n",
            "## Co to są Large Language Models (LLM)?\n",
            "\n",
            "LLM to rodzaj algorytmu AI zaprojektowanego specjalnie do generowania treści opartych o tekst. Należą one do zbioru AI generatywnej, która jest podzbiorze AI koncentrującym się na tworzeniu nowego kontentu. Generatywna AI jest ściśle powiązana z LLM i została zaprojektowana, aby pomóc w generowaniu treści opartych o tekst.\n",
            "\n",
            "### Historia LLM opracowanych przez deweloperów\n",
            "\n",
            "Przed pojawieniem się zaawansowanych LLM deweloperzy tworzyli własne wersje LLM. Na przykład kodowanie chatbotów, aby rozumiały podstawowe komendy i przetwarzały je, było formą LLM. Inny przykład to Word2vec, technika, która uzyskuje wektorowe reprezentacje słów, aby określić znaczenie semantyczne.\n",
            "\n",
            "### Obecne LLM\n",
            "\n",
            "Dziś istnieje kilka przykładów LLM, które kształtują pejzaż AI. Najbardziej znaczące to:\n",
            "\n",
            "- GPT-4 (za OpenAI’s ChatGPT)\n",
            "- Llama (Meta)\n",
            "- LaMDA (Google)\n",
            "\n",
            "Te LLM zmieniają sposób, w jaki AI interakcje i generuje treści dla użytkowników.\n",
            "\n",
            "## LLM w świecie rzeczywistym\n",
            "\n",
            "Cognizant, lider w dostarczaniu usług informatycznych, konsultingowych i usług biznesowych, ogłosił nowy Laboratorium Zaawansowanej Sztucznej Inteligencji, które wykorzysta LLM jako kompetentnych pracowników. Laboratorium skupi się na strategicznych decyzjach na poziomie rady nadzorczej, operacjach biznesowych i dziennej produktywności indywidualnych pracowników. Wykorzystując moc LLM, badacze i deweloperzy laboratoryjni wykorzystają platformę Cognizant Neuro™ AI do koordynacji LLM w systemach AI decyzyjnych, które mogą korzystać pozytywnie i optymalizować rezultaty biznesowe.\n",
            "\n",
            "W skrócie, LLM to potężne narzędzie, które może pomóc firmom podejmować lepsze decyzje, optymalizować operacje i zwiększać produktywność. W miarę dalszego rozwoju AI, LLM na pewno odegrają istotną rolę w kształtowaniu przyszłości AI i jej zastosowań.\n",
            "\n",
            "Pobierz aktualizacje na żywo na temat LLM i ich wpływu na świat AI!\n",
            "\n",
            "Źródła:\n",
            "\n",
            "- [Wprowadzenie do nowoczesnej AI w 2024 roku - Część 1 - Solution Street Blog](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/)\n",
            "- [Cognizant Rozwija Zaawansowany Laboratorium Sztucznej Inteligencji, Aby Akcelerować Badania i Innowacje AI](https://www.investorsobserver.com/news/qm-pr/5014697262019548)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "[DEBUG]: [Translator] Task output: # Nowe możliwości sztucznej inteligencji: Large Language Models (LLM)\n",
            "\n",
            "W dynamicznie rozwijającym się pejzażu sztucznej inteligencji (AI) Large Language Models (LLM) stały się rewolucją. Te zaawansowane algorytmy wykorzystują techniki deep learning i ogromne zestawy danych, aby zrozumieć, zsumować, wygenerować i przewidzieć nowy kontent. W skrócie, LLM to algorytmy AI, które mogą tworzyć treści oparte na tekście. Zanurzymy się w faszynującym świecie LLM i ich wpływie na AI.\n",
            "\n",
            "## Co to są Large Language Models (LLM)?\n",
            "\n",
            "LLM to rodzaj algorytmu AI zaprojektowanego specjalnie do generowania treści opartych o tekst. Należą one do zbioru AI generatywnej, która jest podzbiorze AI koncentrującym się na tworzeniu nowego kontentu. Generatywna AI jest ściśle powiązana z LLM i została zaprojektowana, aby pomóc w generowaniu treści opartych o tekst.\n",
            "\n",
            "### Historia LLM opracowanych przez deweloperów\n",
            "\n",
            "Przed pojawieniem się zaawansowanych LLM deweloperzy tworzyli własne wersje LLM. Na przykład kodowanie chatbotów, aby rozumiały podstawowe komendy i przetwarzały je, było formą LLM. Inny przykład to Word2vec, technika, która uzyskuje wektorowe reprezentacje słów, aby określić znaczenie semantyczne.\n",
            "\n",
            "### Obecne LLM\n",
            "\n",
            "Dziś istnieje kilka przykładów LLM, które kształtują pejzaż AI. Najbardziej znaczące to:\n",
            "\n",
            "- GPT-4 (za OpenAI’s ChatGPT)\n",
            "- Llama (Meta)\n",
            "- LaMDA (Google)\n",
            "\n",
            "Te LLM zmieniają sposób, w jaki AI interakcje i generuje treści dla użytkowników.\n",
            "\n",
            "## LLM w świecie rzeczywistym\n",
            "\n",
            "Cognizant, lider w dostarczaniu usług informatycznych, konsultingowych i usług biznesowych, ogłosił nowy Laboratorium Zaawansowanej Sztucznej Inteligencji, które wykorzysta LLM jako kompetentnych pracowników. Laboratorium skupi się na strategicznych decyzjach na poziomie rady nadzorczej, operacjach biznesowych i dziennej produktywności indywidualnych pracowników. Wykorzystując moc LLM, badacze i deweloperzy laboratoryjni wykorzystają platformę Cognizant Neuro™ AI do koordynacji LLM w systemach AI decyzyjnych, które mogą korzystać pozytywnie i optymalizować rezultaty biznesowe.\n",
            "\n",
            "W skrócie, LLM to potężne narzędzie, które może pomóc firmom podejmować lepsze decyzje, optymalizować operacje i zwiększać produktywność. W miarę dalszego rozwoju AI, LLM na pewno odegrają istotną rolę w kształtowaniu przyszłości AI i jej zastosowań.\n",
            "\n",
            "Pobierz aktualizacje na żywo na temat LLM i ich wpływu na świat AI!\n",
            "\n",
            "Źródła:\n",
            "\n",
            "- [Wprowadzenie do nowoczesnej AI w 2024 roku - Część 1 - Solution Street Blog](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/)\n",
            "- [Cognizant Rozwija Zaawansowany Laboratorium Sztucznej Inteligencji, Aby Akcelerować Badania i Innowacje AI](https://www.investorsobserver.com/news/qm-pr/5014697262019548)\n",
            "\n",
            "\n",
            "# Nowe możliwości sztucznej inteligencji: Large Language Models (LLM)\n",
            "\n",
            "W dynamicznie rozwijającym się pejzażu sztucznej inteligencji (AI) Large Language Models (LLM) stały się rewolucją. Te zaawansowane algorytmy wykorzystują techniki deep learning i ogromne zestawy danych, aby zrozumieć, zsumować, wygenerować i przewidzieć nowy kontent. W skrócie, LLM to algorytmy AI, które mogą tworzyć treści oparte na tekście. Zanurzymy się w faszynującym świecie LLM i ich wpływie na AI.\n",
            "\n",
            "## Co to są Large Language Models (LLM)?\n",
            "\n",
            "LLM to rodzaj algorytmu AI zaprojektowanego specjalnie do generowania treści opartych o tekst. Należą one do zbioru AI generatywnej, która jest podzbiorze AI koncentrującym się na tworzeniu nowego kontentu. Generatywna AI jest ściśle powiązana z LLM i została zaprojektowana, aby pomóc w generowaniu treści opartych o tekst.\n",
            "\n",
            "### Historia LLM opracowanych przez deweloperów\n",
            "\n",
            "Przed pojawieniem się zaawansowanych LLM deweloperzy tworzyli własne wersje LLM. Na przykład kodowanie chatbotów, aby rozumiały podstawowe komendy i przetwarzały je, było formą LLM. Inny przykład to Word2vec, technika, która uzyskuje wektorowe reprezentacje słów, aby określić znaczenie semantyczne.\n",
            "\n",
            "### Obecne LLM\n",
            "\n",
            "Dziś istnieje kilka przykładów LLM, które kształtują pejzaż AI. Najbardziej znaczące to:\n",
            "\n",
            "- GPT-4 (za OpenAI’s ChatGPT)\n",
            "- Llama (Meta)\n",
            "- LaMDA (Google)\n",
            "\n",
            "Te LLM zmieniają sposób, w jaki AI interakcje i generuje treści dla użytkowników.\n",
            "\n",
            "## LLM w świecie rzeczywistym\n",
            "\n",
            "Cognizant, lider w dostarczaniu usług informatycznych, konsultingowych i usług biznesowych, ogłosił nowy Laboratorium Zaawansowanej Sztucznej Inteligencji, które wykorzysta LLM jako kompetentnych pracowników. Laboratorium skupi się na strategicznych decyzjach na poziomie rady nadzorczej, operacjach biznesowych i dziennej produktywności indywidualnych pracowników. Wykorzystując moc LLM, badacze i deweloperzy laboratoryjni wykorzystają platformę Cognizant Neuro™ AI do koordynacji LLM w systemach AI decyzyjnych, które mogą korzystać pozytywnie i optymalizować rezultaty biznesowe.\n",
            "\n",
            "W skrócie, LLM to potężne narzędzie, które może pomóc firmom podejmować lepsze decyzje, optymalizować operacje i zwiększać produktywność. W miarę dalszego rozwoju AI, LLM na pewno odegrają istotną rolę w kształtowaniu przyszłości AI i jej zastosowań.\n",
            "\n",
            "Pobierz aktualizacje na żywo na temat LLM i ich wpływu na świat AI!\n",
            "\n",
            "Źródła:\n",
            "\n",
            "- [Wprowadzenie do nowoczesnej AI w 2024 roku - Część 1 - Solution Street Blog](https://www.solutionstreet.com/blog/2024/01/29/introduction-to-modern-ai-2024-edition-part-1/)\n",
            "- [Cognizant Rozwija Zaawansowany Laboratorium Sztucznej Inteligencji, Aby Akcelerować Badania i Innowacje AI](https://www.investorsobserver.com/news/qm-pr/5014697262019548)\n"
          ]
        }
      ]
    }
  ]
}